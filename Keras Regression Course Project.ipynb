{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Keras Regression Course Project.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwnOS3OOveS9"
      },
      "source": [
        "**Mahdi Mashalla Regression keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72vmZe77Ofnv"
      },
      "source": [
        "# Importing the neccessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics as stats\n",
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime\n",
        "\n",
        "# Forcing keras to use CPU.\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-97_leKOfn0",
        "outputId": "aaa5b32f-fa3f-4f91-a583-2eee54432d10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Reading the Data and storing it in a dataframe\n",
        "\n",
        "path = r'concrete_data.csv' # the path to the concrete_data.csv file\n",
        "df = pd.read_csv(path) # read the data into dataframe\n",
        "\n",
        "print(df.head()) # display first 5 entries in the dataframe\n",
        "print('\\nShape of dataframe : ',df.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cement  Blast Furnace Slag  Fly Ash  ...  Fine Aggregate  Age  Strength\n",
            "0   540.0                 0.0      0.0  ...           676.0   28     79.99\n",
            "1   540.0                 0.0      0.0  ...           676.0   28     61.89\n",
            "2   332.5               142.5      0.0  ...           594.0  270     40.27\n",
            "3   332.5               142.5      0.0  ...           594.0  365     41.05\n",
            "4   198.6               132.4      0.0  ...           825.5  360     44.30\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "\n",
            "Shape of dataframe :  (1030, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0gp1uXROfn0",
        "outputId": "a8018abd-a5b2-491a-d9fd-eb7fd53218bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# Summary of the dataset\n",
        "\n",
        "df.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>281.167864</td>\n",
              "      <td>73.895825</td>\n",
              "      <td>54.188350</td>\n",
              "      <td>181.567282</td>\n",
              "      <td>6.204660</td>\n",
              "      <td>972.918932</td>\n",
              "      <td>773.580485</td>\n",
              "      <td>45.662136</td>\n",
              "      <td>35.817961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104.506364</td>\n",
              "      <td>86.279342</td>\n",
              "      <td>63.997004</td>\n",
              "      <td>21.354219</td>\n",
              "      <td>5.973841</td>\n",
              "      <td>77.753954</td>\n",
              "      <td>80.175980</td>\n",
              "      <td>63.169912</td>\n",
              "      <td>16.705742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>121.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>594.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>192.375000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>932.000000</td>\n",
              "      <td>730.950000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>23.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>272.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>968.000000</td>\n",
              "      <td>779.500000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>34.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>142.950000</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>1029.400000</td>\n",
              "      <td>824.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>46.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>540.000000</td>\n",
              "      <td>359.400000</td>\n",
              "      <td>200.100000</td>\n",
              "      <td>247.000000</td>\n",
              "      <td>32.200000</td>\n",
              "      <td>1145.000000</td>\n",
              "      <td>992.600000</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>82.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Cement  Blast Furnace Slag  ...          Age     Strength\n",
              "count  1030.000000         1030.000000  ...  1030.000000  1030.000000\n",
              "mean    281.167864           73.895825  ...    45.662136    35.817961\n",
              "std     104.506364           86.279342  ...    63.169912    16.705742\n",
              "min     102.000000            0.000000  ...     1.000000     2.330000\n",
              "25%     192.375000            0.000000  ...     7.000000    23.710000\n",
              "50%     272.900000           22.000000  ...    28.000000    34.445000\n",
              "75%     350.000000          142.950000  ...    56.000000    46.135000\n",
              "max     540.000000          359.400000  ...   365.000000    82.600000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29kb6MA4Ofn1"
      },
      "source": [
        "<b>Note </b> : As the data is the same as used in this course, the video lectures have already shown that there is no need to perform any kind of pre-processing on the data. Hence, even the most common checks of data such as checking for missing values are not performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2eIxNjnOfn2",
        "outputId": "d2515555-09b5-422e-a524-cf109d2310cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating dataframes of features (X) and target (Y)\n",
        "X = df.iloc[:, 0:8]\n",
        "Y = df.iloc[:,8]\n",
        "\n",
        "# Printing the dataframes X and Y to ensure we have created the dataframes with the correct columns\n",
        "print('The features or the predictors (X) are : ', X, '\\n\\n') \n",
        "print('The target (Y) is : ', Y, '\\n\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The features or the predictors (X) are :        Cement  Blast Furnace Slag  ...  Fine Aggregate  Age\n",
            "0      540.0                 0.0  ...           676.0   28\n",
            "1      540.0                 0.0  ...           676.0   28\n",
            "2      332.5               142.5  ...           594.0  270\n",
            "3      332.5               142.5  ...           594.0  365\n",
            "4      198.6               132.4  ...           825.5  360\n",
            "...      ...                 ...  ...             ...  ...\n",
            "1025   276.4               116.0  ...           768.3   28\n",
            "1026   322.2                 0.0  ...           813.4   28\n",
            "1027   148.5               139.4  ...           780.0   28\n",
            "1028   159.1               186.7  ...           788.9   28\n",
            "1029   260.9               100.5  ...           761.5   28\n",
            "\n",
            "[1030 rows x 8 columns] \n",
            "\n",
            "\n",
            "The target (Y) is :  0       79.99\n",
            "1       61.89\n",
            "2       40.27\n",
            "3       41.05\n",
            "4       44.30\n",
            "        ...  \n",
            "1025    44.28\n",
            "1026    31.18\n",
            "1027    23.70\n",
            "1028    32.77\n",
            "1029    32.40\n",
            "Name: Strength, Length: 1030, dtype: float64 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIlt1erUOfn3"
      },
      "source": [
        "def regression_model() :\n",
        "    \n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11QBTKAjOfn4"
      },
      "source": [
        "def data_split() :\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create a list containing X_train, X_test, Y_train, Y_test and return the list\n",
        "    splits = [X_train, X_test, Y_train, Y_test] \n",
        "    return splits"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO3LpvksOfn5"
      },
      "source": [
        "<b>Note </b> : In the above function `data_split()` the <i>X_train, X_test, Y_train, Y_test</i> sets are stored in a list and list is returned. This is to ensure that the <i>X_train, X_test, Y_train, Y_test</i> sets are not printed when the function is called"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wa6-6vXOfn6"
      },
      "source": [
        "def predict() :\n",
        "    return model.predict(X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92hBJCIWOfn6"
      },
      "source": [
        "def calculate_mse() :\n",
        "    return mean_squared_error(Y_test,Y_predicted)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__mggJR6Ofn6"
      },
      "source": [
        "<b>Note 1</b> : The function `regression_model` as defined above only **compiles** the model and doesn't fit the model to training set. This is because in PART C, the number of epochs are changed and this would allow to fit the model with new number of epochs. This function will be used for **PART A**, **PART B** and **PART C**.\n",
        "\n",
        "<b>Note 2</b> : Since the splitting data, prediction and mean squared error calculations are all being used repeatly as well, hence there are separate functions created for them to remove redundancy of typing the same line of code while also making the code more neat. However,  as we the features (X) are to be normalized only **once**, hence there is no need to create a function for it\n",
        "\n",
        "<b>Note 3</b> : As the split function is executed first, the training and test sets are obtained and hence there is no need to explicitly pass any arguments to `predict()` and `calculate_mse()` functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Te6GaQ3Ofn7"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55sHsRMcOfn7"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q00h7JRxOfn7"
      },
      "source": [
        "# <font color = blue> PART A : BUILDING A BASELINE MODEL </font>\n",
        "\n",
        "\n",
        "<b>The baseline model consists of the following : </b>\n",
        "    <ul>\n",
        "        <li> Input layer with 10 nodes </li>\n",
        "        <li> A single hidden layer with 10 nodes and ReLU activation function </li>\n",
        "        <li> Adam optimizer and mean squared error loss function </li>\n",
        "    </ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLM5hce7Ofn7"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnrJX8NmOfn8"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model</font>\n",
        "\n",
        "In order to train and test the the baseline model, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA2rKXC0Ofn8"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEMOaJgJOfn8"
      },
      "source": [
        "# Split data into X_train, X_test, Y_train, Y_test\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIdeQOh0Ofn8"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMIW76VUOfn8",
        "outputId": "05b61a19-e0b0-407b-bf57-2d66baa03bcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the model\n",
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 127055.0781 - val_loss: 91688.5703\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 73740.3594 - val_loss: 49715.2305\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 36096.4375 - val_loss: 18831.5547\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 10823.0889 - val_loss: 3200.4392\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2452.1614 - val_loss: 1922.4240\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2006.7437 - val_loss: 1547.3781\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1527.5585 - val_loss: 1220.8889\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1299.6786 - val_loss: 1047.2504\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1103.2429 - val_loss: 930.2743\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 987.6763 - val_loss: 844.8005\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 928.8942 - val_loss: 781.3498\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 878.2062 - val_loss: 737.9839\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 837.9836 - val_loss: 698.8231\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 804.7148 - val_loss: 667.8741\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 774.9352 - val_loss: 638.6255\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 740.2466 - val_loss: 612.7805\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 709.3571 - val_loss: 586.6637\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 681.6907 - val_loss: 564.0494\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 652.9630 - val_loss: 539.8198\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 619.7018 - val_loss: 515.0988\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 589.3851 - val_loss: 482.1745\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 557.1623 - val_loss: 452.9969\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 522.0441 - val_loss: 422.8814\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 494.7473 - val_loss: 399.8534\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 470.3195 - val_loss: 383.1605\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 450.6589 - val_loss: 366.0349\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 435.3570 - val_loss: 357.5624\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 422.2464 - val_loss: 344.2582\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 407.6025 - val_loss: 337.2318\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.1233 - val_loss: 326.4466\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 386.3333 - val_loss: 318.9255\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 375.9048 - val_loss: 311.1054\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 367.5362 - val_loss: 303.0430\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 358.1473 - val_loss: 298.7761\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 351.4720 - val_loss: 293.8067\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 344.8752 - val_loss: 285.8779\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 339.0124 - val_loss: 280.7050\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 332.5865 - val_loss: 277.9222\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 327.6892 - val_loss: 272.5466\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 322.0602 - val_loss: 268.4153\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 317.6892 - val_loss: 264.6682\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 312.3786 - val_loss: 260.0502\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 308.1147 - val_loss: 254.6093\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 305.1729 - val_loss: 253.0715\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 298.0002 - val_loss: 247.3895\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 294.7371 - val_loss: 246.9618\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.3108 - val_loss: 241.9950\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 286.8033 - val_loss: 238.9402\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 281.4943 - val_loss: 235.8603\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 278.2585 - val_loss: 232.9428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f40826fa690>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDGjBEOEOfn9"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J4jUIqZOfn9"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dua6eeMTOfn9"
      },
      "source": [
        "<b>Note </b> : Y_test or the original values are also sometimes refered to as Y_true and this is the notation used in the examples found on the [mean square error page of sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html). However, in this notebook the Y_test notations is used for original values "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGTtkCDeOfn9"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um2ES1MkOfn9",
        "outputId": "213b26e3-dc63-481d-83f7-1e3e662ffa51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the mean square error\n",
        "mse = calculate_mse()\n",
        "#mse = mean_squared_error(Y_test,Y_predicted)\n",
        "print('Mean Square Error (MSE) of the Baseline Model is : ' , mse)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model is :  298.12308243467834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DFnUk7yOfn-"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvcnMpWVOfn-"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPaVIljlOfn-"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors</font>\n",
        "\n",
        "In order to train 50 models and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE)  :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>\n",
        "\n",
        "<b>Note</b> : To calcuate the mean and standard deviation of the mean square errors (mse) of 50 models which are stored in <code>list_of_means</code>, I will be using the python library <code>statistics</code> which has builtin functions to help caluclate the mean and standard deviation of a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YLtnbNnOfn-"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZzKbVSDOfn-"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOpHfOoHOfn-"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqcXpB7OOfn_",
        "outputId": "85b6ba86-c2b1-4a94-dbbd-b6e072d0e140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    data_split()\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=50)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = predict()\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = calculate_mse()\n",
        "    print('Mean Squared Error for Training Model # ', i+1 , ' : ', mse)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 632.2991 - val_loss: 597.0026\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 607.2099 - val_loss: 579.3518\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 591.6709 - val_loss: 565.3609\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 578.6715 - val_loss: 553.3433\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 561.8508 - val_loss: 542.6624\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 548.0954 - val_loss: 533.9008\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 534.8502 - val_loss: 519.2786\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 520.7567 - val_loss: 508.3037\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 505.9124 - val_loss: 496.5117\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 490.1290 - val_loss: 478.1457\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 470.6406 - val_loss: 464.4800\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 453.2131 - val_loss: 447.9376\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 437.3023 - val_loss: 439.1447\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 423.3564 - val_loss: 425.8986\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 408.7948 - val_loss: 416.2400\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 397.3594 - val_loss: 409.2849\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 387.0941 - val_loss: 401.0119\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 379.8109 - val_loss: 393.7036\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 370.1503 - val_loss: 390.1485\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 362.5849 - val_loss: 382.6646\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 353.7068 - val_loss: 375.5705\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 347.3211 - val_loss: 368.7227\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 337.0081 - val_loss: 371.5802\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 330.5432 - val_loss: 360.3008\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 323.2000 - val_loss: 351.9895\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 317.2979 - val_loss: 345.3078\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 310.6642 - val_loss: 343.2997\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 305.6818 - val_loss: 335.2929\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 300.4691 - val_loss: 329.1730\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.9002 - val_loss: 322.7285\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 291.2072 - val_loss: 319.2148\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 287.7484 - val_loss: 317.4824\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.6559 - val_loss: 307.2805\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 279.9194 - val_loss: 307.0374\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.9781 - val_loss: 298.2000\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 273.7740 - val_loss: 304.0859\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 270.5480 - val_loss: 290.5984\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.0089 - val_loss: 291.1792\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 263.4833 - val_loss: 285.8656\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.5902 - val_loss: 284.4958\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 258.0437 - val_loss: 283.0878\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 256.5132 - val_loss: 277.5555\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 254.1173 - val_loss: 278.7331\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 252.5069 - val_loss: 273.9111\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.9679 - val_loss: 272.5161\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  5  :  258.0246241650067\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  6 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 4844.1123 - val_loss: 2995.3279\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2212.3691 - val_loss: 2015.1132\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1532.1588 - val_loss: 1745.6832\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1272.0298 - val_loss: 1382.7699\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1043.1617 - val_loss: 1129.5490\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 823.4840 - val_loss: 874.4201\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 665.9631 - val_loss: 678.0275\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 540.5053 - val_loss: 575.5837\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 451.4534 - val_loss: 459.4218\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 392.4730 - val_loss: 397.6491\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 342.7878 - val_loss: 360.9493\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 310.7985 - val_loss: 330.1300\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 285.4652 - val_loss: 296.1866\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 260.7091 - val_loss: 274.6765\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 240.9212 - val_loss: 248.2616\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.5493 - val_loss: 245.6172\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.2619 - val_loss: 217.1988\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 194.1091 - val_loss: 208.1548\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 183.9467 - val_loss: 201.8363\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 178.6472 - val_loss: 196.0185\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 172.7160 - val_loss: 185.8752\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 169.4171 - val_loss: 182.2987\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 163.4413 - val_loss: 177.7926\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.5706 - val_loss: 177.5541\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 155.3565 - val_loss: 175.0933\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 155.3010 - val_loss: 167.2266\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.7902 - val_loss: 162.3388\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.0228 - val_loss: 161.4872\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.2502 - val_loss: 167.6739\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 143.6577 - val_loss: 152.1833\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.4928 - val_loss: 147.6300\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 139.2566 - val_loss: 151.6172\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.8047 - val_loss: 148.8773\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 132.0684 - val_loss: 146.7202\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.9331 - val_loss: 138.6893\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 130.4770 - val_loss: 135.8997\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.2821 - val_loss: 135.1863\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.8513 - val_loss: 141.1353\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.2488 - val_loss: 129.9522\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.0934 - val_loss: 124.1128\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 116.5349 - val_loss: 131.0820\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.6297 - val_loss: 132.4251\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 113.1412 - val_loss: 128.2569\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 110.6954 - val_loss: 121.5358\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 110.6519 - val_loss: 111.4885\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.8996 - val_loss: 111.6581\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 103.0780 - val_loss: 101.9193\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 99.4892 - val_loss: 103.4680\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 96.8552 - val_loss: 124.2262\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 95.8682 - val_loss: 97.2950\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  6  :  109.61516039473598\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  7 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 24091.8184 - val_loss: 6379.5430\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 6494.4771 - val_loss: 6141.3066\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4753.1567 - val_loss: 4274.2480\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3888.1536 - val_loss: 3818.1492\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3470.6157 - val_loss: 3530.9785\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3166.5071 - val_loss: 3224.2327\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2926.5469 - val_loss: 2977.8003\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2681.6230 - val_loss: 2791.4167\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2475.9177 - val_loss: 2559.6375\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2302.0986 - val_loss: 2385.6802\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2132.3687 - val_loss: 2232.7246\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1980.2936 - val_loss: 2085.6445\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1852.9808 - val_loss: 1962.2566\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1730.8569 - val_loss: 1837.6443\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1610.0056 - val_loss: 1744.8029\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1518.4229 - val_loss: 1636.0736\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1427.9164 - val_loss: 1543.2845\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1339.6118 - val_loss: 1462.6553\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1261.5071 - val_loss: 1389.5254\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1222.4019 - val_loss: 1319.7670\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1134.0194 - val_loss: 1257.5178\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1066.7003 - val_loss: 1202.3470\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1012.0820 - val_loss: 1148.0658\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 968.1760 - val_loss: 1094.2185\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 921.2137 - val_loss: 1046.1586\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 873.5593 - val_loss: 1005.2264\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 833.5383 - val_loss: 966.7896\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 802.7743 - val_loss: 931.6626\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 762.1299 - val_loss: 894.7684\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 730.8121 - val_loss: 861.9133\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 700.7003 - val_loss: 830.6724\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 670.0157 - val_loss: 802.5753\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 648.8250 - val_loss: 777.9255\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 622.1054 - val_loss: 750.4327\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 599.0572 - val_loss: 724.6161\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 577.7208 - val_loss: 703.6519\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 562.1628 - val_loss: 675.5812\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 533.4490 - val_loss: 653.9836\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 515.4291 - val_loss: 634.9067\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 496.4551 - val_loss: 618.0422\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 477.5878 - val_loss: 593.8676\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 461.7170 - val_loss: 580.7595\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 448.0995 - val_loss: 557.3669\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 431.0303 - val_loss: 539.7006\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 414.9784 - val_loss: 521.1572\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 401.4057 - val_loss: 502.6621\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 388.2295 - val_loss: 493.1691\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 381.6073 - val_loss: 471.3386\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 363.5348 - val_loss: 455.8830\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 354.3979 - val_loss: 448.2376\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  7  :  349.29678087232855\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  8 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 2145.5532 - val_loss: 793.9164\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 688.0628 - val_loss: 521.5239\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 396.2602 - val_loss: 316.8075\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 297.6088 - val_loss: 259.9570\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.4728 - val_loss: 214.6480\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.7805 - val_loss: 192.3349\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 179.7588 - val_loss: 179.0978\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 172.3483 - val_loss: 177.5927\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 168.7140 - val_loss: 170.7865\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.2402 - val_loss: 168.3321\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 165.5982 - val_loss: 169.0633\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.2300 - val_loss: 169.1161\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 161.3917 - val_loss: 167.7009\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 161.2004 - val_loss: 165.7523\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.1299 - val_loss: 167.8098\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 156.9189 - val_loss: 167.8822\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.3656 - val_loss: 165.9911\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.0929 - val_loss: 162.0257\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.4898 - val_loss: 168.3739\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.0807 - val_loss: 161.5610\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 151.1121 - val_loss: 161.8582\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.8748 - val_loss: 165.6590\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.9001 - val_loss: 159.4161\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.0127 - val_loss: 163.1652\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.7432 - val_loss: 155.2378\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.6414 - val_loss: 168.5840\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 143.9253 - val_loss: 151.6925\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.6583 - val_loss: 168.7287\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.5804 - val_loss: 148.3547\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.8499 - val_loss: 157.1212\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.0921 - val_loss: 150.9576\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.6243 - val_loss: 143.9802\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 131.0224 - val_loss: 149.2935\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.0560 - val_loss: 146.7117\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 127.0263 - val_loss: 140.0275\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.2815 - val_loss: 149.4173\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 123.4918 - val_loss: 134.2338\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.8302 - val_loss: 138.4805\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 121.6566 - val_loss: 144.7751\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.9279 - val_loss: 137.9791\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.0472 - val_loss: 133.9120\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.3294 - val_loss: 133.9852\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 117.7407 - val_loss: 136.4015\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.3064 - val_loss: 132.5049\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.1757 - val_loss: 125.2780\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.8402 - val_loss: 136.2638\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.9465 - val_loss: 126.7724\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.4602 - val_loss: 137.0596\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.1453 - val_loss: 124.7106\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.9334 - val_loss: 119.9393\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  8  :  120.07896595335626\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  9 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 35753.4141 - val_loss: 10487.7627\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4145.6797 - val_loss: 1811.7462\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1315.3190 - val_loss: 736.5274\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 725.7298 - val_loss: 632.7688\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 622.8580 - val_loss: 589.6266\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 581.2952 - val_loss: 513.8203\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 526.7735 - val_loss: 479.3459\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 492.9080 - val_loss: 447.0264\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 460.5988 - val_loss: 419.2905\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 434.2448 - val_loss: 396.4159\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 414.0968 - val_loss: 378.4616\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 392.7404 - val_loss: 360.7352\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 375.9258 - val_loss: 351.0703\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 363.8156 - val_loss: 341.6769\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 348.2566 - val_loss: 326.2928\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 337.4469 - val_loss: 316.2484\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 325.5386 - val_loss: 305.6192\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 316.6223 - val_loss: 296.2200\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 304.4847 - val_loss: 297.8710\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 295.6379 - val_loss: 288.5638\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 288.2555 - val_loss: 284.7878\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 281.2882 - val_loss: 279.2767\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.5533 - val_loss: 287.7737\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 268.9524 - val_loss: 267.4399\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.9242 - val_loss: 273.0127\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.7996 - val_loss: 267.0689\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.6656 - val_loss: 259.2584\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.2713 - val_loss: 257.0693\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 243.4435 - val_loss: 252.5823\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.4735 - val_loss: 255.5157\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 238.1756 - val_loss: 256.8976\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 233.0592 - val_loss: 247.0532\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.7651 - val_loss: 248.7347\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.0289 - val_loss: 255.5306\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 231.9883 - val_loss: 238.0553\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.7603 - val_loss: 236.4453\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.2042 - val_loss: 242.8355\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 215.2071 - val_loss: 236.9192\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.2316 - val_loss: 232.3238\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 212.3424 - val_loss: 228.4548\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 208.9524 - val_loss: 229.6114\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.2461 - val_loss: 246.1266\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 210.7534 - val_loss: 223.6957\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.5540 - val_loss: 223.2135\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 200.0680 - val_loss: 247.8949\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 204.2335 - val_loss: 218.3454\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197.4346 - val_loss: 216.9368\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.4611 - val_loss: 227.4591\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 192.1921 - val_loss: 214.4208\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 191.0874 - val_loss: 222.4125\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  9  :  184.9840918333197\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  10 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 5487.6831 - val_loss: 1062.6031\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1058.1946 - val_loss: 1160.6776\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 923.2778 - val_loss: 700.7885\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 707.1055 - val_loss: 589.8479\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 594.2967 - val_loss: 545.0508\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 530.6055 - val_loss: 480.3251\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 482.3723 - val_loss: 445.1958\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 445.9563 - val_loss: 416.4211\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 419.7025 - val_loss: 385.1024\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 395.8240 - val_loss: 385.5025\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 375.9044 - val_loss: 355.9080\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.1327 - val_loss: 349.2530\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 346.6228 - val_loss: 345.9766\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 338.4426 - val_loss: 338.8946\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 329.2201 - val_loss: 317.7661\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 315.4160 - val_loss: 338.5547\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 305.8483 - val_loss: 296.7402\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 296.0765 - val_loss: 308.3282\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 285.5755 - val_loss: 283.9098\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.7623 - val_loss: 284.6244\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 271.9572 - val_loss: 283.4627\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 261.9556 - val_loss: 258.4171\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 254.8415 - val_loss: 262.3491\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.4083 - val_loss: 251.4231\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 241.2298 - val_loss: 246.0224\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.0671 - val_loss: 232.6957\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.7875 - val_loss: 234.7028\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 221.4457 - val_loss: 221.6669\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.4729 - val_loss: 217.3837\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 209.0267 - val_loss: 222.4494\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.1034 - val_loss: 214.8928\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 197.9678 - val_loss: 208.8626\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.9566 - val_loss: 192.1678\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 188.7530 - val_loss: 215.6479\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.6565 - val_loss: 192.6283\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.4836 - val_loss: 181.2173\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.1286 - val_loss: 194.9371\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.3918 - val_loss: 180.0691\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.9454 - val_loss: 183.0133\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.7381 - val_loss: 170.3450\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.8987 - val_loss: 164.3398\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.4906 - val_loss: 166.3592\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.7327 - val_loss: 189.8217\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.8563 - val_loss: 147.8826\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 143.5940 - val_loss: 147.0416\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.1779 - val_loss: 147.7192\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 133.9870 - val_loss: 144.1060\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.3954 - val_loss: 140.5518\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.3344 - val_loss: 146.3024\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.2844 - val_loss: 134.5233\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  10  :  128.8841477292691\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  11 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 35415.6055 - val_loss: 19009.4434\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10521.7168 - val_loss: 4741.0444\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2461.1875 - val_loss: 1221.1354\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 867.1283 - val_loss: 612.3074\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 621.3309 - val_loss: 491.4876\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 547.7375 - val_loss: 434.9584\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 487.8249 - val_loss: 396.0195\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 441.4294 - val_loss: 365.6727\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 403.9528 - val_loss: 340.2400\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 374.0861 - val_loss: 324.8202\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 354.3393 - val_loss: 313.4053\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 340.6222 - val_loss: 305.6577\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 331.9086 - val_loss: 299.5720\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.6014 - val_loss: 296.5257\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 321.1866 - val_loss: 294.0484\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 317.3550 - val_loss: 290.7061\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 314.7752 - val_loss: 289.6065\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 311.9659 - val_loss: 287.3575\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.1196 - val_loss: 287.3027\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 308.0076 - val_loss: 285.2348\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 306.1730 - val_loss: 283.9807\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 304.2752 - val_loss: 279.7505\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 302.6643 - val_loss: 279.1142\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 300.7583 - val_loss: 279.3068\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 298.9300 - val_loss: 279.6263\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 297.3658 - val_loss: 274.6923\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.1958 - val_loss: 274.6573\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 293.0685 - val_loss: 273.5823\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 291.0426 - val_loss: 272.4418\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 289.1169 - val_loss: 271.4011\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 287.2821 - val_loss: 269.5365\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 285.0738 - val_loss: 266.6564\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.9519 - val_loss: 265.1224\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 280.8092 - val_loss: 264.1496\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 278.3646 - val_loss: 261.7834\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 276.0585 - val_loss: 259.8722\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.6205 - val_loss: 260.8290\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 270.5005 - val_loss: 257.2468\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.4964 - val_loss: 254.9005\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 264.6729 - val_loss: 252.2209\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.6121 - val_loss: 251.8449\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 256.8407 - val_loss: 248.1892\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 251.9519 - val_loss: 241.3233\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 245.8096 - val_loss: 235.8449\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.1987 - val_loss: 234.0746\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 234.1640 - val_loss: 225.1129\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 227.6734 - val_loss: 223.2399\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.9589 - val_loss: 217.0283\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 215.8488 - val_loss: 207.5770\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.4873 - val_loss: 209.0035\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  11  :  231.83434480313042\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  12 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 612156.6875 - val_loss: 471107.6562\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 376075.8125 - val_loss: 283071.9688\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 219718.2812 - val_loss: 160423.6719\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119685.1719 - val_loss: 82721.2109\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 57991.6133 - val_loss: 36482.1602\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 23062.3535 - val_loss: 12459.9951\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 7431.2700 - val_loss: 4127.2271\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 4111.6357 - val_loss: 3210.0371\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3551.2019 - val_loss: 2743.4070\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2978.8838 - val_loss: 2433.9253\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2590.4795 - val_loss: 2143.1794\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2286.0591 - val_loss: 1871.0555\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2033.6991 - val_loss: 1677.7964\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1849.5134 - val_loss: 1525.7377\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1704.5859 - val_loss: 1401.6532\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1580.1848 - val_loss: 1309.3254\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1481.4622 - val_loss: 1236.7742\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1394.9735 - val_loss: 1162.6251\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1318.9879 - val_loss: 1104.8456\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1253.1920 - val_loss: 1054.3541\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1195.4164 - val_loss: 1001.3719\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1135.6376 - val_loss: 962.0770\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1087.7430 - val_loss: 926.2605\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1036.6151 - val_loss: 887.8871\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 994.3492 - val_loss: 849.4681\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 948.8134 - val_loss: 818.5389\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 917.7293 - val_loss: 787.4487\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 869.6419 - val_loss: 755.7612\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 833.0508 - val_loss: 737.3849\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 797.5967 - val_loss: 701.8359\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 767.5161 - val_loss: 677.5042\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 738.4308 - val_loss: 649.8895\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 703.7450 - val_loss: 627.0104\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 675.4838 - val_loss: 610.4565\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 654.8058 - val_loss: 584.4572\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 622.7516 - val_loss: 560.4711\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 594.6217 - val_loss: 547.2107\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 569.0932 - val_loss: 519.8671\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 545.0001 - val_loss: 501.4059\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 521.5913 - val_loss: 483.4909\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 501.3591 - val_loss: 464.8842\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 476.7245 - val_loss: 450.0421\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 458.4366 - val_loss: 429.4064\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 438.3132 - val_loss: 407.7057\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 419.3025 - val_loss: 401.0228\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 398.0714 - val_loss: 375.7824\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 377.6723 - val_loss: 365.0346\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 361.5607 - val_loss: 349.5383\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 344.6841 - val_loss: 336.7204\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 330.1912 - val_loss: 315.4740\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  12  :  242.9981074371297\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  13 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 601.9769 - val_loss: 550.0784\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 383.6568 - val_loss: 379.2670\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 302.3958 - val_loss: 303.0554\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 242.3486 - val_loss: 249.7977\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 206.5905 - val_loss: 210.4743\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 182.3647 - val_loss: 191.6463\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.9398 - val_loss: 191.3721\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 166.5908 - val_loss: 186.9028\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 165.3928 - val_loss: 169.3694\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 158.0084 - val_loss: 167.0450\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 153.7204 - val_loss: 181.1812\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.2245 - val_loss: 158.8310\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 150.1206 - val_loss: 175.0903\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 149.8972 - val_loss: 171.9933\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 146.2059 - val_loss: 151.7637\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 148.6471 - val_loss: 149.4696\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.3894 - val_loss: 147.9840\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.0938 - val_loss: 159.4523\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.6618 - val_loss: 150.8827\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.8083 - val_loss: 146.2106\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 135.9938 - val_loss: 144.8181\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.7552 - val_loss: 159.7688\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 135.4453 - val_loss: 151.5562\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 135.9827 - val_loss: 150.0720\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.7899 - val_loss: 176.9237\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.8471 - val_loss: 167.7111\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.0634 - val_loss: 139.5117\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.5262 - val_loss: 144.6226\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.5694 - val_loss: 167.2674\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.1146 - val_loss: 164.1237\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.0970 - val_loss: 141.0758\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 125.3036 - val_loss: 139.5818\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.8179 - val_loss: 131.3655\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.2146 - val_loss: 130.0451\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.7336 - val_loss: 128.5390\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.2370 - val_loss: 128.2603\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.8788 - val_loss: 132.8251\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.1878 - val_loss: 132.8493\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.7503 - val_loss: 125.8531\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 121.7020 - val_loss: 124.8818\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.2876 - val_loss: 124.0545\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.9786 - val_loss: 122.9202\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 119.2401 - val_loss: 122.7230\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.5863 - val_loss: 121.5944\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.6652 - val_loss: 121.7599\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 118.5288 - val_loss: 121.8281\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 115.2147 - val_loss: 120.7170\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 117.3145 - val_loss: 120.0113\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.1273 - val_loss: 127.3664\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.0839 - val_loss: 135.1467\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  13  :  121.41491005045343\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  14 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 31585.7441 - val_loss: 14534.9980\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 7134.2129 - val_loss: 2750.3240\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1606.5701 - val_loss: 1062.9901\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1087.8002 - val_loss: 931.3961\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1007.7792 - val_loss: 895.3907\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 967.9751 - val_loss: 882.1027\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 932.9139 - val_loss: 859.0732\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 906.8930 - val_loss: 832.8162\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 882.7759 - val_loss: 809.8400\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 854.7330 - val_loss: 794.5068\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 832.6838 - val_loss: 767.5054\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 808.6421 - val_loss: 750.7083\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 786.5757 - val_loss: 731.0549\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 767.2471 - val_loss: 701.4547\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 743.9653 - val_loss: 684.7563\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 722.4848 - val_loss: 667.8450\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 703.8742 - val_loss: 648.2824\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 683.1655 - val_loss: 632.6250\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 664.6029 - val_loss: 618.9670\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 645.0528 - val_loss: 595.9387\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 627.2107 - val_loss: 578.8378\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 610.6132 - val_loss: 564.4559\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 591.1459 - val_loss: 555.0834\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 573.7837 - val_loss: 536.0940\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 556.7480 - val_loss: 517.7408\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 540.1511 - val_loss: 505.9406\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 525.1653 - val_loss: 489.4861\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 509.3845 - val_loss: 478.5769\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 497.2480 - val_loss: 463.7969\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 480.3248 - val_loss: 451.0033\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 467.1731 - val_loss: 434.5529\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 452.9542 - val_loss: 424.7407\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 443.8019 - val_loss: 421.6454\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 430.7040 - val_loss: 396.4878\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 415.2099 - val_loss: 390.8669\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 405.2563 - val_loss: 382.3766\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 392.7151 - val_loss: 369.8923\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 382.5855 - val_loss: 355.2599\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 371.6788 - val_loss: 349.6888\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 360.9017 - val_loss: 341.8062\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 352.3946 - val_loss: 335.9637\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 341.9012 - val_loss: 321.3333\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 334.0201 - val_loss: 313.8841\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 325.3378 - val_loss: 313.6904\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 317.2366 - val_loss: 300.6441\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 309.1485 - val_loss: 296.0775\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 301.3499 - val_loss: 287.6639\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 295.3337 - val_loss: 284.3138\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 287.4862 - val_loss: 276.8798\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.4673 - val_loss: 267.9785\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  14  :  286.87158378375307\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  15 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 2220.6663 - val_loss: 1241.6593\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1172.2847 - val_loss: 871.7305\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 972.4507 - val_loss: 741.0981\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 833.7165 - val_loss: 668.0831\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 732.0539 - val_loss: 558.3781\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 592.4685 - val_loss: 483.6219\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 489.7525 - val_loss: 420.7546\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 407.8362 - val_loss: 365.4305\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 354.7655 - val_loss: 327.7496\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328.5227 - val_loss: 307.4537\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316.1057 - val_loss: 314.5670\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 312.2699 - val_loss: 284.1228\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.7848 - val_loss: 287.9845\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 283.7137 - val_loss: 273.5656\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 279.8874 - val_loss: 264.6186\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.4106 - val_loss: 261.6633\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 272.5231 - val_loss: 258.0321\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 265.5309 - val_loss: 266.2184\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.1629 - val_loss: 247.4504\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.9629 - val_loss: 252.2350\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 242.5186 - val_loss: 263.8719\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.8940 - val_loss: 239.1100\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 239.1678 - val_loss: 237.2430\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.5629 - val_loss: 240.9463\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 235.3908 - val_loss: 231.0773\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.7386 - val_loss: 226.0313\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 222.2220 - val_loss: 222.7290\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.7584 - val_loss: 222.2542\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.3119 - val_loss: 240.5174\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 216.9793 - val_loss: 216.5388\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 210.3970 - val_loss: 212.7512\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206.5154 - val_loss: 214.7953\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.3618 - val_loss: 215.2177\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.4059 - val_loss: 215.2255\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.2088 - val_loss: 203.9206\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 194.5504 - val_loss: 201.3650\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 194.1182 - val_loss: 201.3576\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 202.0375 - val_loss: 197.3249\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.6733 - val_loss: 224.3898\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.8105 - val_loss: 194.3363\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 184.5329 - val_loss: 190.6703\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.3580 - val_loss: 189.6311\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 190.0670 - val_loss: 192.8655\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 186.5934 - val_loss: 188.5945\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 179.3132 - val_loss: 183.6601\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.2374 - val_loss: 207.9041\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 180.9080 - val_loss: 234.5660\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.8218 - val_loss: 190.1302\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 172.0762 - val_loss: 177.1081\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.6405 - val_loss: 179.4972\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  15  :  161.65294033099858\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  16 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 17123.8984 - val_loss: 8082.0449\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 4933.9424 - val_loss: 4139.6494\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3789.8064 - val_loss: 3345.7273\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2984.8176 - val_loss: 2690.4194\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2493.0796 - val_loss: 2234.6873\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2103.8022 - val_loss: 1850.2819\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1795.9647 - val_loss: 1555.5175\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1570.1932 - val_loss: 1348.8700\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1410.7595 - val_loss: 1195.5756\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1275.0581 - val_loss: 1085.9751\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1175.0714 - val_loss: 999.2277\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1085.9448 - val_loss: 921.5047\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1013.5039 - val_loss: 859.5428\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 950.4712 - val_loss: 802.6047\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 893.2426 - val_loss: 764.6747\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 839.5286 - val_loss: 719.8771\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 796.6550 - val_loss: 683.1504\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 757.2296 - val_loss: 660.4636\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 723.3403 - val_loss: 626.0685\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 694.6658 - val_loss: 609.4380\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 670.7267 - val_loss: 595.8150\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 637.8059 - val_loss: 557.0888\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 620.1624 - val_loss: 545.3937\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 596.6498 - val_loss: 530.1803\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 575.9526 - val_loss: 512.0220\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 557.8669 - val_loss: 500.6369\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 542.0869 - val_loss: 486.0578\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 530.6974 - val_loss: 472.2815\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 513.7603 - val_loss: 465.7179\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 497.2974 - val_loss: 445.5178\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 485.5036 - val_loss: 435.5764\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 472.9461 - val_loss: 429.7444\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 462.8335 - val_loss: 416.0472\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 452.3686 - val_loss: 411.2642\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 442.1228 - val_loss: 399.5033\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 433.0906 - val_loss: 395.9974\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 425.7739 - val_loss: 386.4877\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 416.4330 - val_loss: 380.4157\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 409.8695 - val_loss: 378.0600\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 402.0265 - val_loss: 364.0640\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 396.8712 - val_loss: 359.1249\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 388.3942 - val_loss: 355.1509\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 382.2614 - val_loss: 349.0380\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 374.9049 - val_loss: 350.6355\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.4356 - val_loss: 334.6451\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 363.3492 - val_loss: 331.0817\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 356.7762 - val_loss: 328.0741\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 351.5240 - val_loss: 324.3274\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 346.6069 - val_loss: 313.5509\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 343.6449 - val_loss: 315.6248\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  16  :  339.8710601794114\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  17 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 9723.7998 - val_loss: 6846.7554\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4568.5303 - val_loss: 3199.4124\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2152.4436 - val_loss: 1566.9888\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1152.0967 - val_loss: 874.2487\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 745.4531 - val_loss: 578.9533\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 556.8503 - val_loss: 462.6326\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 481.4525 - val_loss: 399.8565\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 433.6696 - val_loss: 363.5195\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 406.8448 - val_loss: 349.7536\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 387.9347 - val_loss: 335.2358\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 374.1297 - val_loss: 324.2805\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 361.6925 - val_loss: 319.6536\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 351.0420 - val_loss: 310.5291\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343.0832 - val_loss: 304.2241\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335.8136 - val_loss: 304.1801\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328.7813 - val_loss: 301.1079\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 323.1023 - val_loss: 295.3277\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.1013 - val_loss: 295.5703\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 309.6122 - val_loss: 295.8400\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 301.0605 - val_loss: 284.7195\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.0344 - val_loss: 275.3009\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.5320 - val_loss: 269.3896\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 275.3585 - val_loss: 258.8731\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.5944 - val_loss: 254.3163\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.0892 - val_loss: 250.1842\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 255.4496 - val_loss: 238.7433\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.3013 - val_loss: 236.9856\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.4131 - val_loss: 227.4776\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.6105 - val_loss: 228.0302\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.8590 - val_loss: 221.8814\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.0709 - val_loss: 223.1765\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.4137 - val_loss: 218.2888\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.8254 - val_loss: 209.4193\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 205.8761 - val_loss: 208.1603\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.4420 - val_loss: 209.3447\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 199.4663 - val_loss: 207.5970\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.8476 - val_loss: 215.7845\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 192.0401 - val_loss: 198.3051\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.8709 - val_loss: 205.6884\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.2511 - val_loss: 203.0234\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 190.8537 - val_loss: 205.4926\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.3152 - val_loss: 196.3224\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.8058 - val_loss: 197.1616\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.6599 - val_loss: 193.4108\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.8502 - val_loss: 201.7125\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.0480 - val_loss: 193.5237\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.8652 - val_loss: 192.2890\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 176.6647 - val_loss: 197.3036\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.0329 - val_loss: 192.2781\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.4644 - val_loss: 187.3798\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  17  :  180.73146094192978\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  18 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 150378.1250 - val_loss: 94911.2266\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 64900.8594 - val_loss: 38911.2734\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 25257.9062 - val_loss: 13210.7139\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7971.8740 - val_loss: 3683.5112\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2281.2217 - val_loss: 1455.2603\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1272.8599 - val_loss: 1304.0382\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1168.3788 - val_loss: 1213.5215\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1078.7806 - val_loss: 1107.7290\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 995.3713 - val_loss: 1030.4427\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 918.3441 - val_loss: 961.2064\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 840.8574 - val_loss: 891.9539\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 772.8439 - val_loss: 825.0153\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 706.3183 - val_loss: 766.8480\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 647.3490 - val_loss: 714.1161\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 593.9301 - val_loss: 662.2352\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 544.9263 - val_loss: 612.8299\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 500.7652 - val_loss: 566.2502\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 459.4349 - val_loss: 528.1068\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 426.7542 - val_loss: 490.6126\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 394.6071 - val_loss: 458.4436\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 367.2042 - val_loss: 427.6739\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343.0060 - val_loss: 400.9604\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 321.6326 - val_loss: 376.7027\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.4089 - val_loss: 354.9303\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.8116 - val_loss: 334.7890\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.3924 - val_loss: 315.8925\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.1821 - val_loss: 299.8078\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 242.6387 - val_loss: 283.9268\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 231.2833 - val_loss: 270.7231\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 221.4037 - val_loss: 258.4143\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.5727 - val_loss: 246.5672\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.4413 - val_loss: 239.0160\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 197.3273 - val_loss: 228.2164\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.5545 - val_loss: 222.3953\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.5325 - val_loss: 213.6736\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.0627 - val_loss: 206.7004\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.5793 - val_loss: 200.4591\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.3237 - val_loss: 194.9918\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.0423 - val_loss: 189.1860\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.2563 - val_loss: 185.3328\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.0396 - val_loss: 182.3805\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.8142 - val_loss: 176.0050\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.4085 - val_loss: 174.8573\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.7733 - val_loss: 170.2257\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 145.2176 - val_loss: 166.9185\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 143.1925 - val_loss: 165.6634\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.4719 - val_loss: 160.4843\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.0473 - val_loss: 160.7300\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.2881 - val_loss: 156.8218\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 135.6906 - val_loss: 155.2588\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  18  :  151.97515487601933\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  19 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 10475.8643 - val_loss: 6648.7822\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 5096.1919 - val_loss: 3403.3665\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2965.0466 - val_loss: 2189.3889\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2057.2014 - val_loss: 1610.0682\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1547.4363 - val_loss: 1242.9717\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1184.3577 - val_loss: 938.4961\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 852.9159 - val_loss: 672.8399\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 559.6331 - val_loss: 478.5133\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 399.7359 - val_loss: 412.0404\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 353.3980 - val_loss: 369.4196\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 320.2376 - val_loss: 331.3683\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.4741 - val_loss: 308.5036\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.5793 - val_loss: 291.9849\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.6134 - val_loss: 281.2263\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 255.8224 - val_loss: 269.1207\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.7676 - val_loss: 261.4507\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.8357 - val_loss: 254.9119\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.9121 - val_loss: 251.2345\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 228.6291 - val_loss: 247.7680\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.0504 - val_loss: 241.7437\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.2512 - val_loss: 238.2804\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 216.5868 - val_loss: 234.1371\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.9171 - val_loss: 229.3206\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 210.7854 - val_loss: 229.5376\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.6499 - val_loss: 228.7310\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 206.6266 - val_loss: 222.2024\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 204.5596 - val_loss: 221.4462\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.5089 - val_loss: 222.3858\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 200.6250 - val_loss: 215.8691\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.3237 - val_loss: 215.7709\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.8723 - val_loss: 213.5852\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.4733 - val_loss: 213.0182\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 195.4738 - val_loss: 210.1373\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.8883 - val_loss: 209.8393\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 192.3973 - val_loss: 207.5193\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.0677 - val_loss: 206.0636\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.6633 - val_loss: 204.0341\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 188.4983 - val_loss: 204.2635\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.0484 - val_loss: 203.1940\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.4872 - val_loss: 203.6715\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.4831 - val_loss: 200.0858\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.3227 - val_loss: 199.7613\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 181.6928 - val_loss: 199.2626\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.1467 - val_loss: 200.9579\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.5588 - val_loss: 192.8306\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.0353 - val_loss: 197.2594\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.3209 - val_loss: 193.1426\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.5907 - val_loss: 194.1449\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.5428 - val_loss: 195.4416\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 173.5743 - val_loss: 192.2621\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  19  :  174.86130198726357\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  20 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 75715.4297 - val_loss: 38376.5977\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 21875.0996 - val_loss: 9654.6172\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5729.6284 - val_loss: 3084.8660\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2499.0098 - val_loss: 1812.2557\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1783.4309 - val_loss: 1402.6721\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1430.8696 - val_loss: 1112.8544\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1167.9243 - val_loss: 925.1542\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1001.7769 - val_loss: 787.1340\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 871.5712 - val_loss: 692.6389\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 765.8287 - val_loss: 626.8957\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 690.4108 - val_loss: 574.9249\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 625.0744 - val_loss: 535.6663\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 576.4679 - val_loss: 506.4944\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 537.0386 - val_loss: 482.8663\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 506.3358 - val_loss: 463.6660\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 480.0128 - val_loss: 449.2701\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 458.3782 - val_loss: 435.8173\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 439.5981 - val_loss: 421.8845\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 421.3448 - val_loss: 415.4702\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 406.6149 - val_loss: 401.8981\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 392.8346 - val_loss: 393.3956\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 380.4216 - val_loss: 386.2610\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 368.4551 - val_loss: 373.9384\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 357.9944 - val_loss: 365.7648\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 348.4060 - val_loss: 360.3364\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 338.7267 - val_loss: 348.4607\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.5794 - val_loss: 344.1202\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.0020 - val_loss: 332.5252\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.0291 - val_loss: 323.4177\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 301.5241 - val_loss: 316.4531\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.7188 - val_loss: 309.2193\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 284.7254 - val_loss: 300.9599\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.6693 - val_loss: 294.7105\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.7132 - val_loss: 284.4669\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.5861 - val_loss: 276.3312\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 252.9834 - val_loss: 272.3555\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.7665 - val_loss: 265.8733\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.0982 - val_loss: 257.3560\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 233.5664 - val_loss: 250.0103\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.0628 - val_loss: 243.5814\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.7350 - val_loss: 238.9861\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 215.9382 - val_loss: 231.8391\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 210.5946 - val_loss: 227.8607\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.5420 - val_loss: 222.7729\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 200.6545 - val_loss: 220.2307\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.1196 - val_loss: 213.6940\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.2310 - val_loss: 212.6415\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.3526 - val_loss: 207.5923\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.1716 - val_loss: 201.6582\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.2591 - val_loss: 200.2277\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  20  :  188.29028254974568\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  21 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 86286.2109 - val_loss: 51036.7695\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 33871.0977 - val_loss: 20224.2070\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13835.2637 - val_loss: 8736.5693\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6134.7964 - val_loss: 3900.0254\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2732.3267 - val_loss: 1718.7751\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1232.2584 - val_loss: 883.0162\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 725.2150 - val_loss: 661.3353\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 605.9528 - val_loss: 626.8020\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 587.0405 - val_loss: 611.8663\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 571.9097 - val_loss: 589.6427\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 554.4569 - val_loss: 563.1388\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 534.6055 - val_loss: 538.9116\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 515.8144 - val_loss: 519.2739\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 492.6495 - val_loss: 498.0467\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 470.5674 - val_loss: 477.6528\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 446.8271 - val_loss: 454.4862\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 424.4383 - val_loss: 435.1626\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 400.6680 - val_loss: 408.3203\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 371.2005 - val_loss: 379.6879\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335.8314 - val_loss: 351.0667\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 311.3857 - val_loss: 325.1786\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 291.0967 - val_loss: 309.4037\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 274.7550 - val_loss: 283.7889\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.9020 - val_loss: 271.3175\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.2849 - val_loss: 252.3588\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.7720 - val_loss: 234.6697\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.0631 - val_loss: 238.5283\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.3556 - val_loss: 212.6500\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.3557 - val_loss: 213.6005\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 187.7513 - val_loss: 195.3417\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.1444 - val_loss: 192.7614\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.9408 - val_loss: 180.7401\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.7817 - val_loss: 181.8832\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.7028 - val_loss: 170.5193\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 158.5849 - val_loss: 167.3482\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4187 - val_loss: 172.8525\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.2986 - val_loss: 169.6374\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.6519 - val_loss: 157.7457\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 143.8931 - val_loss: 157.8935\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.0262 - val_loss: 151.4827\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.8638 - val_loss: 151.7049\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.0351 - val_loss: 147.3262\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.9694 - val_loss: 148.8288\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.7210 - val_loss: 148.7449\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.7064 - val_loss: 144.7301\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 130.6584 - val_loss: 143.6494\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.0573 - val_loss: 149.0776\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.0824 - val_loss: 145.6307\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.6026 - val_loss: 141.0049\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.8565 - val_loss: 145.9799\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  21  :  123.2596777805469\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  22 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 369660.8438 - val_loss: 309831.1250\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 271403.8750 - val_loss: 229151.1094\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202224.0156 - val_loss: 171791.6875\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152371.2188 - val_loss: 130424.8125\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115925.4609 - val_loss: 99760.0547\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88465.0391 - val_loss: 75689.8672\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66305.6484 - val_loss: 55749.7617\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 47852.2695 - val_loss: 38917.3906\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 32352.0605 - val_loss: 25077.3457\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 19984.9102 - val_loss: 14473.8242\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10987.2256 - val_loss: 7347.3105\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5322.8315 - val_loss: 3347.6946\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2386.4458 - val_loss: 1549.9625\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1205.5201 - val_loss: 927.8510\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 817.5927 - val_loss: 780.0336\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 736.0800 - val_loss: 746.8505\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 709.8781 - val_loss: 733.0770\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 694.6007 - val_loss: 719.3857\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 681.5324 - val_loss: 705.8126\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 668.5663 - val_loss: 692.5026\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 656.2691 - val_loss: 680.0868\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 644.2194 - val_loss: 667.1472\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 632.1283 - val_loss: 655.6337\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 621.4156 - val_loss: 644.8550\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 611.0128 - val_loss: 634.0678\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 601.0798 - val_loss: 623.2708\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 591.7401 - val_loss: 612.7949\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 582.3810 - val_loss: 602.5392\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 571.4311 - val_loss: 592.2073\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 561.6703 - val_loss: 582.6690\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 552.8124 - val_loss: 572.7757\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 543.3384 - val_loss: 563.1675\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 533.8495 - val_loss: 553.5682\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 524.7084 - val_loss: 544.2903\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 515.9205 - val_loss: 534.9148\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 507.4528 - val_loss: 525.8779\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 498.2421 - val_loss: 516.8793\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 489.4769 - val_loss: 508.7532\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 481.4679 - val_loss: 499.7025\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 473.4308 - val_loss: 491.4361\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 464.7002 - val_loss: 482.8589\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 456.8093 - val_loss: 474.4960\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 448.9497 - val_loss: 466.3937\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 440.9056 - val_loss: 459.0396\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 433.8311 - val_loss: 451.4045\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 426.1059 - val_loss: 444.7912\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 419.8996 - val_loss: 436.5881\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 411.7930 - val_loss: 429.5941\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 404.4660 - val_loss: 423.0532\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.8068 - val_loss: 416.1648\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  22  :  363.9727821807131\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  23 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 3196.9028 - val_loss: 2061.5015\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1967.8319 - val_loss: 1409.7241\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1379.5341 - val_loss: 1011.8594\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 990.9563 - val_loss: 768.0129\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 789.1359 - val_loss: 639.3072\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 671.7562 - val_loss: 551.8456\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 582.8419 - val_loss: 478.7668\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 509.6284 - val_loss: 425.5083\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 449.0451 - val_loss: 378.3908\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 402.9749 - val_loss: 346.6754\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 368.5008 - val_loss: 324.0638\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 338.4794 - val_loss: 304.7520\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.2390 - val_loss: 287.2909\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 295.9182 - val_loss: 271.0680\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 276.4808 - val_loss: 265.0610\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.9092 - val_loss: 255.3136\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 252.1749 - val_loss: 248.8105\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 242.3178 - val_loss: 243.8806\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.6629 - val_loss: 238.4169\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.4816 - val_loss: 233.0986\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.9787 - val_loss: 234.7765\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.4887 - val_loss: 221.4714\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.4386 - val_loss: 223.5070\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 199.9669 - val_loss: 215.2304\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 195.5886 - val_loss: 218.1049\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.7348 - val_loss: 206.4835\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.3951 - val_loss: 224.1384\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.0191 - val_loss: 201.1839\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.4306 - val_loss: 207.1894\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.1809 - val_loss: 195.9660\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.2295 - val_loss: 193.8548\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.2957 - val_loss: 194.5141\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.1289 - val_loss: 184.3129\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.5367 - val_loss: 183.0080\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.7025 - val_loss: 186.7935\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 159.1132 - val_loss: 173.4707\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.6715 - val_loss: 172.6443\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.7179 - val_loss: 174.6419\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.2667 - val_loss: 163.7619\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.7809 - val_loss: 159.3968\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.0821 - val_loss: 156.4378\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.9049 - val_loss: 154.2006\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 142.1305 - val_loss: 156.3949\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.2213 - val_loss: 154.7856\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.5343 - val_loss: 145.7185\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 133.1651 - val_loss: 141.6684\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.6260 - val_loss: 144.4654\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.7222 - val_loss: 148.5468\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 126.6488 - val_loss: 140.7639\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.2008 - val_loss: 135.4796\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  23  :  127.02445876256976\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  24 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 130826.8203 - val_loss: 93187.5859\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 70678.2344 - val_loss: 45570.1602\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 31574.3848 - val_loss: 16145.4531\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9827.6270 - val_loss: 4631.8301\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3478.6907 - val_loss: 3283.3879\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2871.2395 - val_loss: 2998.6057\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2490.9023 - val_loss: 2518.4360\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2155.1582 - val_loss: 2202.5925\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1903.7366 - val_loss: 1953.1396\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1689.0536 - val_loss: 1739.9327\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1504.8116 - val_loss: 1559.5061\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1345.0023 - val_loss: 1401.7458\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1219.5852 - val_loss: 1272.5192\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1109.8049 - val_loss: 1156.9790\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1014.0266 - val_loss: 1060.3318\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 935.1251 - val_loss: 977.7009\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 867.7592 - val_loss: 905.1523\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 807.6367 - val_loss: 842.7952\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 757.0976 - val_loss: 788.0524\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 712.5101 - val_loss: 740.4630\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 673.1491 - val_loss: 695.0887\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 638.7037 - val_loss: 657.0542\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 608.7596 - val_loss: 621.6692\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 579.4194 - val_loss: 591.4342\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 553.6456 - val_loss: 563.6568\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 531.0812 - val_loss: 537.4213\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 509.1726 - val_loss: 513.4877\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 492.2919 - val_loss: 490.9577\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 471.6347 - val_loss: 472.4426\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 455.8872 - val_loss: 454.1270\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 440.3905 - val_loss: 437.9013\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 425.8384 - val_loss: 421.5419\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 413.1179 - val_loss: 408.6104\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 400.4285 - val_loss: 391.3062\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 387.0898 - val_loss: 380.4920\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.7511 - val_loss: 368.4663\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 364.9808 - val_loss: 354.4626\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 354.0034 - val_loss: 344.4856\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343.1202 - val_loss: 331.7715\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.6461 - val_loss: 320.9986\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 321.3416 - val_loss: 310.7709\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.7448 - val_loss: 301.7303\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 298.9604 - val_loss: 285.2862\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.9310 - val_loss: 278.0081\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 272.1079 - val_loss: 263.0011\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.7315 - val_loss: 250.6648\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 246.4032 - val_loss: 242.4169\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.9457 - val_loss: 236.0961\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.3778 - val_loss: 235.2871\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.6771 - val_loss: 236.2447\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  24  :  242.27140397411023\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  25 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 413.4238 - val_loss: 328.1794\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 313.5638 - val_loss: 266.2892\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 296.9465 - val_loss: 265.9733\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.0781 - val_loss: 260.9794\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.3015 - val_loss: 251.9579\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.3325 - val_loss: 234.0355\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.0152 - val_loss: 238.1818\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.1335 - val_loss: 206.1392\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.2065 - val_loss: 209.9968\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.1781 - val_loss: 209.8783\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.1430 - val_loss: 189.8189\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.7311 - val_loss: 177.5812\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.9267 - val_loss: 171.9827\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.7391 - val_loss: 166.0570\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.1980 - val_loss: 147.4879\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.6923 - val_loss: 142.6758\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.1867 - val_loss: 136.1343\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.9508 - val_loss: 131.8585\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.7543 - val_loss: 122.5282\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.0725 - val_loss: 120.6966\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.7517 - val_loss: 118.1303\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.7058 - val_loss: 126.8662\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 110.9564 - val_loss: 120.0722\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.5045 - val_loss: 115.8495\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.6460 - val_loss: 121.9500\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.9146 - val_loss: 115.0639\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.3422 - val_loss: 121.4040\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.1796 - val_loss: 128.3166\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.7227 - val_loss: 129.7961\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 105.6302 - val_loss: 122.1647\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.4446 - val_loss: 112.5195\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.8877 - val_loss: 123.8310\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.5698 - val_loss: 115.7418\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.5258 - val_loss: 119.4047\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.3104 - val_loss: 114.2301\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.3712 - val_loss: 114.5645\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2598 - val_loss: 120.5233\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.9715 - val_loss: 112.7531\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.6233 - val_loss: 122.8194\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.4224 - val_loss: 119.7066\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.9651 - val_loss: 112.1223\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.3935 - val_loss: 112.3910\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 97.5524 - val_loss: 106.3885\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.9560 - val_loss: 111.3984\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.5885 - val_loss: 111.8523\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.4136 - val_loss: 105.7757\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.9136 - val_loss: 116.1365\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.9425 - val_loss: 110.7791\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.1366 - val_loss: 113.0802\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.3325 - val_loss: 110.4371\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  25  :  102.40883506955059\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  26 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 10688.2930 - val_loss: 5467.7974\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3059.0623 - val_loss: 1536.3472\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1172.9073 - val_loss: 1062.6056\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1028.4086 - val_loss: 939.3177\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 889.8306 - val_loss: 821.4012\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 773.2708 - val_loss: 729.2369\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 684.0660 - val_loss: 647.9427\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 607.9526 - val_loss: 585.1738\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 547.1165 - val_loss: 535.1924\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 494.8951 - val_loss: 498.6640\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 450.4055 - val_loss: 465.6498\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 414.6708 - val_loss: 439.7664\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 389.5458 - val_loss: 418.5551\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 365.5823 - val_loss: 406.9620\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 347.8510 - val_loss: 393.1287\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 330.8740 - val_loss: 376.6430\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 315.5936 - val_loss: 367.1094\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.3003 - val_loss: 357.5070\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.0632 - val_loss: 351.2711\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.7669 - val_loss: 337.1316\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.4627 - val_loss: 328.5224\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.9977 - val_loss: 322.1835\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.9216 - val_loss: 315.6375\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.1610 - val_loss: 307.9885\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.7064 - val_loss: 299.3513\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.0142 - val_loss: 292.2560\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.3544 - val_loss: 285.8948\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.2746 - val_loss: 283.6025\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219.4703 - val_loss: 275.3952\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.7562 - val_loss: 272.3076\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.4910 - val_loss: 265.7682\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.3542 - val_loss: 263.0364\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.0944 - val_loss: 257.0020\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.9754 - val_loss: 254.9424\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.1360 - val_loss: 249.2136\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.2822 - val_loss: 245.1379\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.5484 - val_loss: 241.1810\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192.6873 - val_loss: 241.4565\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.4315 - val_loss: 236.4621\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.4333 - val_loss: 232.2434\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 185.9419 - val_loss: 230.0940\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.6571 - val_loss: 230.2929\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.2603 - val_loss: 223.5515\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.3168 - val_loss: 226.2641\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.0827 - val_loss: 219.2798\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.1830 - val_loss: 220.7606\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.9279 - val_loss: 215.8502\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.6523 - val_loss: 215.9868\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.9587 - val_loss: 212.7061\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.7512 - val_loss: 210.5106\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  26  :  180.21068399891215\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1627.5686 - val_loss: 970.4719\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 917.5154 - val_loss: 798.7977\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 775.5376 - val_loss: 598.1681\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 675.9637 - val_loss: 566.3723\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 617.2377 - val_loss: 522.9971\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 582.9575 - val_loss: 500.9693\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 548.9259 - val_loss: 471.6645\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 524.5263 - val_loss: 456.7041\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 505.6008 - val_loss: 423.5307\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 478.0779 - val_loss: 404.5174\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 460.0673 - val_loss: 407.5269\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 436.8070 - val_loss: 375.8245\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.7401 - val_loss: 363.0424\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 402.2596 - val_loss: 348.1378\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 393.8970 - val_loss: 351.5402\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 378.4367 - val_loss: 346.1468\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 367.9134 - val_loss: 318.9941\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 353.2962 - val_loss: 310.9428\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 347.3046 - val_loss: 302.6038\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 337.2088 - val_loss: 312.1913\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 323.9572 - val_loss: 285.4812\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.4055 - val_loss: 304.7410\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 317.9381 - val_loss: 311.0273\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.7975 - val_loss: 278.3857\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.9108 - val_loss: 260.3136\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.5441 - val_loss: 254.0393\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.6984 - val_loss: 248.2280\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 273.6184 - val_loss: 247.8750\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.8667 - val_loss: 239.5352\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 262.4935 - val_loss: 245.6227\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 261.3598 - val_loss: 240.4240\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.3659 - val_loss: 232.1828\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.7960 - val_loss: 233.3347\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 245.4091 - val_loss: 244.3550\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.8711 - val_loss: 216.5084\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.7372 - val_loss: 210.0114\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 231.3371 - val_loss: 206.8026\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.0636 - val_loss: 210.1587\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.2892 - val_loss: 212.8757\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.9803 - val_loss: 207.3250\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.4026 - val_loss: 195.0421\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.4604 - val_loss: 190.9387\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.7207 - val_loss: 188.2554\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.5939 - val_loss: 182.6822\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.5847 - val_loss: 204.7965\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.6227 - val_loss: 182.3242\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.0553 - val_loss: 177.9221\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.2670 - val_loss: 181.5680\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.3400 - val_loss: 190.5440\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.3640 - val_loss: 174.9580\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  27  :  167.61447864279486\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 6811.9492 - val_loss: 618.4719\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 958.6155 - val_loss: 1228.0334\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 751.2432 - val_loss: 529.3832\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 606.9983 - val_loss: 517.5985\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 547.7742 - val_loss: 533.8525\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 522.5817 - val_loss: 474.2729\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 495.2698 - val_loss: 486.0931\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 477.8993 - val_loss: 444.0159\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 453.7920 - val_loss: 454.9574\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 434.5294 - val_loss: 413.5717\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 412.5570 - val_loss: 419.7401\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.7686 - val_loss: 388.1519\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 378.6836 - val_loss: 386.4653\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 363.5603 - val_loss: 359.0609\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 347.9968 - val_loss: 354.0032\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 336.8198 - val_loss: 351.7283\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 321.2623 - val_loss: 329.9922\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 309.0518 - val_loss: 326.7301\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 295.9137 - val_loss: 299.4042\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 283.6539 - val_loss: 298.8241\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.7762 - val_loss: 294.0727\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 265.4760 - val_loss: 268.0096\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.5918 - val_loss: 269.1617\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.7791 - val_loss: 259.8015\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 237.4603 - val_loss: 260.9477\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.9635 - val_loss: 230.3801\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.8395 - val_loss: 231.9122\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0849 - val_loss: 218.6806\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206.7086 - val_loss: 221.0681\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.2350 - val_loss: 201.6850\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.6703 - val_loss: 229.3995\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.5348 - val_loss: 189.2368\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.6863 - val_loss: 197.2101\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.4219 - val_loss: 178.8176\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 176.5776 - val_loss: 189.0512\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.5510 - val_loss: 174.0601\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.6320 - val_loss: 183.3223\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.2340 - val_loss: 167.4140\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.9404 - val_loss: 164.2487\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.4606 - val_loss: 180.2959\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.4516 - val_loss: 156.4245\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.4478 - val_loss: 155.4586\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.8474 - val_loss: 183.4629\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.1604 - val_loss: 165.0230\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.3941 - val_loss: 163.6411\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.1329 - val_loss: 162.4981\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.5820 - val_loss: 146.4921\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.9927 - val_loss: 141.5127\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.4005 - val_loss: 155.2404\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.2017 - val_loss: 141.8670\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  28  :  135.96502581474311\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 2865.8684 - val_loss: 2259.7449\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2106.0674 - val_loss: 1730.1881\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1586.3835 - val_loss: 1336.9714\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1204.2157 - val_loss: 1033.9424\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 918.5588 - val_loss: 818.6078\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 695.0242 - val_loss: 646.7917\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 537.9304 - val_loss: 528.8541\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 418.3635 - val_loss: 502.7812\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 368.1502 - val_loss: 420.8704\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 341.2039 - val_loss: 415.3856\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.1747 - val_loss: 382.7658\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 332.0523 - val_loss: 375.2260\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.5489 - val_loss: 325.5949\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.7589 - val_loss: 315.5249\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 273.1254 - val_loss: 301.8222\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 265.2016 - val_loss: 294.1346\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 274.3558 - val_loss: 285.8642\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 250.7318 - val_loss: 271.6357\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.5567 - val_loss: 266.0613\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.5251 - val_loss: 277.7714\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 230.3337 - val_loss: 266.7848\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.3770 - val_loss: 243.4865\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219.5416 - val_loss: 237.2791\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.6204 - val_loss: 227.2822\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 209.7380 - val_loss: 224.5934\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.4217 - val_loss: 215.7440\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.7340 - val_loss: 218.6191\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.7963 - val_loss: 215.2069\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.5715 - val_loss: 205.1008\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.4237 - val_loss: 216.8777\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.2921 - val_loss: 220.2408\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.5118 - val_loss: 194.5505\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.7250 - val_loss: 183.1543\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.2635 - val_loss: 178.4336\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.5397 - val_loss: 175.6680\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.3044 - val_loss: 173.2795\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.7811 - val_loss: 182.3544\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.3380 - val_loss: 183.8486\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.3842 - val_loss: 169.0692\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.0432 - val_loss: 159.4511\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.2234 - val_loss: 157.6975\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.1872 - val_loss: 153.7850\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.2088 - val_loss: 152.8195\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.0320 - val_loss: 149.8793\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.2119 - val_loss: 151.4345\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.4806 - val_loss: 167.2602\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.0287 - val_loss: 149.0983\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 142.9998 - val_loss: 161.1543\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.9211 - val_loss: 142.8645\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.9290 - val_loss: 142.8986\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  29  :  134.57321559860216\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 14834.9766 - val_loss: 3754.7661\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1994.0786 - val_loss: 734.7147\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 813.8481 - val_loss: 861.6243\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 739.3439 - val_loss: 630.8499\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 608.8913 - val_loss: 539.1760\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 557.0277 - val_loss: 499.3908\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 510.2799 - val_loss: 472.9813\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 472.8031 - val_loss: 446.1560\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 438.2587 - val_loss: 417.6225\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 407.2385 - val_loss: 395.3122\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 381.1653 - val_loss: 379.7404\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.2528 - val_loss: 358.4483\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 334.7532 - val_loss: 344.6834\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.7969 - val_loss: 338.0464\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.4052 - val_loss: 317.9121\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.4829 - val_loss: 303.9732\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.4008 - val_loss: 288.4786\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.0286 - val_loss: 278.1352\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.0959 - val_loss: 268.0213\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 224.3572 - val_loss: 257.8135\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 215.3032 - val_loss: 248.4153\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.6447 - val_loss: 241.6937\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.8737 - val_loss: 233.1195\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.9981 - val_loss: 224.2751\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.8633 - val_loss: 216.5505\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.1117 - val_loss: 213.7827\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.6868 - val_loss: 207.1124\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.6950 - val_loss: 200.9900\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.1950 - val_loss: 195.3109\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.4911 - val_loss: 193.9320\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.6047 - val_loss: 188.7439\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.8650 - val_loss: 183.4779\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.3438 - val_loss: 181.0964\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.9062 - val_loss: 174.7965\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.2723 - val_loss: 172.7209\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.3576 - val_loss: 167.7971\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.5621 - val_loss: 168.6501\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.3277 - val_loss: 164.7096\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.2946 - val_loss: 162.7379\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.5219 - val_loss: 156.6065\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.4649 - val_loss: 160.5242\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.9625 - val_loss: 152.7077\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.1128 - val_loss: 159.0379\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0146 - val_loss: 147.9135\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2581 - val_loss: 151.6049\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.9952 - val_loss: 144.0236\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.2283 - val_loss: 150.8484\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.4182 - val_loss: 144.4104\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.8187 - val_loss: 146.5675\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.9663 - val_loss: 141.5995\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  30  :  115.51201433086537\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 4839.1968 - val_loss: 2941.0076\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1909.6270 - val_loss: 1470.4208\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1055.1942 - val_loss: 931.5224\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 695.6941 - val_loss: 669.6146\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 515.7509 - val_loss: 511.3650\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 406.9554 - val_loss: 416.3516\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 343.4714 - val_loss: 355.1581\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304.5376 - val_loss: 316.1060\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 279.6180 - val_loss: 291.4591\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.4485 - val_loss: 273.9882\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.0320 - val_loss: 262.8310\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 250.0413 - val_loss: 255.6193\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 246.9624 - val_loss: 249.2783\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.6187 - val_loss: 245.2372\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.1842 - val_loss: 242.4238\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.2711 - val_loss: 240.3871\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 241.4879 - val_loss: 238.9441\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.9128 - val_loss: 238.1105\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.4783 - val_loss: 236.7748\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.1133 - val_loss: 235.7474\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.5422 - val_loss: 235.5821\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.1972 - val_loss: 235.2946\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.7590 - val_loss: 234.1778\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.3093 - val_loss: 234.0300\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 237.8306 - val_loss: 233.5432\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.3607 - val_loss: 233.1553\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.9842 - val_loss: 232.4025\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.5521 - val_loss: 232.3120\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.0780 - val_loss: 231.7456\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.7108 - val_loss: 231.4465\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.1925 - val_loss: 230.6520\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.7850 - val_loss: 230.1506\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.1870 - val_loss: 230.1223\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.6246 - val_loss: 229.7385\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.9221 - val_loss: 229.2798\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.3519 - val_loss: 228.5606\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.4818 - val_loss: 228.4689\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.3689 - val_loss: 228.1352\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.6942 - val_loss: 226.6944\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.0517 - val_loss: 224.0238\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 223.4676 - val_loss: 222.0448\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.1596 - val_loss: 221.2264\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.5698 - val_loss: 221.6112\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.7799 - val_loss: 221.7624\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.9870 - val_loss: 223.8888\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.6482 - val_loss: 219.1172\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206.1830 - val_loss: 218.2070\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.3230 - val_loss: 216.0598\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.5449 - val_loss: 216.1048\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.8898 - val_loss: 213.1604\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  31  :  198.48098847663852\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 15460.3984 - val_loss: 6904.8970\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5763.5010 - val_loss: 4226.9170\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2883.0134 - val_loss: 2330.3718\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1450.5923 - val_loss: 1149.3918\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 849.3946 - val_loss: 891.6642\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 655.0472 - val_loss: 689.4355\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 570.5338 - val_loss: 577.3354\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 487.2459 - val_loss: 537.6838\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 412.1808 - val_loss: 461.7686\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.4620 - val_loss: 365.0309\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 295.4345 - val_loss: 331.6641\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.4581 - val_loss: 317.2456\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.8653 - val_loss: 274.7211\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.5983 - val_loss: 244.7213\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.7876 - val_loss: 230.4942\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.1476 - val_loss: 217.8226\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.7013 - val_loss: 217.6230\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.4551 - val_loss: 221.9525\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.8176 - val_loss: 196.3425\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.0269 - val_loss: 184.5519\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.9203 - val_loss: 175.3300\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.9200 - val_loss: 175.0966\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.0144 - val_loss: 169.0474\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.3405 - val_loss: 166.4624\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.0636 - val_loss: 176.2833\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.3745 - val_loss: 179.6989\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.2412 - val_loss: 154.0109\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.1400 - val_loss: 151.5155\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.6957 - val_loss: 149.0636\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.8044 - val_loss: 155.3072\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.3156 - val_loss: 152.5903\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 113.8007 - val_loss: 142.3954\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.3140 - val_loss: 143.0478\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.6171 - val_loss: 133.0069\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.0460 - val_loss: 123.6960\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.7366 - val_loss: 121.4143\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.8321 - val_loss: 144.6257\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.6350 - val_loss: 122.2028\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.8035 - val_loss: 131.1077\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.8131 - val_loss: 120.0719\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.3473 - val_loss: 110.3882\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.0618 - val_loss: 105.1870\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.9421 - val_loss: 104.1470\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.0016 - val_loss: 98.9821\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8533 - val_loss: 97.9765\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.9693 - val_loss: 121.3887\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.1053 - val_loss: 104.1099\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.1428 - val_loss: 98.9197\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.3658 - val_loss: 94.1231\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.5957 - val_loss: 96.8638\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  32  :  93.31532784995119\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 16507.0254 - val_loss: 3722.1550\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2155.0837 - val_loss: 2128.9529\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1860.8779 - val_loss: 1553.8733\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1280.8177 - val_loss: 1190.0332\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1088.2059 - val_loss: 1040.3077\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 979.5892 - val_loss: 945.9854\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 894.5294 - val_loss: 856.1703\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 821.7003 - val_loss: 780.5152\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 750.6433 - val_loss: 704.0986\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 687.7062 - val_loss: 647.0730\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 633.3090 - val_loss: 579.8064\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 587.2469 - val_loss: 537.5928\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 536.1908 - val_loss: 497.2897\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 498.2988 - val_loss: 458.3698\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 464.5290 - val_loss: 423.2274\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 436.6507 - val_loss: 400.8314\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 408.1612 - val_loss: 374.1398\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 386.4247 - val_loss: 347.2225\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 365.6029 - val_loss: 331.4008\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 345.9898 - val_loss: 318.5804\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.8748 - val_loss: 303.1473\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.5214 - val_loss: 303.3936\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 305.7430 - val_loss: 278.7209\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.6037 - val_loss: 268.5536\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.4287 - val_loss: 264.6087\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 266.8042 - val_loss: 250.0796\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.1811 - val_loss: 254.8673\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 251.2609 - val_loss: 235.7701\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 243.2041 - val_loss: 233.4405\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.2651 - val_loss: 235.4188\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 228.8003 - val_loss: 227.0771\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.2074 - val_loss: 217.9599\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.2631 - val_loss: 210.9650\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 216.5019 - val_loss: 207.7572\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.2223 - val_loss: 211.8015\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.0170 - val_loss: 204.0467\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 201.8292 - val_loss: 199.6733\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197.7098 - val_loss: 204.9576\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 196.0835 - val_loss: 214.4057\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.4782 - val_loss: 193.3403\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.5313 - val_loss: 189.3655\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.7483 - val_loss: 194.9975\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.1794 - val_loss: 188.8919\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.5087 - val_loss: 209.0419\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.4340 - val_loss: 189.2657\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.4124 - val_loss: 187.5972\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.9922 - val_loss: 178.5558\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.8438 - val_loss: 185.4328\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.1593 - val_loss: 194.6822\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0122 - val_loss: 175.1070\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  33  :  176.9305090623244\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 11284.6455 - val_loss: 3093.4246\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3424.4487 - val_loss: 3104.4050\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2534.0369 - val_loss: 2065.2263\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1914.6699 - val_loss: 1475.0680\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1354.4241 - val_loss: 1210.2877\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1105.1985 - val_loss: 1022.0473\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 946.8179 - val_loss: 882.8053\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 812.2225 - val_loss: 776.1884\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 715.2775 - val_loss: 687.7284\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 636.0230 - val_loss: 612.1708\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 564.7886 - val_loss: 550.1119\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 503.3505 - val_loss: 491.3760\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 456.8109 - val_loss: 453.4397\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 421.0971 - val_loss: 413.0984\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 387.3355 - val_loss: 387.6058\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.9768 - val_loss: 361.7288\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 334.3436 - val_loss: 329.5959\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.6960 - val_loss: 311.7676\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 300.8475 - val_loss: 317.0175\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.8058 - val_loss: 297.7714\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.0147 - val_loss: 273.2101\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.6750 - val_loss: 258.3183\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.9232 - val_loss: 248.5067\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.4046 - val_loss: 242.3103\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.2786 - val_loss: 230.6872\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.3340 - val_loss: 224.5861\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 215.1807 - val_loss: 226.9516\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.1747 - val_loss: 225.0631\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.2072 - val_loss: 214.3094\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.5701 - val_loss: 204.1605\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.0283 - val_loss: 200.4095\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.7153 - val_loss: 196.4171\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.7632 - val_loss: 203.8636\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.6340 - val_loss: 197.7801\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.9785 - val_loss: 197.5769\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.3586 - val_loss: 187.3637\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.6823 - val_loss: 182.0178\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.2838 - val_loss: 177.7402\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.4780 - val_loss: 174.9523\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.2577 - val_loss: 181.2544\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.3119 - val_loss: 172.9622\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.6086 - val_loss: 168.4121\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.2248 - val_loss: 180.1004\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.4903 - val_loss: 174.9187\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.6041 - val_loss: 166.2105\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.6776 - val_loss: 170.4188\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.8708 - val_loss: 166.4805\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.8529 - val_loss: 176.6248\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.4724 - val_loss: 191.2242\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.8047 - val_loss: 188.4107\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  34  :  165.23900590974336\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 13528.2969 - val_loss: 3745.4641\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2939.1748 - val_loss: 3076.6729\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2410.7361 - val_loss: 2304.4780\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1948.3356 - val_loss: 1960.8853\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1719.6359 - val_loss: 1733.2927\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1508.7858 - val_loss: 1527.1282\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1324.9304 - val_loss: 1344.3236\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1169.0500 - val_loss: 1178.0471\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1014.4702 - val_loss: 1024.0360\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 873.9797 - val_loss: 874.7220\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 753.9235 - val_loss: 744.4936\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 637.2343 - val_loss: 633.6125\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 542.4858 - val_loss: 548.6002\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 471.4724 - val_loss: 478.3497\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 422.8926 - val_loss: 423.5271\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 387.6084 - val_loss: 389.5273\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.3265 - val_loss: 364.7501\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 346.9587 - val_loss: 346.8800\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.6019 - val_loss: 332.9953\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 321.5944 - val_loss: 319.8072\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 309.2611 - val_loss: 309.4680\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 298.8622 - val_loss: 297.6216\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 290.4357 - val_loss: 288.8273\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.1042 - val_loss: 278.6049\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.1731 - val_loss: 269.7967\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.5457 - val_loss: 260.9467\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.7411 - val_loss: 252.6351\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.9746 - val_loss: 245.6522\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.5443 - val_loss: 238.2697\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 230.2678 - val_loss: 231.9732\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.2902 - val_loss: 224.8009\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.8644 - val_loss: 222.3006\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.4240 - val_loss: 214.7391\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.4469 - val_loss: 208.4533\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.1827 - val_loss: 204.8742\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.6534 - val_loss: 199.6865\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.4519 - val_loss: 195.2801\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.1198 - val_loss: 191.2927\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.3786 - val_loss: 187.8249\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.1591 - val_loss: 185.3179\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.8041 - val_loss: 182.1699\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.9688 - val_loss: 178.5219\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.1931 - val_loss: 177.3800\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.1541 - val_loss: 174.0995\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.8379 - val_loss: 171.5110\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.3174 - val_loss: 169.5824\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.0846 - val_loss: 168.0063\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.8570 - val_loss: 166.1673\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.2646 - val_loss: 162.7946\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.4846 - val_loss: 163.6107\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  35  :  157.06111401590272\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 355586.9688 - val_loss: 227612.2656\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160058.7344 - val_loss: 92575.0391\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 61111.5703 - val_loss: 31137.2793\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 19352.8418 - val_loss: 8852.0908\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5779.6323 - val_loss: 2961.3511\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2471.5986 - val_loss: 2106.3894\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1978.8843 - val_loss: 2047.2350\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1920.4677 - val_loss: 1998.5604\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1860.9971 - val_loss: 1926.2373\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1799.2366 - val_loss: 1853.6117\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1737.2688 - val_loss: 1793.2246\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1674.8530 - val_loss: 1727.9200\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1617.2468 - val_loss: 1660.6133\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1555.6943 - val_loss: 1603.3007\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1496.7081 - val_loss: 1542.0227\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1439.4460 - val_loss: 1479.8701\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1382.7042 - val_loss: 1415.0635\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1325.1625 - val_loss: 1360.0652\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1271.4012 - val_loss: 1301.0175\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1219.1544 - val_loss: 1248.6274\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1166.4277 - val_loss: 1193.9607\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1118.9458 - val_loss: 1136.4846\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1071.0740 - val_loss: 1092.0936\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1023.1083 - val_loss: 1041.7174\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 978.1823 - val_loss: 992.8289\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 935.6319 - val_loss: 949.6061\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 894.9339 - val_loss: 908.7579\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 855.6342 - val_loss: 868.2099\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 817.7537 - val_loss: 828.3455\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 783.1798 - val_loss: 789.0861\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 748.3602 - val_loss: 756.0907\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 717.3945 - val_loss: 718.6154\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 687.0518 - val_loss: 691.5566\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 657.3509 - val_loss: 656.7405\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 630.1001 - val_loss: 628.7483\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 604.0668 - val_loss: 603.1144\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 580.8420 - val_loss: 578.3952\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 559.0944 - val_loss: 555.5287\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 535.9005 - val_loss: 529.9207\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 517.3692 - val_loss: 508.0587\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 498.0226 - val_loss: 488.1592\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 481.4425 - val_loss: 472.1473\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 465.0410 - val_loss: 451.7924\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 449.3638 - val_loss: 438.6078\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 436.4167 - val_loss: 421.1282\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 422.3182 - val_loss: 410.0934\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 410.4641 - val_loss: 397.1470\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 399.2701 - val_loss: 383.6262\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 389.0412 - val_loss: 373.4928\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 380.1307 - val_loss: 362.7556\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  36  :  353.7580006515502\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 14210.9258 - val_loss: 9910.1084\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7099.3008 - val_loss: 5004.6895\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3551.8235 - val_loss: 2559.3672\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1876.1770 - val_loss: 1434.0182\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1131.5498 - val_loss: 902.4824\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 765.0701 - val_loss: 643.8412\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 569.0865 - val_loss: 513.0148\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 463.0378 - val_loss: 438.3382\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 396.0291 - val_loss: 384.9589\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.3421 - val_loss: 348.6638\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.8658 - val_loss: 331.3482\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 307.7248 - val_loss: 313.3108\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.1593 - val_loss: 300.7566\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 285.7625 - val_loss: 293.6432\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.1248 - val_loss: 280.6354\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.6158 - val_loss: 285.1969\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.5289 - val_loss: 275.5808\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.9808 - val_loss: 270.4857\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.4547 - val_loss: 274.7462\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.4780 - val_loss: 265.3817\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.3843 - val_loss: 263.7865\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.0542 - val_loss: 263.4741\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.2541 - val_loss: 260.0842\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.6239 - val_loss: 261.3488\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.2483 - val_loss: 258.7746\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 250.7804 - val_loss: 257.6521\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.3656 - val_loss: 252.9538\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.2934 - val_loss: 248.2803\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.4315 - val_loss: 252.1869\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.7679 - val_loss: 248.2565\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.3887 - val_loss: 246.2295\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.4149 - val_loss: 247.3665\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.8698 - val_loss: 244.6711\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.2042 - val_loss: 243.6272\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.8503 - val_loss: 244.1699\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.8454 - val_loss: 239.0113\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.0025 - val_loss: 239.5144\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.5870 - val_loss: 237.8638\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 231.5063 - val_loss: 238.0518\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.5905 - val_loss: 234.3711\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.1723 - val_loss: 235.4171\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 228.3334 - val_loss: 236.2307\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.7872 - val_loss: 229.8021\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.7298 - val_loss: 230.0177\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.8414 - val_loss: 229.8602\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 223.6089 - val_loss: 227.8841\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 223.0519 - val_loss: 228.7175\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.2316 - val_loss: 225.2277\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.0851 - val_loss: 227.7792\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.0859 - val_loss: 224.1622\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  37  :  255.89411984705634\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 828.3323 - val_loss: 632.8047\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 409.0442 - val_loss: 365.7110\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.7768 - val_loss: 318.2398\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.0193 - val_loss: 276.8511\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.1607 - val_loss: 260.5439\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.2753 - val_loss: 241.5327\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.5620 - val_loss: 242.1002\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 209.2587 - val_loss: 225.0208\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 201.1649 - val_loss: 217.0159\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.7826 - val_loss: 214.0045\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.5250 - val_loss: 210.1675\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 188.2489 - val_loss: 206.2690\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.1417 - val_loss: 197.6206\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.8354 - val_loss: 200.3862\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.0154 - val_loss: 200.2297\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.7316 - val_loss: 192.5474\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.6012 - val_loss: 190.7050\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.5945 - val_loss: 188.1759\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.6423 - val_loss: 207.3652\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.9378 - val_loss: 195.7147\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.7998 - val_loss: 177.7067\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.7876 - val_loss: 197.6869\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.8249 - val_loss: 174.7569\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.3914 - val_loss: 187.2883\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.6596 - val_loss: 172.1353\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.7950 - val_loss: 168.4272\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.3987 - val_loss: 181.9397\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.8979 - val_loss: 167.9754\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.6961 - val_loss: 167.3106\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.8935 - val_loss: 166.8021\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.0402 - val_loss: 166.4565\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.6852 - val_loss: 165.4031\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.6378 - val_loss: 167.0958\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.8186 - val_loss: 161.5200\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.2292 - val_loss: 173.5039\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.4825 - val_loss: 155.9236\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.9129 - val_loss: 161.5155\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.9402 - val_loss: 166.6286\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.4787 - val_loss: 162.9238\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.3630 - val_loss: 150.7526\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.1384 - val_loss: 150.0231\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.9988 - val_loss: 150.2516\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.4157 - val_loss: 152.0614\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.1133 - val_loss: 151.3434\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.4627 - val_loss: 150.7205\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.8224 - val_loss: 147.0195\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.1693 - val_loss: 148.0768\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4273 - val_loss: 142.3959\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.3240 - val_loss: 141.9730\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.0305 - val_loss: 138.8869\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  38  :  134.56921425728208\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 155532.1562 - val_loss: 83169.2188\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 42479.7656 - val_loss: 14072.1553\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5344.6377 - val_loss: 1810.0194\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2816.0793 - val_loss: 2091.4829\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2318.7034 - val_loss: 1648.2094\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1996.7371 - val_loss: 1577.5979\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1827.9348 - val_loss: 1409.9629\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1677.1803 - val_loss: 1292.1962\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1531.8094 - val_loss: 1191.0227\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1399.7947 - val_loss: 1102.5446\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1275.4709 - val_loss: 1003.9729\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1163.5803 - val_loss: 927.4476\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1057.6440 - val_loss: 861.2327\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 963.6885 - val_loss: 781.5920\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 872.9733 - val_loss: 734.1242\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 796.3096 - val_loss: 676.5106\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 726.5444 - val_loss: 622.8373\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 666.9775 - val_loss: 579.7538\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 608.2603 - val_loss: 541.6657\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 558.9041 - val_loss: 498.6565\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 513.0844 - val_loss: 472.3965\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 472.9434 - val_loss: 435.2238\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 438.7279 - val_loss: 408.6438\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 405.4778 - val_loss: 380.9597\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 377.5278 - val_loss: 361.8511\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 351.4106 - val_loss: 340.9568\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328.4156 - val_loss: 313.0820\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 305.1140 - val_loss: 302.9203\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 286.0151 - val_loss: 279.5967\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 268.9397 - val_loss: 265.0594\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.8363 - val_loss: 252.9769\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.4984 - val_loss: 238.3870\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.1931 - val_loss: 230.9252\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.0871 - val_loss: 215.0479\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.1864 - val_loss: 211.2271\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.0008 - val_loss: 198.8973\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.7803 - val_loss: 191.5358\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.2250 - val_loss: 185.0007\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.8560 - val_loss: 179.6333\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.0587 - val_loss: 174.1715\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.8817 - val_loss: 169.8416\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.2121 - val_loss: 165.7122\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.5978 - val_loss: 160.2756\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.1245 - val_loss: 160.1347\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.9978 - val_loss: 158.9057\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.1777 - val_loss: 153.0272\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.5295 - val_loss: 150.8425\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.2412 - val_loss: 166.0018\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.6542 - val_loss: 144.4763\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.8703 - val_loss: 145.2369\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  39  :  163.53163442723758\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 112238.5859 - val_loss: 64450.2539\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 42496.5195 - val_loss: 20383.5762\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13200.7275 - val_loss: 6466.2109\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5925.6938 - val_loss: 4835.1724\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5131.5913 - val_loss: 4350.8960\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4478.4468 - val_loss: 3770.3792\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3937.7769 - val_loss: 3335.5188\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3466.3088 - val_loss: 2950.2288\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3055.3748 - val_loss: 2590.9407\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2670.2385 - val_loss: 2275.0068\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2330.8066 - val_loss: 1993.0619\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2010.7084 - val_loss: 1713.1340\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1633.1315 - val_loss: 1313.2786\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1263.5797 - val_loss: 1048.4246\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1000.9501 - val_loss: 844.6591\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 806.6934 - val_loss: 687.8173\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 647.7783 - val_loss: 579.5593\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 543.1989 - val_loss: 493.6804\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 461.2874 - val_loss: 434.2429\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 400.2949 - val_loss: 390.1115\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 357.3058 - val_loss: 357.0627\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.9617 - val_loss: 332.3122\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.9827 - val_loss: 307.8219\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.2097 - val_loss: 290.9844\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.9072 - val_loss: 272.5479\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.4494 - val_loss: 255.3822\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.5899 - val_loss: 247.6854\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.6136 - val_loss: 229.3121\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.0126 - val_loss: 222.4057\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.8914 - val_loss: 206.4214\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.4377 - val_loss: 196.6111\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.5651 - val_loss: 195.4946\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.5580 - val_loss: 179.6382\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.9675 - val_loss: 179.5155\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.4957 - val_loss: 174.3586\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.5008 - val_loss: 159.1921\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.5066 - val_loss: 158.5343\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.1930 - val_loss: 150.2826\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.1901 - val_loss: 144.9400\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.6901 - val_loss: 140.0636\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.5199 - val_loss: 136.1531\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.7441 - val_loss: 136.3304\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.3431 - val_loss: 129.1542\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.8424 - val_loss: 131.1385\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.2014 - val_loss: 124.7535\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.9285 - val_loss: 118.6862\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.9053 - val_loss: 115.7565\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0332 - val_loss: 114.5523\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8134 - val_loss: 113.2624\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.6561 - val_loss: 108.3853\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  40  :  126.38281460295651\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 416595.2812 - val_loss: 301163.8125\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230476.8906 - val_loss: 149162.4531\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103304.8047 - val_loss: 55973.0742\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 33520.2070 - val_loss: 13716.9316\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7662.3511 - val_loss: 3965.7224\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3160.1040 - val_loss: 3234.9026\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2560.0464 - val_loss: 2358.6396\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1833.8605 - val_loss: 1885.0472\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1545.5748 - val_loss: 1688.7451\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1400.8812 - val_loss: 1561.7020\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1306.0677 - val_loss: 1457.3649\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1205.9828 - val_loss: 1361.2062\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1129.7112 - val_loss: 1275.4957\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1055.0587 - val_loss: 1200.1227\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 988.7664 - val_loss: 1118.8481\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 928.6964 - val_loss: 1055.9650\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 880.0776 - val_loss: 1010.4161\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 839.4169 - val_loss: 935.3391\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 782.1911 - val_loss: 892.8290\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 737.8505 - val_loss: 837.7652\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 700.8080 - val_loss: 796.9658\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 667.4054 - val_loss: 749.2869\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 633.0023 - val_loss: 717.9596\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 601.4764 - val_loss: 671.7022\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 573.7220 - val_loss: 613.0019\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 525.8467 - val_loss: 562.5323\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 490.5325 - val_loss: 533.3725\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 464.2709 - val_loss: 513.7313\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 443.7388 - val_loss: 476.6439\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.4666 - val_loss: 452.9020\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 402.5468 - val_loss: 431.2163\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 384.8972 - val_loss: 416.3702\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 369.5494 - val_loss: 396.6140\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 360.4259 - val_loss: 386.9051\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 348.7694 - val_loss: 376.7424\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.7446 - val_loss: 363.6848\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.2986 - val_loss: 356.9217\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.5321 - val_loss: 347.5799\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.7218 - val_loss: 344.4574\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.0470 - val_loss: 336.3731\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 309.9347 - val_loss: 333.7148\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 300.3055 - val_loss: 323.0398\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.2928 - val_loss: 317.7889\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.4330 - val_loss: 312.2542\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.2557 - val_loss: 305.8149\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.6459 - val_loss: 301.0999\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.0510 - val_loss: 300.9416\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.3105 - val_loss: 291.9001\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 268.1386 - val_loss: 288.6773\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 265.4508 - val_loss: 284.6063\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  41  :  237.3721555124008\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 2084.4832 - val_loss: 1533.2909\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1507.7764 - val_loss: 1151.7391\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1129.9530 - val_loss: 907.7800\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 914.6482 - val_loss: 755.3280\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 766.9431 - val_loss: 670.1747\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 683.0168 - val_loss: 603.2441\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 630.4476 - val_loss: 583.0726\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 578.5858 - val_loss: 536.1053\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 543.1289 - val_loss: 514.1204\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 514.9225 - val_loss: 478.6382\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 491.4552 - val_loss: 472.7000\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 473.0505 - val_loss: 440.2507\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 445.4875 - val_loss: 434.9766\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 423.7780 - val_loss: 415.0555\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 406.4184 - val_loss: 399.6318\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 396.1933 - val_loss: 383.6248\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 378.7697 - val_loss: 374.8149\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 366.5513 - val_loss: 360.7404\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 353.4794 - val_loss: 351.5627\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 345.1223 - val_loss: 341.2982\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.5824 - val_loss: 334.3245\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.1721 - val_loss: 333.1196\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 311.9719 - val_loss: 323.4006\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.7099 - val_loss: 318.7285\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297.4265 - val_loss: 299.0230\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 287.1646 - val_loss: 302.2871\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.3999 - val_loss: 290.2781\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 272.1141 - val_loss: 286.3004\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.8042 - val_loss: 280.9980\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 261.9547 - val_loss: 275.9947\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.1414 - val_loss: 272.4531\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 251.6611 - val_loss: 264.4716\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.6030 - val_loss: 261.3916\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.9910 - val_loss: 256.6180\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.1632 - val_loss: 259.0763\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.5496 - val_loss: 246.5848\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.7506 - val_loss: 247.5645\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.8504 - val_loss: 249.6608\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.5392 - val_loss: 234.5265\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.1105 - val_loss: 237.3227\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.4761 - val_loss: 228.5091\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.9938 - val_loss: 230.2165\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.9072 - val_loss: 235.2348\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.8996 - val_loss: 222.4528\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.4964 - val_loss: 220.9415\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.3722 - val_loss: 227.3620\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.9062 - val_loss: 213.9299\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.9179 - val_loss: 212.5652\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.2096 - val_loss: 214.6145\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192.1594 - val_loss: 212.6082\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  42  :  181.26958332748876\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 140815.8438 - val_loss: 85694.2734\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 60656.0312 - val_loss: 39793.8242\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 29299.9277 - val_loss: 19315.8633\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13795.1016 - val_loss: 8628.7764\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5925.2856 - val_loss: 3680.7886\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2495.6436 - val_loss: 1695.6068\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1225.8016 - val_loss: 1008.3945\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 827.2987 - val_loss: 786.2814\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 682.6269 - val_loss: 697.4828\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 620.9470 - val_loss: 628.8362\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 567.0620 - val_loss: 577.9757\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 529.4896 - val_loss: 533.7215\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 498.4330 - val_loss: 495.9867\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 470.0055 - val_loss: 467.2590\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 446.1506 - val_loss: 439.3451\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 423.9051 - val_loss: 412.2533\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 403.2128 - val_loss: 391.3997\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 387.5765 - val_loss: 370.4738\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 372.3624 - val_loss: 356.2837\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 359.9505 - val_loss: 340.9075\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 348.7146 - val_loss: 329.3427\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 338.9324 - val_loss: 320.0332\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 330.1430 - val_loss: 310.3435\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 322.7091 - val_loss: 303.9014\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.6167 - val_loss: 293.6064\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 309.8384 - val_loss: 290.1532\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 302.9364 - val_loss: 280.4419\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.0378 - val_loss: 277.9838\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.3473 - val_loss: 274.5678\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.7644 - val_loss: 266.3060\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.7478 - val_loss: 264.6622\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.9447 - val_loss: 258.9637\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.7695 - val_loss: 256.3485\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.9746 - val_loss: 254.1358\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.5131 - val_loss: 251.6393\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.8720 - val_loss: 245.1856\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.2676 - val_loss: 243.3021\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.0558 - val_loss: 241.7646\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 254.0067 - val_loss: 236.9384\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 251.3590 - val_loss: 234.4805\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.9934 - val_loss: 235.4155\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.6147 - val_loss: 230.8675\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.7168 - val_loss: 229.7589\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.2283 - val_loss: 225.6696\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.9493 - val_loss: 224.5193\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.2021 - val_loss: 223.0044\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.6622 - val_loss: 220.8792\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.5225 - val_loss: 217.7335\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 228.0136 - val_loss: 217.5903\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.8424 - val_loss: 217.0495\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  43  :  210.7659308367301\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 618.8592 - val_loss: 434.7344\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 423.8569 - val_loss: 342.8838\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 370.4733 - val_loss: 288.8449\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 330.9095 - val_loss: 287.3427\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 296.5613 - val_loss: 255.7253\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.7425 - val_loss: 247.7388\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.4361 - val_loss: 229.4088\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.1040 - val_loss: 210.7729\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.8797 - val_loss: 204.4501\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.7024 - val_loss: 217.7671\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.2235 - val_loss: 215.6804\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.2029 - val_loss: 183.4533\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.8316 - val_loss: 185.5181\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.6579 - val_loss: 176.8018\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.4228 - val_loss: 170.5320\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.1932 - val_loss: 163.1894\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.9663 - val_loss: 161.0553\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.8080 - val_loss: 154.9638\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.7781 - val_loss: 176.5794\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.7079 - val_loss: 184.0658\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.4954 - val_loss: 156.8247\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.4363 - val_loss: 147.9820\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.1725 - val_loss: 141.5220\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.7462 - val_loss: 152.8071\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.3844 - val_loss: 138.4393\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.4872 - val_loss: 136.7681\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.6804 - val_loss: 142.0825\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.8266 - val_loss: 133.9413\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.4796 - val_loss: 143.6303\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.3029 - val_loss: 130.6727\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.7106 - val_loss: 127.2578\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0210 - val_loss: 124.8872\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0546 - val_loss: 123.8426\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3675 - val_loss: 123.4791\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2871 - val_loss: 133.8547\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.1003 - val_loss: 137.6400\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2911 - val_loss: 129.2972\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.1338 - val_loss: 120.7202\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.3804 - val_loss: 141.2734\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.9775 - val_loss: 149.5988\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.0702 - val_loss: 136.2269\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0951 - val_loss: 127.6453\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7654 - val_loss: 143.2752\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.9368 - val_loss: 133.4124\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8366 - val_loss: 120.7719\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.8383 - val_loss: 117.4269\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.6556 - val_loss: 132.2028\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.8583 - val_loss: 145.8211\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6366 - val_loss: 124.1877\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2962 - val_loss: 115.3514\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  44  :  118.70739838454841\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 41924.5234 - val_loss: 21935.4219\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 13498.7246 - val_loss: 5257.8472\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2838.1084 - val_loss: 889.6550\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 748.4291 - val_loss: 551.1033\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 562.4641 - val_loss: 415.1099\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 424.1763 - val_loss: 322.7818\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 351.3524 - val_loss: 283.9097\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.5313 - val_loss: 263.8764\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.9736 - val_loss: 254.2615\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 274.4301 - val_loss: 241.6909\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.9772 - val_loss: 233.0063\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.1342 - val_loss: 228.8417\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.9627 - val_loss: 223.4529\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.0872 - val_loss: 221.3083\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.8839 - val_loss: 216.3307\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.3443 - val_loss: 211.6105\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.5966 - val_loss: 207.3669\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.1682 - val_loss: 207.9420\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.6505 - val_loss: 203.9391\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.2339 - val_loss: 198.5966\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.6638 - val_loss: 195.5956\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.1704 - val_loss: 195.4198\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.6788 - val_loss: 191.1106\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.6332 - val_loss: 190.2786\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.7356 - val_loss: 187.9443\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.7240 - val_loss: 185.3106\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.8921 - val_loss: 184.0560\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 185.7342 - val_loss: 180.7486\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.6870 - val_loss: 179.9014\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.5396 - val_loss: 176.4748\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.9209 - val_loss: 177.7820\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.7950 - val_loss: 173.5625\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.4448 - val_loss: 173.5877\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.3495 - val_loss: 171.6855\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.5175 - val_loss: 169.9154\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.3259 - val_loss: 169.5128\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.6668 - val_loss: 167.3532\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.9233 - val_loss: 167.9913\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.9880 - val_loss: 164.0669\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.1574 - val_loss: 161.2283\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.8728 - val_loss: 163.7924\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.6896 - val_loss: 158.0021\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.2146 - val_loss: 158.2591\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.4471 - val_loss: 159.8167\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.1133 - val_loss: 157.1754\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.6113 - val_loss: 155.5700\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.1548 - val_loss: 153.5761\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.1884 - val_loss: 153.1976\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.2472 - val_loss: 152.8059\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.1333 - val_loss: 150.2231\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  45  :  155.03153718765262\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 9000.0244 - val_loss: 6064.5732\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5437.8989 - val_loss: 3604.1807\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3074.5112 - val_loss: 1868.9883\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1488.0319 - val_loss: 961.1205\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 855.4673 - val_loss: 707.0626\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 646.7893 - val_loss: 524.5824\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 492.4940 - val_loss: 397.3143\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 380.1751 - val_loss: 312.6154\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 302.0274 - val_loss: 252.4948\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.1045 - val_loss: 211.2359\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.4394 - val_loss: 186.9096\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.5833 - val_loss: 179.3036\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.2871 - val_loss: 178.6195\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.8545 - val_loss: 172.8087\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.2923 - val_loss: 168.3383\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.1719 - val_loss: 167.6377\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.9906 - val_loss: 162.5634\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.3521 - val_loss: 160.8988\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.4428 - val_loss: 158.0911\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.9678 - val_loss: 156.9391\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.3250 - val_loss: 155.2331\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.4455 - val_loss: 152.1350\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.5920 - val_loss: 147.8800\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.5150 - val_loss: 148.9230\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.9293 - val_loss: 145.0730\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.8868 - val_loss: 145.3304\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.5596 - val_loss: 140.3897\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.0251 - val_loss: 139.9309\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.3611 - val_loss: 137.8297\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.8130 - val_loss: 138.2174\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2258 - val_loss: 135.4959\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.7817 - val_loss: 136.3774\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.5784 - val_loss: 131.4426\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8265 - val_loss: 131.9547\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.5143 - val_loss: 128.7470\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.1083 - val_loss: 127.8137\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0815 - val_loss: 129.8810\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.6299 - val_loss: 123.7171\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.6844 - val_loss: 131.2933\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.3005 - val_loss: 120.6224\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.3089 - val_loss: 128.6729\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4843 - val_loss: 122.9739\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.7578 - val_loss: 119.3547\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.7067 - val_loss: 126.4481\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 106.7652 - val_loss: 118.2877\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.4136 - val_loss: 119.6764\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.8484 - val_loss: 116.4080\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0823 - val_loss: 119.2540\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.9455 - val_loss: 115.3158\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5364 - val_loss: 117.3151\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  46  :  108.6092211029965\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 9291.1748 - val_loss: 1951.3491\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2260.3577 - val_loss: 1968.5302\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1432.5901 - val_loss: 1075.1637\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1052.0911 - val_loss: 882.0436\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 873.5104 - val_loss: 764.8747\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 786.7065 - val_loss: 709.0041\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 726.8905 - val_loss: 650.5676\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 678.0817 - val_loss: 611.2957\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 632.6729 - val_loss: 574.1104\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 598.2978 - val_loss: 541.3878\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 571.2087 - val_loss: 541.2699\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 548.8553 - val_loss: 493.3179\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 518.6501 - val_loss: 496.5278\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 501.2260 - val_loss: 457.5586\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 483.8268 - val_loss: 458.2498\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 464.4912 - val_loss: 442.3489\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 451.4846 - val_loss: 420.6359\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 439.2876 - val_loss: 416.8814\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.6406 - val_loss: 402.1249\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 417.0430 - val_loss: 384.7032\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 406.8760 - val_loss: 381.6563\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 395.3672 - val_loss: 371.2083\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 386.1433 - val_loss: 370.2745\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 379.8691 - val_loss: 354.4837\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.0208 - val_loss: 346.7930\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.9171 - val_loss: 343.4497\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 355.2971 - val_loss: 327.9622\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 347.4426 - val_loss: 326.1220\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.4366 - val_loss: 324.6067\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 337.5040 - val_loss: 304.0483\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 326.9926 - val_loss: 312.4494\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.8356 - val_loss: 291.3629\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.8774 - val_loss: 315.5157\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 313.5050 - val_loss: 279.5653\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.0546 - val_loss: 279.4589\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 302.2134 - val_loss: 267.8003\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.7500 - val_loss: 294.2841\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.2129 - val_loss: 265.8715\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.0526 - val_loss: 286.6044\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.7095 - val_loss: 247.2929\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.5649 - val_loss: 249.2364\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.8947 - val_loss: 256.7332\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.1888 - val_loss: 238.1562\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.7961 - val_loss: 247.7668\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.7058 - val_loss: 237.7548\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.4042 - val_loss: 227.5711\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 238.5865 - val_loss: 220.3339\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.6192 - val_loss: 228.9174\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.8759 - val_loss: 207.0504\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.4596 - val_loss: 231.8230\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  47  :  216.08242616310957\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 683704.9375 - val_loss: 469552.0625\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343811.3125 - val_loss: 219939.9375\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150295.4688 - val_loss: 86064.3984\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53179.4453 - val_loss: 25171.7949\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13509.2471 - val_loss: 5315.8242\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2713.8755 - val_loss: 1644.9053\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1323.0055 - val_loss: 1462.8878\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1310.6425 - val_loss: 1454.9938\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1288.2706 - val_loss: 1431.1611\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1266.2712 - val_loss: 1417.5355\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1256.3033 - val_loss: 1407.2615\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1244.6143 - val_loss: 1393.8042\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1233.4076 - val_loss: 1380.0499\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1222.0164 - val_loss: 1366.4005\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1209.6877 - val_loss: 1353.2264\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1198.1329 - val_loss: 1340.0273\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1185.4473 - val_loss: 1325.6351\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1177.6981 - val_loss: 1312.5317\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1161.0544 - val_loss: 1296.1173\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1151.1201 - val_loss: 1281.7689\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1135.5338 - val_loss: 1267.8969\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1122.9845 - val_loss: 1252.5553\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1110.3024 - val_loss: 1239.1333\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1097.6517 - val_loss: 1221.9058\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1081.5460 - val_loss: 1206.6111\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1067.0491 - val_loss: 1191.1283\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1051.4456 - val_loss: 1174.7472\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1036.1245 - val_loss: 1158.0342\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1021.1349 - val_loss: 1140.7513\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1008.6429 - val_loss: 1125.9426\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 990.2060 - val_loss: 1107.5309\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 972.9310 - val_loss: 1091.1692\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 956.9991 - val_loss: 1074.0101\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 939.7630 - val_loss: 1056.4060\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 925.3842 - val_loss: 1039.6196\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 908.0081 - val_loss: 1023.0926\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 892.7360 - val_loss: 1005.3445\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 878.8698 - val_loss: 988.9093\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 860.6786 - val_loss: 971.3724\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 849.5872 - val_loss: 955.1290\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 835.7159 - val_loss: 940.9236\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 820.0105 - val_loss: 925.5048\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 804.0315 - val_loss: 911.8228\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 792.6208 - val_loss: 898.1810\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 782.0624 - val_loss: 884.4691\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 768.7090 - val_loss: 872.2519\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 758.3894 - val_loss: 858.8699\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 745.3393 - val_loss: 848.0982\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 737.6365 - val_loss: 835.6820\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 725.2436 - val_loss: 823.6656\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  48  :  720.9143468500771\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 15211.5801 - val_loss: 3723.5635\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1705.0150 - val_loss: 1579.6741\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1400.8949 - val_loss: 1366.1896\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1002.4464 - val_loss: 1111.3801\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 916.6650 - val_loss: 1033.1040\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 834.3573 - val_loss: 942.6798\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 771.9700 - val_loss: 877.7859\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 718.7095 - val_loss: 811.4791\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 666.7792 - val_loss: 754.9219\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 613.4058 - val_loss: 696.4392\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 561.8936 - val_loss: 643.5886\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 513.0183 - val_loss: 586.0842\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 466.6349 - val_loss: 535.5480\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 423.5298 - val_loss: 480.1515\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 380.1139 - val_loss: 434.0196\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 339.6367 - val_loss: 390.5215\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304.4302 - val_loss: 357.1163\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 274.6063 - val_loss: 325.3545\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.4635 - val_loss: 288.0777\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.1405 - val_loss: 265.5952\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.6815 - val_loss: 238.0014\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.1470 - val_loss: 220.3713\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.3862 - val_loss: 211.6629\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.9580 - val_loss: 196.5438\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.9458 - val_loss: 185.5069\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.1570 - val_loss: 182.0779\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.6256 - val_loss: 174.1162\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4420 - val_loss: 166.3195\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.0964 - val_loss: 158.7844\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.8975 - val_loss: 160.0443\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.7878 - val_loss: 151.1437\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.8607 - val_loss: 150.9484\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.3385 - val_loss: 151.0798\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.7925 - val_loss: 144.8549\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.6517 - val_loss: 147.7338\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.9357 - val_loss: 144.3395\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.4838 - val_loss: 141.0177\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.5917 - val_loss: 141.2713\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.9420 - val_loss: 144.0801\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2488 - val_loss: 136.7722\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2081 - val_loss: 136.3599\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.4719 - val_loss: 134.6911\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.2338 - val_loss: 135.4546\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.7643 - val_loss: 132.7425\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.9096 - val_loss: 132.1458\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6932 - val_loss: 134.0541\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.0882 - val_loss: 132.6430\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.9758 - val_loss: 128.7110\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.5580 - val_loss: 140.7941\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.6885 - val_loss: 125.0413\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  49  :  124.80429862282318\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 40529.5312 - val_loss: 27024.0000\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 22211.1113 - val_loss: 14958.5342\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12838.8848 - val_loss: 9069.3799\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8000.2139 - val_loss: 5658.5000\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5087.6421 - val_loss: 3500.2632\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3209.5598 - val_loss: 2139.4094\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2055.3296 - val_loss: 1413.7206\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1462.0906 - val_loss: 1058.4388\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1131.3524 - val_loss: 810.6868\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 861.6617 - val_loss: 579.9440\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 620.8951 - val_loss: 412.0764\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 467.5752 - val_loss: 363.5893\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 427.4266 - val_loss: 361.6600\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 409.5757 - val_loss: 350.1765\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.0733 - val_loss: 337.1721\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 385.8626 - val_loss: 328.6246\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 374.5582 - val_loss: 318.8654\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.7743 - val_loss: 309.2867\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 351.0440 - val_loss: 297.8076\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.6647 - val_loss: 289.7859\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 329.8136 - val_loss: 285.6882\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 322.0848 - val_loss: 275.2729\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.6517 - val_loss: 274.3235\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.5183 - val_loss: 263.7339\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 300.0546 - val_loss: 262.3491\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.6624 - val_loss: 256.6925\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.1494 - val_loss: 258.1634\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.6537 - val_loss: 249.3354\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.1946 - val_loss: 247.5511\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.3501 - val_loss: 246.5074\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.3496 - val_loss: 245.7169\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.0674 - val_loss: 240.9337\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.6867 - val_loss: 240.8110\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.8549 - val_loss: 237.3710\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 262.6521 - val_loss: 237.8990\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.8392 - val_loss: 233.7374\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.6457 - val_loss: 232.7999\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.8557 - val_loss: 231.0009\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.5155 - val_loss: 229.1518\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.5579 - val_loss: 226.4901\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.6408 - val_loss: 227.7103\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 245.3793 - val_loss: 224.9703\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.0540 - val_loss: 221.0719\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.8924 - val_loss: 221.1039\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.0533 - val_loss: 218.0605\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.3110 - val_loss: 219.9147\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.3587 - val_loss: 214.3836\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.4872 - val_loss: 214.4897\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.5130 - val_loss: 213.1427\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.2265 - val_loss: 214.2016\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  50  :  246.45582033820742\n",
            "\n",
            "\n",
            "Total Execution Time :  0:04:13.605067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDqPBFPaOfn_",
        "outputId": "5f8def52-269f-4cc7-e2e3-1a36b89e3ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' , str(std_of_mse))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  209.14975856494516\n",
            "Standard Deviation of MSE of 50 Models :  130.97723909098966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfDcbdFOfn_"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2MOD6TZOfn_"
      },
      "source": [
        "# <font color = blue> END OF PART A </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_docYe_FOfn_"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvalLoVuOfoA"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXwfJaIMOfoA"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdvGQW1tOfoA"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1aleb1-OfoA"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJgYl8oWOfoA"
      },
      "source": [
        "# <font color = blue> PART B : BASELINE MODEL WITH NORMALIZED FEATURES </font>\n",
        "\n",
        "\n",
        "In this part, all the tasks from <b>PART A</b> are performed, but this time the values for the features (X) will be normalized using the formula `X - µ / σ`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwWany0lOfoA"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LAxS4HEOfoA"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model with Normalized Features</font>\n",
        "\n",
        "In order to train and test the the baseline model with normalized features, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Normalize the features (X)</li>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3uGHc0NOfoA"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Normalize the features (X) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTTMajbwOfoA"
      },
      "source": [
        "X = X - X.mean() / X.std()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3nlTOfbOfoB"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbPA9GvUOfoB"
      },
      "source": [
        "# Creating X_train, X_test, Y_train and Y_test sets\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEnFQ1M7OfoB"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J82eu17OfoB"
      },
      "source": [
        "<b>Note </b> : Since the regression model has already been created using `def regression_model` in <b>TASK 1</b> and there are no changes being made to it, hence there is no need to write the code for the model again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwRY2TqgOfoB",
        "outputId": "05967fdc-fa98-4450-85a3-729cd6eeaa06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=50)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 420930.3125 - val_loss: 307454.6875\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 230931.1562 - val_loss: 160147.4844\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 115177.7734 - val_loss: 75359.8672\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 51420.1680 - val_loss: 31217.0488\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 20043.1562 - val_loss: 11107.6797\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6814.2642 - val_loss: 3450.8831\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2166.3718 - val_loss: 1187.4994\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 938.2435 - val_loss: 635.5397\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 656.0827 - val_loss: 537.2068\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 607.3584 - val_loss: 519.9875\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 599.1852 - val_loss: 514.6065\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 592.3937 - val_loss: 510.0405\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 585.6017 - val_loss: 506.2851\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 579.6325 - val_loss: 502.7337\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 573.7465 - val_loss: 499.2408\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 567.4106 - val_loss: 495.6839\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 561.8668 - val_loss: 492.0428\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 556.3936 - val_loss: 488.4822\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 550.0310 - val_loss: 485.0833\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 545.0552 - val_loss: 481.5845\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 538.9413 - val_loss: 477.7643\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 532.7581 - val_loss: 473.8892\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 527.6004 - val_loss: 469.8361\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 521.6208 - val_loss: 465.9108\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 515.9703 - val_loss: 462.2466\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 510.6042 - val_loss: 458.7543\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 504.7455 - val_loss: 454.9192\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 499.4426 - val_loss: 450.9394\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 493.6898 - val_loss: 447.0942\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 488.5747 - val_loss: 443.3937\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 482.1942 - val_loss: 439.6432\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 476.9837 - val_loss: 436.0903\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 471.0147 - val_loss: 432.5577\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 465.2815 - val_loss: 428.8670\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 460.9018 - val_loss: 425.0611\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 454.6568 - val_loss: 421.2303\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 449.2444 - val_loss: 417.2839\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 444.1549 - val_loss: 413.4996\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 438.2424 - val_loss: 409.5742\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 432.7112 - val_loss: 405.4545\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 427.1745 - val_loss: 401.6613\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 421.5139 - val_loss: 397.6111\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 418.2664 - val_loss: 394.2267\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 411.5399 - val_loss: 389.3031\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 408.7195 - val_loss: 386.7954\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 400.5552 - val_loss: 382.2797\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 395.2596 - val_loss: 378.8740\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 390.0274 - val_loss: 375.2752\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 384.8215 - val_loss: 371.7235\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 379.8406 - val_loss: 367.9589\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f40770e0f50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeP-ivAuOfoB"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoTjUOfoB"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiyZJweVOfoB"
      },
      "source": [
        "### <font color = #2980B9> Step 5 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7uEpiwqOfoC",
        "outputId": "cb77d24a-218f-4440-8e65-cb056b170977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the mean square error\n",
        "\n",
        "mse = calculate_mse()\n",
        "print('Mean Square Error (MSE) of the Baseline Model with Normalized Features is : ' , str(mse))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model with Normalized Features is :  354.3626814366455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7qJAlDbOfoC"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czVV6dGCOfoC"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJDHfFCjOfoC"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors with new Features</font>\n",
        "\n",
        "In order to train 50 models with new features (normalized features) and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE) the following steps are performed :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPgPkU7_OfoC"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJcIOw6_OfoC"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNECDF5IOfoC"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cAD3U_rOfoD",
        "outputId": "342e1f12-4574-4fb4-cb7d-b93a9f3a3cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=50)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = model.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = mean_squared_error(Y_test, Y_predicted)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 180.6215 - val_loss: 151.7586\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 177.3257 - val_loss: 151.5825\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 176.6839 - val_loss: 150.4128\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 178.5508 - val_loss: 147.5721\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.3558 - val_loss: 146.4247\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.1836 - val_loss: 148.5096\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 169.9695 - val_loss: 142.0718\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 168.9519 - val_loss: 142.8320\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.7685 - val_loss: 140.8236\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 166.6651 - val_loss: 138.0016\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 161.7221 - val_loss: 139.2049\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.5052 - val_loss: 137.4446\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.8892 - val_loss: 138.7887\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.3545 - val_loss: 132.1942\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  5 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 455179.8750 - val_loss: 254864.1094\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162863.0312 - val_loss: 80432.6328\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 47552.4062 - val_loss: 20861.2734\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 12117.1152 - val_loss: 5488.0967\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 4067.4153 - val_loss: 3368.0779\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3176.7341 - val_loss: 3227.4548\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3037.9038 - val_loss: 3084.9785\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2894.8579 - val_loss: 2918.1765\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2759.4666 - val_loss: 2789.1501\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2643.6660 - val_loss: 2665.0513\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2534.7581 - val_loss: 2545.0483\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2424.0237 - val_loss: 2437.2100\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2318.1819 - val_loss: 2343.9446\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2225.9160 - val_loss: 2241.2715\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2133.7253 - val_loss: 2150.2542\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2048.4768 - val_loss: 2060.6240\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1963.4409 - val_loss: 1979.9247\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1886.5555 - val_loss: 1898.4622\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1810.6809 - val_loss: 1822.3669\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1740.1688 - val_loss: 1748.7301\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1669.9128 - val_loss: 1679.7273\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1608.0035 - val_loss: 1607.1528\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1544.5043 - val_loss: 1542.5278\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1483.9657 - val_loss: 1483.6394\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1433.1904 - val_loss: 1425.6632\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1378.4108 - val_loss: 1368.2167\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1328.0555 - val_loss: 1314.0510\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1278.5724 - val_loss: 1262.4493\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1234.0260 - val_loss: 1214.3564\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1190.5363 - val_loss: 1163.0095\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1142.8629 - val_loss: 1118.0005\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1098.7889 - val_loss: 1065.9711\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1054.3804 - val_loss: 1015.1403\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1009.8947 - val_loss: 965.1851\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 967.7874 - val_loss: 914.2645\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 924.5745 - val_loss: 868.6705\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 882.8820 - val_loss: 821.8967\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 842.3230 - val_loss: 782.4340\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 806.6857 - val_loss: 740.6377\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 769.4965 - val_loss: 706.0718\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 735.4648 - val_loss: 673.1975\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 706.4333 - val_loss: 645.2379\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 681.8861 - val_loss: 616.9312\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 656.8995 - val_loss: 594.4537\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 634.2021 - val_loss: 575.3854\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 614.3344 - val_loss: 555.7743\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 601.1120 - val_loss: 536.1398\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 577.2607 - val_loss: 521.9990\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 563.3515 - val_loss: 505.7040\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 547.2461 - val_loss: 488.4731\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  6 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 28466.9082 - val_loss: 15934.8418\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10062.6865 - val_loss: 5608.5024\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3771.6335 - val_loss: 2686.1733\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2159.2981 - val_loss: 2092.4504\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1834.4344 - val_loss: 1915.2299\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1711.8735 - val_loss: 1832.8988\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1648.6500 - val_loss: 1789.9221\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1611.7878 - val_loss: 1763.1962\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1582.1545 - val_loss: 1742.9399\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1557.2971 - val_loss: 1726.6707\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1535.6162 - val_loss: 1712.8240\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1518.9479 - val_loss: 1701.1702\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1505.1346 - val_loss: 1690.5671\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1494.0995 - val_loss: 1681.1288\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1484.6327 - val_loss: 1672.7104\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1476.8715 - val_loss: 1664.2863\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1469.3152 - val_loss: 1658.1981\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1464.2277 - val_loss: 1653.8656\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1460.0311 - val_loss: 1650.4974\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1457.5209 - val_loss: 1646.5542\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1455.2528 - val_loss: 1643.8611\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1453.5482 - val_loss: 1641.9695\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1452.3289 - val_loss: 1640.3855\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1451.0682 - val_loss: 1639.0394\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1449.9666 - val_loss: 1637.6865\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1448.7969 - val_loss: 1636.4470\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1447.7701 - val_loss: 1635.0956\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1446.6703 - val_loss: 1633.8636\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1445.6093 - val_loss: 1632.6958\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1444.6217 - val_loss: 1631.6436\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1443.7123 - val_loss: 1630.5935\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1442.7585 - val_loss: 1629.6080\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1441.8059 - val_loss: 1628.7002\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1440.8795 - val_loss: 1627.7318\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1439.9139 - val_loss: 1626.7834\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1438.9923 - val_loss: 1625.8811\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1438.0889 - val_loss: 1624.9325\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1437.2078 - val_loss: 1623.9570\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1436.2832 - val_loss: 1623.0011\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1435.3691 - val_loss: 1622.0543\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1434.4739 - val_loss: 1621.0703\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1433.5703 - val_loss: 1620.1298\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1432.6324 - val_loss: 1619.1388\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1431.6934 - val_loss: 1618.1602\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1430.7910 - val_loss: 1617.1854\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1429.8336 - val_loss: 1616.2444\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1428.8936 - val_loss: 1615.2858\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1427.9670 - val_loss: 1614.3364\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1427.0380 - val_loss: 1613.3822\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1426.0697 - val_loss: 1612.4224\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  7 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 11965.6680 - val_loss: 2031.3560\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1980.4131 - val_loss: 2150.9695\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1648.7805 - val_loss: 1426.9685\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1254.2727 - val_loss: 1230.9368\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1065.3447 - val_loss: 1057.4270\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 926.4775 - val_loss: 919.4796\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 804.1442 - val_loss: 797.3076\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 693.5585 - val_loss: 695.8810\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 608.2533 - val_loss: 607.3591\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 527.4325 - val_loss: 534.9626\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 462.5074 - val_loss: 473.3550\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 411.0682 - val_loss: 420.4394\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 368.4544 - val_loss: 379.6855\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 332.3473 - val_loss: 344.3805\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 304.2930 - val_loss: 316.6657\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.6352 - val_loss: 293.7407\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.5383 - val_loss: 274.7596\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 239.2714 - val_loss: 261.6828\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 227.3246 - val_loss: 244.5383\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.0394 - val_loss: 232.6413\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.6881 - val_loss: 224.1851\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.2751 - val_loss: 214.1212\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 188.3727 - val_loss: 208.1564\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 183.8705 - val_loss: 202.9186\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 176.0734 - val_loss: 194.5232\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.0705 - val_loss: 193.0728\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 168.7452 - val_loss: 186.7170\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 162.1530 - val_loss: 179.4238\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.3371 - val_loss: 176.0632\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 153.9257 - val_loss: 172.0833\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 151.0050 - val_loss: 169.1025\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 148.9883 - val_loss: 167.8671\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.1430 - val_loss: 163.6324\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.3754 - val_loss: 161.4572\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 143.4840 - val_loss: 159.0090\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.8218 - val_loss: 157.0382\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.4560 - val_loss: 155.3739\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.8381 - val_loss: 154.9599\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.1949 - val_loss: 152.0851\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.6515 - val_loss: 150.5613\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.8446 - val_loss: 149.3245\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.3125 - val_loss: 147.9563\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 134.1386 - val_loss: 146.7870\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.8686 - val_loss: 146.0622\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.9544 - val_loss: 144.2974\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.9066 - val_loss: 143.6269\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 127.4711 - val_loss: 147.2839\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.6846 - val_loss: 142.5019\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.4814 - val_loss: 151.9168\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 131.6773 - val_loss: 142.3737\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  8 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 10867.1582 - val_loss: 3909.7529\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3206.6426 - val_loss: 3326.8621\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2350.2419 - val_loss: 2306.2424\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1834.4075 - val_loss: 1946.7444\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1551.2778 - val_loss: 1725.7083\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1396.0543 - val_loss: 1538.6259\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1274.7456 - val_loss: 1412.2057\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1173.8649 - val_loss: 1316.1980\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1082.6609 - val_loss: 1214.9399\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1011.8383 - val_loss: 1136.4801\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 948.6212 - val_loss: 1067.9269\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 885.6310 - val_loss: 1002.9903\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 834.0432 - val_loss: 946.5806\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 790.7924 - val_loss: 891.5109\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 746.7579 - val_loss: 840.7874\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 703.0530 - val_loss: 783.0604\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 662.9965 - val_loss: 743.6143\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 624.8249 - val_loss: 696.1949\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 592.6310 - val_loss: 653.0402\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 558.8171 - val_loss: 619.4467\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 529.0684 - val_loss: 575.2475\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 500.8340 - val_loss: 540.3718\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 469.5279 - val_loss: 509.6161\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 441.3325 - val_loss: 471.9218\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 409.4837 - val_loss: 433.7509\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 368.8792 - val_loss: 377.7755\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 318.6009 - val_loss: 339.7595\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 283.4166 - val_loss: 307.7838\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.5406 - val_loss: 284.7518\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.3367 - val_loss: 258.5452\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.4397 - val_loss: 252.2923\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.6214 - val_loss: 226.6160\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.6357 - val_loss: 218.5724\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 203.1736 - val_loss: 210.3874\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.5101 - val_loss: 205.6866\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.8514 - val_loss: 193.4192\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 182.1380 - val_loss: 189.7474\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.7168 - val_loss: 175.2266\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.2798 - val_loss: 181.5264\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.6786 - val_loss: 167.8689\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.4971 - val_loss: 167.0344\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 159.3505 - val_loss: 157.5701\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 157.2601 - val_loss: 156.5424\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.8521 - val_loss: 164.6036\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 152.4843 - val_loss: 152.8254\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 149.1819 - val_loss: 155.4376\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 148.7980 - val_loss: 147.1152\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 144.9570 - val_loss: 144.1460\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.6122 - val_loss: 138.3750\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.2765 - val_loss: 140.9793\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  9 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 42046.0195 - val_loss: 26436.2793\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 16149.3896 - val_loss: 8554.2041\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 5032.4927 - val_loss: 3251.9297\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2805.0349 - val_loss: 2824.4233\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2676.6724 - val_loss: 2664.4321\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2484.1267 - val_loss: 2504.3127\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2316.7954 - val_loss: 2354.7761\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2179.4529 - val_loss: 2203.1882\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2020.5780 - val_loss: 2039.0294\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1884.2402 - val_loss: 1896.8070\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1748.1339 - val_loss: 1748.1875\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1620.0477 - val_loss: 1612.1284\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1492.1067 - val_loss: 1485.6023\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1386.1920 - val_loss: 1377.0361\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1290.6172 - val_loss: 1261.9604\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1200.1476 - val_loss: 1173.9902\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1116.4313 - val_loss: 1097.5420\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1043.9025 - val_loss: 1017.6101\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 971.1467 - val_loss: 946.6693\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 909.4380 - val_loss: 879.6678\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 853.4907 - val_loss: 819.3205\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 798.5000 - val_loss: 765.8403\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 745.1624 - val_loss: 720.4203\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 704.0916 - val_loss: 678.2894\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 660.4008 - val_loss: 637.9702\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 627.7517 - val_loss: 602.6494\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 590.7319 - val_loss: 571.4138\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 562.0800 - val_loss: 544.0865\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 538.5288 - val_loss: 517.8497\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 516.1707 - val_loss: 493.4774\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 489.2065 - val_loss: 474.5714\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 474.5706 - val_loss: 454.7240\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 455.4608 - val_loss: 437.8004\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 437.3910 - val_loss: 421.7087\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420.3918 - val_loss: 406.9543\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 406.6700 - val_loss: 393.7756\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 393.5789 - val_loss: 380.6678\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 383.5570 - val_loss: 370.3938\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 373.3154 - val_loss: 357.1771\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 358.8919 - val_loss: 352.2546\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 347.8690 - val_loss: 338.2933\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 341.1707 - val_loss: 332.6746\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 332.5171 - val_loss: 320.9910\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 323.6527 - val_loss: 314.9724\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 316.6541 - val_loss: 307.6479\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 310.7700 - val_loss: 303.1254\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 304.3565 - val_loss: 293.8785\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 294.6857 - val_loss: 289.7825\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 289.5811 - val_loss: 282.0649\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 283.4927 - val_loss: 277.3071\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  10 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 171801.1875 - val_loss: 117264.8203\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86785.2031 - val_loss: 59135.2227\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 43360.3516 - val_loss: 29729.4316\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 22393.7598 - val_loss: 16197.9492\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 12738.8018 - val_loss: 9626.6025\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 7917.4507 - val_loss: 6380.8945\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5584.6187 - val_loss: 4831.9780\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 4359.7178 - val_loss: 3968.1951\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3668.6406 - val_loss: 3490.0840\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3283.6912 - val_loss: 3181.7322\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3027.4116 - val_loss: 2966.7280\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2839.5962 - val_loss: 2805.5588\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2691.6265 - val_loss: 2669.2109\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2566.7021 - val_loss: 2548.8135\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2455.4268 - val_loss: 2444.4563\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2359.8215 - val_loss: 2353.6099\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2277.6067 - val_loss: 2270.9260\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2201.9583 - val_loss: 2196.9534\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2134.4463 - val_loss: 2129.7163\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2071.7253 - val_loss: 2070.4910\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2015.9030 - val_loss: 2014.9159\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1963.4164 - val_loss: 1965.0339\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1916.1937 - val_loss: 1919.1814\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1874.0964 - val_loss: 1877.3335\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1834.8776 - val_loss: 1839.3259\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1799.3079 - val_loss: 1802.6740\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1764.7363 - val_loss: 1769.0303\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1732.4531 - val_loss: 1737.5409\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1701.9095 - val_loss: 1707.6221\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1672.9596 - val_loss: 1678.6885\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1644.9297 - val_loss: 1650.0280\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1617.5784 - val_loss: 1622.8042\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1590.6991 - val_loss: 1596.4110\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1564.6510 - val_loss: 1569.6195\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1538.0242 - val_loss: 1543.1061\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1511.6119 - val_loss: 1516.3619\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1484.6415 - val_loss: 1489.2847\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1457.8236 - val_loss: 1460.7880\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1429.3611 - val_loss: 1432.0361\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1400.4351 - val_loss: 1402.5078\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1370.3842 - val_loss: 1372.1180\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1339.4125 - val_loss: 1340.3063\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1306.7661 - val_loss: 1306.6021\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1272.4755 - val_loss: 1270.8721\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1235.9376 - val_loss: 1234.0762\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1198.4131 - val_loss: 1195.0250\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1159.3561 - val_loss: 1153.9020\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1118.2747 - val_loss: 1111.5686\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1075.3184 - val_loss: 1068.0763\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1032.0574 - val_loss: 1022.0715\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  11 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 437.2768 - val_loss: 363.3518\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 392.4859 - val_loss: 344.8778\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 365.1673 - val_loss: 335.9684\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 353.4480 - val_loss: 322.5795\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 342.5682 - val_loss: 318.1131\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 333.1464 - val_loss: 305.9385\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 324.4099 - val_loss: 299.9865\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 317.1981 - val_loss: 294.3316\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 309.4032 - val_loss: 287.7564\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 303.6537 - val_loss: 284.1251\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 298.8856 - val_loss: 276.5526\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 293.0580 - val_loss: 274.0801\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 287.2037 - val_loss: 266.7704\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 280.3696 - val_loss: 265.1816\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 275.5761 - val_loss: 256.7019\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 270.8911 - val_loss: 251.9452\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.9887 - val_loss: 249.0464\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 257.5677 - val_loss: 239.9342\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 250.0769 - val_loss: 235.1712\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 241.7667 - val_loss: 226.5568\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.4252 - val_loss: 221.6655\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 223.6781 - val_loss: 211.2153\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.0914 - val_loss: 206.2821\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.0142 - val_loss: 199.3174\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 194.5196 - val_loss: 183.3131\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 185.2271 - val_loss: 174.1219\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.1668 - val_loss: 166.4320\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 169.4138 - val_loss: 166.4041\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.9825 - val_loss: 157.0373\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 144.0586 - val_loss: 150.2745\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.1503 - val_loss: 143.8150\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 130.0506 - val_loss: 133.1549\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 122.9863 - val_loss: 126.5392\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.5497 - val_loss: 122.5507\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.2831 - val_loss: 118.0636\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.5926 - val_loss: 117.9461\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 107.7347 - val_loss: 115.9466\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.3679 - val_loss: 115.7319\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 104.4672 - val_loss: 114.0548\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.5887 - val_loss: 107.4497\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.0926 - val_loss: 105.3646\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.2929 - val_loss: 104.5419\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 99.3247 - val_loss: 105.8443\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 98.2837 - val_loss: 102.5503\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.6172 - val_loss: 100.8824\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 96.7157 - val_loss: 102.5989\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.8862 - val_loss: 99.0708\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 93.2440 - val_loss: 100.1126\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.6890 - val_loss: 98.0848\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.8226 - val_loss: 97.6034\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  12 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 5455.6514 - val_loss: 2027.2145\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1403.0464 - val_loss: 715.7902\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 777.9066 - val_loss: 621.3704\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 695.3668 - val_loss: 567.3971\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 628.6490 - val_loss: 507.3617\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 571.6950 - val_loss: 472.5865\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 536.9823 - val_loss: 455.0941\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 511.6461 - val_loss: 442.4869\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 488.2014 - val_loss: 430.1240\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 468.2445 - val_loss: 418.8716\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 451.9764 - val_loss: 407.0815\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 435.4984 - val_loss: 391.5700\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 418.9538 - val_loss: 377.4628\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 402.7128 - val_loss: 361.6627\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 386.7413 - val_loss: 342.6414\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 365.1714 - val_loss: 321.7062\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 345.6968 - val_loss: 295.7802\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 320.4439 - val_loss: 271.2033\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 302.3587 - val_loss: 253.4608\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 283.9921 - val_loss: 241.5140\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.1036 - val_loss: 227.3993\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.4553 - val_loss: 211.8860\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 230.6961 - val_loss: 201.1760\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.7079 - val_loss: 190.6486\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.2794 - val_loss: 182.8631\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.1916 - val_loss: 177.7734\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 188.3523 - val_loss: 169.7209\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.8165 - val_loss: 163.6096\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.8589 - val_loss: 159.1758\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 167.7489 - val_loss: 153.7204\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.5669 - val_loss: 149.6892\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 159.0248 - val_loss: 145.8956\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 152.9963 - val_loss: 142.6224\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.9061 - val_loss: 137.3993\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 144.3543 - val_loss: 134.7823\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.4778 - val_loss: 133.6363\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.4665 - val_loss: 129.0719\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.6808 - val_loss: 127.6298\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8494 - val_loss: 125.4067\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.2391 - val_loss: 123.5267\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.3040 - val_loss: 121.8509\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 121.4614 - val_loss: 119.6839\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.1150 - val_loss: 120.8024\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.4239 - val_loss: 118.5691\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.9220 - val_loss: 117.3153\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.2180 - val_loss: 115.9436\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 110.1772 - val_loss: 114.3695\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2510 - val_loss: 113.1795\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 106.6581 - val_loss: 113.7441\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.2397 - val_loss: 113.9048\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  13 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1547.8492 - val_loss: 1646.7070\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1546.5568 - val_loss: 1645.5234\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1545.4199 - val_loss: 1644.3386\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1544.2944 - val_loss: 1643.1470\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1543.1643 - val_loss: 1641.9595\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1542.0317 - val_loss: 1640.7812\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1540.9033 - val_loss: 1639.6034\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1539.7770 - val_loss: 1638.4232\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1538.6549 - val_loss: 1637.2393\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1537.5222 - val_loss: 1636.0612\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1536.3961 - val_loss: 1634.8811\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1535.2687 - val_loss: 1633.7048\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1534.1570 - val_loss: 1632.5112\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1533.0244 - val_loss: 1631.3375\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1531.9004 - val_loss: 1630.1720\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1530.7817 - val_loss: 1629.0034\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1529.6660 - val_loss: 1627.8292\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1528.5444 - val_loss: 1626.6602\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1527.4307 - val_loss: 1625.4845\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1526.3077 - val_loss: 1624.3175\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1525.1964 - val_loss: 1623.1388\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1524.0839 - val_loss: 1621.9589\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1522.9563 - val_loss: 1620.8063\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1521.8533 - val_loss: 1619.6312\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1520.7312 - val_loss: 1618.4712\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1519.6273 - val_loss: 1617.2961\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1518.5037 - val_loss: 1616.1399\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1517.4058 - val_loss: 1614.9624\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1516.2803 - val_loss: 1613.8099\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1515.1740 - val_loss: 1612.6482\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1514.0623 - val_loss: 1611.4879\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1512.9564 - val_loss: 1610.3206\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1511.8462 - val_loss: 1609.1531\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1510.7363 - val_loss: 1607.9906\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1509.6324 - val_loss: 1606.8230\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1508.5216 - val_loss: 1605.6661\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1507.4139 - val_loss: 1604.5123\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1506.3135 - val_loss: 1603.3507\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1505.2098 - val_loss: 1602.1886\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1504.0973 - val_loss: 1601.0442\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1502.9971 - val_loss: 1599.8945\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1501.9017 - val_loss: 1598.7291\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1500.7950 - val_loss: 1597.5759\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1499.7008 - val_loss: 1596.4108\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1498.5928 - val_loss: 1595.2649\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1497.4957 - val_loss: 1594.1177\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1496.3940 - val_loss: 1592.9705\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1495.3035 - val_loss: 1591.8102\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1494.2072 - val_loss: 1590.6488\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1493.0918 - val_loss: 1589.5198\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  14 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 2648.6062 - val_loss: 1519.0820\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1118.6957 - val_loss: 841.4083\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 746.5854 - val_loss: 646.8108\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 620.8489 - val_loss: 550.1664\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 542.6754 - val_loss: 479.7632\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 488.1172 - val_loss: 425.0223\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 441.3400 - val_loss: 386.9938\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 411.0614 - val_loss: 356.6560\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 379.5294 - val_loss: 336.9740\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 359.6981 - val_loss: 315.4980\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.1770 - val_loss: 298.7350\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 315.8732 - val_loss: 279.6168\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 298.0591 - val_loss: 264.0541\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 281.2239 - val_loss: 252.7822\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 270.2465 - val_loss: 240.3491\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.8010 - val_loss: 231.8552\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.0476 - val_loss: 221.5905\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 241.4719 - val_loss: 213.0596\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.0079 - val_loss: 207.8123\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.9374 - val_loss: 197.7370\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.7179 - val_loss: 191.0481\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.1166 - val_loss: 184.0876\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.4610 - val_loss: 178.6123\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 196.7030 - val_loss: 176.0646\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.5376 - val_loss: 171.6907\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 185.3879 - val_loss: 164.2919\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 178.3208 - val_loss: 164.0981\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.7549 - val_loss: 156.5272\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.3580 - val_loss: 153.9263\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.5132 - val_loss: 151.3844\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 162.7848 - val_loss: 147.0254\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.2111 - val_loss: 145.3758\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 159.1401 - val_loss: 144.0681\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.4823 - val_loss: 139.7255\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.8662 - val_loss: 138.5817\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.6535 - val_loss: 134.9551\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.5006 - val_loss: 138.4733\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.6047 - val_loss: 135.2431\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.9993 - val_loss: 132.9274\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.5935 - val_loss: 128.1092\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.5630 - val_loss: 127.3195\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.1582 - val_loss: 128.5253\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.0013 - val_loss: 133.0962\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 135.9564 - val_loss: 125.8051\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.0269 - val_loss: 122.2089\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.3354 - val_loss: 121.0144\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.9888 - val_loss: 120.8274\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.1599 - val_loss: 117.3458\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.4048 - val_loss: 114.8866\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 124.0671 - val_loss: 119.8958\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  15 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 2094.2334 - val_loss: 1177.8359\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 912.1873 - val_loss: 713.9197\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 691.8813 - val_loss: 632.4588\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 578.7401 - val_loss: 519.0354\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 469.5297 - val_loss: 417.8870\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 374.4541 - val_loss: 327.3311\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 309.5184 - val_loss: 269.6698\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 270.2449 - val_loss: 243.3015\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 246.3529 - val_loss: 217.2409\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.1013 - val_loss: 204.8169\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.4258 - val_loss: 186.4527\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 201.7837 - val_loss: 175.4544\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.6457 - val_loss: 167.4472\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.9904 - val_loss: 162.2762\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.4126 - val_loss: 169.7882\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.6302 - val_loss: 156.7299\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.7202 - val_loss: 149.1869\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 160.9039 - val_loss: 148.1898\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.6313 - val_loss: 143.9325\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.0579 - val_loss: 144.5611\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.2551 - val_loss: 140.4523\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.2436 - val_loss: 144.1630\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 146.3443 - val_loss: 139.4111\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.8651 - val_loss: 133.9694\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 139.1301 - val_loss: 137.5542\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.5441 - val_loss: 132.9460\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.1331 - val_loss: 129.8368\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.2119 - val_loss: 128.0480\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.1880 - val_loss: 127.6153\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 131.6617 - val_loss: 126.1141\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.0223 - val_loss: 125.0983\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 127.0202 - val_loss: 123.9719\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.2203 - val_loss: 122.3405\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.4660 - val_loss: 123.1322\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.3860 - val_loss: 121.5358\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 121.5428 - val_loss: 120.0145\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.1752 - val_loss: 118.2454\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.5169 - val_loss: 115.6466\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.3932 - val_loss: 113.3633\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.4450 - val_loss: 114.4044\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 113.5535 - val_loss: 116.7166\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.2879 - val_loss: 113.1081\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.5829 - val_loss: 110.6746\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.4707 - val_loss: 110.2762\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.5669 - val_loss: 109.9458\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 107.5001 - val_loss: 115.0779\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.1429 - val_loss: 111.4558\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.7938 - val_loss: 109.9796\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 104.7748 - val_loss: 108.3693\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.4656 - val_loss: 107.3861\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  16 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 6295.2461 - val_loss: 1286.6653\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 596.9841 - val_loss: 670.0188\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 567.8284 - val_loss: 521.6797\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 410.1930 - val_loss: 483.8083\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 373.7540 - val_loss: 443.3116\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 346.5359 - val_loss: 408.4972\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 324.8417 - val_loss: 383.7991\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 306.6790 - val_loss: 360.0307\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 291.9176 - val_loss: 345.1977\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.2126 - val_loss: 328.6754\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 268.9790 - val_loss: 315.9852\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.8276 - val_loss: 301.4545\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.6886 - val_loss: 289.9190\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.7560 - val_loss: 277.8415\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 230.4334 - val_loss: 268.4826\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 224.3277 - val_loss: 259.0505\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.7645 - val_loss: 250.5131\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 212.9298 - val_loss: 243.7846\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.1977 - val_loss: 237.4591\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.7855 - val_loss: 231.2846\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.4767 - val_loss: 225.8753\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.5139 - val_loss: 220.2737\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.2778 - val_loss: 215.4341\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.5463 - val_loss: 210.7506\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.4195 - val_loss: 205.9933\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.3447 - val_loss: 200.8518\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.2296 - val_loss: 196.4780\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 173.5134 - val_loss: 192.8519\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 170.7038 - val_loss: 189.3449\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.3005 - val_loss: 185.2055\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.5901 - val_loss: 182.3995\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 163.0420 - val_loss: 178.7569\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.0865 - val_loss: 176.4239\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.8758 - val_loss: 173.6892\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.1746 - val_loss: 170.2055\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.1731 - val_loss: 167.6835\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.0036 - val_loss: 165.2552\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.1435 - val_loss: 162.7511\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.7230 - val_loss: 160.5066\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.3134 - val_loss: 158.9390\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.9913 - val_loss: 157.5695\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.9123 - val_loss: 156.6760\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.8001 - val_loss: 154.9416\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.8671 - val_loss: 153.5018\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.8038 - val_loss: 152.4010\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 136.6507 - val_loss: 151.0106\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.7994 - val_loss: 151.6778\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.1452 - val_loss: 149.6894\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.6972 - val_loss: 147.6438\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.5808 - val_loss: 147.4044\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  17 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 3362.3811 - val_loss: 2385.4888\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1844.7224 - val_loss: 1208.9023\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 908.9107 - val_loss: 542.2274\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 433.8294 - val_loss: 314.2349\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 306.7585 - val_loss: 256.7108\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 255.5714 - val_loss: 231.8594\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.3304 - val_loss: 221.1181\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.1099 - val_loss: 208.7903\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 205.3820 - val_loss: 217.4583\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.1095 - val_loss: 193.4256\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 185.7169 - val_loss: 188.6700\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.3211 - val_loss: 181.9016\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.2874 - val_loss: 178.0751\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.7561 - val_loss: 170.0672\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.0250 - val_loss: 166.4379\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.2701 - val_loss: 162.3157\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.0119 - val_loss: 167.1884\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.0723 - val_loss: 158.6833\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.6695 - val_loss: 157.9540\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 141.8999 - val_loss: 150.8147\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 140.7807 - val_loss: 147.2693\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.5527 - val_loss: 149.4972\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 134.1967 - val_loss: 145.6208\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 131.0156 - val_loss: 139.0862\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 128.5684 - val_loss: 139.7299\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.9047 - val_loss: 138.1653\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.1040 - val_loss: 135.0222\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.1190 - val_loss: 133.8852\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.6005 - val_loss: 133.5012\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 119.7730 - val_loss: 132.2542\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.1797 - val_loss: 138.0827\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1274 - val_loss: 128.5815\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.2059 - val_loss: 130.5343\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.4564 - val_loss: 128.3991\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.6759 - val_loss: 133.5041\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.0839 - val_loss: 125.8876\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.1483 - val_loss: 129.3415\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.7106 - val_loss: 123.1747\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.4576 - val_loss: 122.5897\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 109.3701 - val_loss: 121.7913\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 111.4349 - val_loss: 125.6385\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.5782 - val_loss: 117.3288\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3481 - val_loss: 120.8024\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 106.2333 - val_loss: 126.2284\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.0795 - val_loss: 125.3677\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 106.8270 - val_loss: 119.4125\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.6734 - val_loss: 116.5110\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.9612 - val_loss: 118.9588\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 101.7316 - val_loss: 121.0303\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.6674 - val_loss: 117.9223\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  18 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 156619.3906 - val_loss: 71585.0703\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 35931.1875 - val_loss: 12655.8379\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7249.1230 - val_loss: 4885.6763\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4987.0225 - val_loss: 4662.0620\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4607.3174 - val_loss: 4127.0806\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4096.6548 - val_loss: 3857.0146\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3769.8086 - val_loss: 3575.5378\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3471.3755 - val_loss: 3270.5178\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 3165.5364 - val_loss: 2983.7666\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2881.3738 - val_loss: 2693.5837\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2579.2864 - val_loss: 2427.0588\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2311.6104 - val_loss: 2175.5603\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2064.6301 - val_loss: 1964.9396\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1851.0004 - val_loss: 1757.5205\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1675.1382 - val_loss: 1582.0634\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1503.8245 - val_loss: 1413.6670\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1352.3920 - val_loss: 1261.5928\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1227.5450 - val_loss: 1134.9805\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1126.3635 - val_loss: 1066.6344\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1022.7186 - val_loss: 945.3918\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 945.8754 - val_loss: 883.3889\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 871.8284 - val_loss: 811.3913\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 829.6630 - val_loss: 752.0117\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 772.8170 - val_loss: 716.4629\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 722.5507 - val_loss: 658.7122\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 681.3558 - val_loss: 611.8267\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 611.2267 - val_loss: 546.5049\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 560.4808 - val_loss: 494.7713\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 505.4919 - val_loss: 446.9151\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 476.5087 - val_loss: 418.7678\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 445.5761 - val_loss: 387.2019\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 425.4248 - val_loss: 368.5159\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 418.6942 - val_loss: 360.5274\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.3584 - val_loss: 337.1542\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 378.2551 - val_loss: 336.7858\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 375.3474 - val_loss: 313.9780\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 359.9843 - val_loss: 304.9292\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 345.8271 - val_loss: 309.8690\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 340.6207 - val_loss: 288.7832\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 326.2904 - val_loss: 283.5913\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 315.3086 - val_loss: 276.8792\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 308.9474 - val_loss: 271.3939\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 302.6676 - val_loss: 265.9659\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 298.6905 - val_loss: 262.0083\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.2348 - val_loss: 256.9969\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.7982 - val_loss: 264.5239\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.7933 - val_loss: 255.2190\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 275.0059 - val_loss: 245.9953\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 266.0939 - val_loss: 242.6260\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.8889 - val_loss: 247.5312\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  19 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 6207.5015 - val_loss: 731.1223\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 526.2646 - val_loss: 597.7195\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 434.8271 - val_loss: 300.0642\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.7063 - val_loss: 276.0467\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.5144 - val_loss: 275.1900\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.5743 - val_loss: 264.9068\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 273.5317 - val_loss: 255.2122\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 265.0104 - val_loss: 247.1914\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 260.3745 - val_loss: 246.6837\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.9920 - val_loss: 235.3817\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.5377 - val_loss: 235.9934\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.1832 - val_loss: 225.3681\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.9681 - val_loss: 223.6540\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 230.4121 - val_loss: 214.7656\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.0759 - val_loss: 212.3976\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.8268 - val_loss: 204.8110\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 213.2076 - val_loss: 202.1191\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206.0238 - val_loss: 193.4566\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 201.8448 - val_loss: 189.3354\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.9948 - val_loss: 183.7395\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.4183 - val_loss: 178.4668\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.3091 - val_loss: 173.0715\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.6811 - val_loss: 166.3475\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.3852 - val_loss: 158.0178\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.6036 - val_loss: 154.0722\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.3425 - val_loss: 147.0862\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.9070 - val_loss: 142.9217\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.2895 - val_loss: 141.3974\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.4376 - val_loss: 138.3104\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5737 - val_loss: 135.8546\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.9079 - val_loss: 132.6679\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.9708 - val_loss: 131.4200\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.6162 - val_loss: 128.5088\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.8160 - val_loss: 131.9620\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 137.9988 - val_loss: 126.6584\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.4066 - val_loss: 131.7023\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.8237 - val_loss: 124.7008\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.1072 - val_loss: 131.7291\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.3644 - val_loss: 124.3678\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 132.8087 - val_loss: 123.0467\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.0024 - val_loss: 122.5691\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.5334 - val_loss: 121.5711\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.3521 - val_loss: 121.0644\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 129.7785 - val_loss: 123.3372\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.6065 - val_loss: 125.8355\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.5325 - val_loss: 120.8309\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.3466 - val_loss: 119.6745\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.6633 - val_loss: 118.8916\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.9110 - val_loss: 122.5714\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.4681 - val_loss: 116.5594\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  20 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 39807.3711 - val_loss: 16614.0195\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 7365.0005 - val_loss: 2385.5149\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1678.3319 - val_loss: 2045.2714\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1775.2415 - val_loss: 1786.0914\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1484.4248 - val_loss: 1635.4971\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1403.3291 - val_loss: 1549.0535\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1324.8617 - val_loss: 1454.1842\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1254.4277 - val_loss: 1366.8751\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1185.5068 - val_loss: 1281.3335\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1115.8442 - val_loss: 1205.5935\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1057.0833 - val_loss: 1131.1973\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 992.4693 - val_loss: 1063.9929\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 937.1534 - val_loss: 1000.0779\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 882.2851 - val_loss: 941.3466\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 834.8149 - val_loss: 883.2791\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 789.2921 - val_loss: 827.5402\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 740.2830 - val_loss: 780.7520\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 700.3749 - val_loss: 732.6347\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 660.4639 - val_loss: 688.7116\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 629.4731 - val_loss: 646.9339\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 588.5419 - val_loss: 613.4459\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 558.2292 - val_loss: 572.1210\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 524.9676 - val_loss: 539.6371\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 497.4579 - val_loss: 505.9847\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 469.9476 - val_loss: 478.9753\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 445.7227 - val_loss: 449.2866\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 420.6234 - val_loss: 424.7515\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.3767 - val_loss: 399.3370\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 376.7863 - val_loss: 377.0315\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 357.3741 - val_loss: 356.6330\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 338.5070 - val_loss: 338.6402\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 322.5343 - val_loss: 319.4902\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 305.7941 - val_loss: 302.7421\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.7253 - val_loss: 287.1113\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 276.8197 - val_loss: 272.6937\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 264.8649 - val_loss: 259.0723\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.2169 - val_loss: 246.4493\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 242.6896 - val_loss: 234.9057\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.7899 - val_loss: 224.4314\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.5580 - val_loss: 214.7159\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 213.6415 - val_loss: 205.6928\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.9319 - val_loss: 197.4063\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.0770 - val_loss: 189.4849\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.2102 - val_loss: 182.8311\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.3429 - val_loss: 176.4936\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.9930 - val_loss: 170.9645\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 170.3431 - val_loss: 165.2175\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.4800 - val_loss: 160.5627\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 159.1762 - val_loss: 155.7400\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.3221 - val_loss: 151.8975\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  21 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 142702.6562 - val_loss: 73436.1953\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 43515.6836 - val_loss: 13806.8574\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6284.8677 - val_loss: 1170.5132\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1589.8022 - val_loss: 1642.1556\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1592.9561 - val_loss: 1123.3364\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1278.9139 - val_loss: 934.8214\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1184.5325 - val_loss: 874.8995\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1101.5645 - val_loss: 826.5793\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1029.5066 - val_loss: 777.1672\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 965.1407 - val_loss: 729.7147\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 906.3915 - val_loss: 690.0099\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 849.1303 - val_loss: 656.3669\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 808.4828 - val_loss: 618.1910\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 748.0148 - val_loss: 590.2543\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 703.8763 - val_loss: 562.8070\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 663.2774 - val_loss: 538.1770\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 623.7272 - val_loss: 513.8557\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 591.7839 - val_loss: 492.9545\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 558.0120 - val_loss: 473.6805\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 526.8162 - val_loss: 454.6276\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 499.9532 - val_loss: 436.8563\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 472.4808 - val_loss: 421.0683\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 448.1163 - val_loss: 401.3094\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.2132 - val_loss: 385.4596\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 403.9183 - val_loss: 371.0582\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 386.8263 - val_loss: 355.4645\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.5770 - val_loss: 342.7371\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 352.0483 - val_loss: 330.4648\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 336.8746 - val_loss: 317.8161\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 325.3612 - val_loss: 308.8096\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 311.8603 - val_loss: 298.0360\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.6974 - val_loss: 288.0681\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.2678 - val_loss: 278.2378\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.3134 - val_loss: 270.0408\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.7195 - val_loss: 261.6047\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.8206 - val_loss: 254.5047\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 252.1501 - val_loss: 246.9738\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.0343 - val_loss: 240.5622\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 237.5671 - val_loss: 235.6823\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 230.7246 - val_loss: 228.1638\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 224.3833 - val_loss: 223.7779\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 219.3753 - val_loss: 218.7284\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 213.6422 - val_loss: 214.2879\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.7534 - val_loss: 210.0542\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 204.8754 - val_loss: 205.4819\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.6044 - val_loss: 201.9279\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.7114 - val_loss: 199.0627\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.3382 - val_loss: 195.9806\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 188.5775 - val_loss: 191.8308\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.8454 - val_loss: 188.9200\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  22 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 6125.4971 - val_loss: 2784.1238\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1467.2943 - val_loss: 628.6559\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 363.4857 - val_loss: 287.6227\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 245.2650 - val_loss: 274.0958\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.0223 - val_loss: 269.4503\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.2657 - val_loss: 263.3653\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.4023 - val_loss: 259.7991\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 231.5276 - val_loss: 256.7547\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.4270 - val_loss: 251.7913\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.6701 - val_loss: 250.3160\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.4494 - val_loss: 246.9576\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 224.6368 - val_loss: 246.7865\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.6979 - val_loss: 245.1743\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.1501 - val_loss: 242.7901\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.9579 - val_loss: 240.3440\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 215.7258 - val_loss: 237.7840\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.9916 - val_loss: 236.3582\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 210.4368 - val_loss: 231.9816\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.6483 - val_loss: 224.0417\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.9333 - val_loss: 214.4120\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.8642 - val_loss: 206.2436\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.9012 - val_loss: 197.5984\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 178.6808 - val_loss: 188.4172\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 174.6878 - val_loss: 182.1050\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.8976 - val_loss: 175.9511\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.7160 - val_loss: 173.5145\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 160.5735 - val_loss: 167.6765\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.5516 - val_loss: 165.4882\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.7699 - val_loss: 162.2890\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.7256 - val_loss: 159.4316\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.8707 - val_loss: 156.6202\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.0659 - val_loss: 154.3887\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.0099 - val_loss: 152.3817\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.9906 - val_loss: 150.9209\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.2225 - val_loss: 151.3862\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.2681 - val_loss: 145.3800\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.3971 - val_loss: 144.7068\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.8209 - val_loss: 140.8145\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.0423 - val_loss: 139.3319\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.5472 - val_loss: 138.4169\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.0340 - val_loss: 136.6339\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.1373 - val_loss: 134.6971\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.3388 - val_loss: 134.6813\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.0005 - val_loss: 133.2831\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.5019 - val_loss: 132.2700\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.8836 - val_loss: 129.1909\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.1262 - val_loss: 128.1438\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.3936 - val_loss: 126.2865\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.8441 - val_loss: 126.9691\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.2632 - val_loss: 124.8215\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  23 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 17512.0234 - val_loss: 7959.1187\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3500.6587 - val_loss: 1029.6427\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1068.8939 - val_loss: 1019.7236\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 853.2936 - val_loss: 844.8990\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 732.9511 - val_loss: 751.3543\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 650.3903 - val_loss: 652.8722\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 575.0263 - val_loss: 565.5153\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 503.1252 - val_loss: 506.5573\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 463.2176 - val_loss: 475.1580\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 437.5341 - val_loss: 445.9296\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 409.9586 - val_loss: 422.9683\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 387.6039 - val_loss: 394.1679\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 365.9568 - val_loss: 374.0597\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 347.7894 - val_loss: 352.6845\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 331.6833 - val_loss: 336.6660\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 319.3078 - val_loss: 324.0281\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 307.0472 - val_loss: 306.9388\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 297.2816 - val_loss: 296.4727\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.2299 - val_loss: 287.2378\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.3313 - val_loss: 277.5814\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.5801 - val_loss: 266.6338\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 258.1968 - val_loss: 258.3546\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.4067 - val_loss: 251.3837\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 238.0017 - val_loss: 238.1752\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.9719 - val_loss: 231.9648\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.6768 - val_loss: 219.9507\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 211.7069 - val_loss: 216.2844\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 201.1591 - val_loss: 205.6523\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.4857 - val_loss: 196.8757\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.9059 - val_loss: 191.7747\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.7462 - val_loss: 180.9136\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.2747 - val_loss: 172.1923\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.3971 - val_loss: 164.7471\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.7633 - val_loss: 159.2141\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.8120 - val_loss: 151.3519\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.5764 - val_loss: 149.3354\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.9757 - val_loss: 142.4747\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 130.1706 - val_loss: 138.2416\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.0918 - val_loss: 133.8562\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.5748 - val_loss: 132.9806\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.1268 - val_loss: 126.3184\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.3968 - val_loss: 122.3961\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.3871 - val_loss: 124.3113\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.4505 - val_loss: 123.1504\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.5243 - val_loss: 114.8774\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.0385 - val_loss: 113.3171\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.1742 - val_loss: 110.8562\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.0201 - val_loss: 113.1720\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.2869 - val_loss: 111.8244\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2555 - val_loss: 106.4155\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  24 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 4211.5229 - val_loss: 3898.8872\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3030.7292 - val_loss: 2953.8284\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2375.4377 - val_loss: 2314.0032\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1836.8507 - val_loss: 1787.9921\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1390.0559 - val_loss: 1349.7596\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1016.9506 - val_loss: 1029.4285\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 764.2814 - val_loss: 769.7836\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 574.7633 - val_loss: 604.9050\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 454.7668 - val_loss: 487.8123\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.6425 - val_loss: 419.2397\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 323.1675 - val_loss: 369.9449\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 289.0931 - val_loss: 334.2328\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 264.6495 - val_loss: 308.8817\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.2012 - val_loss: 288.9373\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.9398 - val_loss: 288.8383\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 224.9900 - val_loss: 256.2538\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 209.9457 - val_loss: 245.0446\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.3288 - val_loss: 229.8465\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 195.6798 - val_loss: 219.6029\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.8376 - val_loss: 214.7663\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.1267 - val_loss: 207.3715\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.2770 - val_loss: 194.8814\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 169.7823 - val_loss: 188.1678\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.4758 - val_loss: 185.3572\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.6775 - val_loss: 179.0873\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.3503 - val_loss: 180.2934\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.2823 - val_loss: 165.0634\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.4234 - val_loss: 156.8156\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.8314 - val_loss: 152.0267\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.6767 - val_loss: 145.5996\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.5935 - val_loss: 141.4290\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.2762 - val_loss: 137.2967\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.9380 - val_loss: 131.8037\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.6949 - val_loss: 126.9566\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.2147 - val_loss: 122.2990\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.9392 - val_loss: 119.5297\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.3326 - val_loss: 115.4312\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.7204 - val_loss: 115.2544\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.9796 - val_loss: 112.2115\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.0025 - val_loss: 112.6697\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.1629 - val_loss: 105.2446\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.7494 - val_loss: 102.5413\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.6720 - val_loss: 101.6158\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.1313 - val_loss: 98.9730\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.3319 - val_loss: 96.8998\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.4631 - val_loss: 94.7733\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.9848 - val_loss: 92.3166\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.3438 - val_loss: 94.4389\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6166 - val_loss: 90.5436\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.8414 - val_loss: 89.8400\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  25 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1363.9873 - val_loss: 566.9660\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 388.7956 - val_loss: 418.2647\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.5704 - val_loss: 395.2336\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.7052 - val_loss: 397.6007\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316.7722 - val_loss: 374.1620\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 304.3114 - val_loss: 359.7519\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.9752 - val_loss: 342.6999\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.8773 - val_loss: 291.7510\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.2644 - val_loss: 272.3615\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.2493 - val_loss: 249.9263\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.7314 - val_loss: 242.7193\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.2899 - val_loss: 235.6927\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.7103 - val_loss: 228.2863\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.7840 - val_loss: 228.0454\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.5726 - val_loss: 217.3327\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.2006 - val_loss: 216.9911\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.3589 - val_loss: 210.8094\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.6600 - val_loss: 202.6018\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.3309 - val_loss: 198.5699\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.3238 - val_loss: 193.1782\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.1481 - val_loss: 190.2542\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.8109 - val_loss: 183.1239\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.7590 - val_loss: 181.2085\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.6461 - val_loss: 174.6313\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.0264 - val_loss: 171.1387\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.8313 - val_loss: 167.7773\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.2115 - val_loss: 166.2571\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.7747 - val_loss: 163.1162\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.4049 - val_loss: 157.3190\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.4094 - val_loss: 154.3098\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.3248 - val_loss: 152.1980\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.0390 - val_loss: 147.4014\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3039 - val_loss: 146.2454\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.5718 - val_loss: 143.9465\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.5669 - val_loss: 138.9986\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.9412 - val_loss: 139.4466\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5818 - val_loss: 134.2902\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 102.6607 - val_loss: 132.9667\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.4716 - val_loss: 131.4638\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.9436 - val_loss: 129.5133\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.3524 - val_loss: 127.5191\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.0858 - val_loss: 125.0999\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.8506 - val_loss: 123.3175\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.0968 - val_loss: 121.1301\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.6366 - val_loss: 119.6684\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.9468 - val_loss: 118.9739\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.2969 - val_loss: 117.2549\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.1452 - val_loss: 116.8865\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.1586 - val_loss: 116.6176\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 86.2215 - val_loss: 113.1046\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  26 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 691.1490 - val_loss: 700.3482\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 531.8427 - val_loss: 556.3774\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 436.5602 - val_loss: 473.6485\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 376.3457 - val_loss: 412.6914\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.7038 - val_loss: 368.2716\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 299.7616 - val_loss: 338.8830\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.5691 - val_loss: 314.2876\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.4425 - val_loss: 292.9911\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.8114 - val_loss: 276.5756\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.3447 - val_loss: 262.8083\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 213.2894 - val_loss: 250.8778\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.4063 - val_loss: 238.3580\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.5587 - val_loss: 235.6065\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.8535 - val_loss: 219.7727\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.3089 - val_loss: 211.1764\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.4843 - val_loss: 203.8237\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.2120 - val_loss: 199.1711\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.7451 - val_loss: 191.1199\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.8108 - val_loss: 201.8270\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.0706 - val_loss: 184.0919\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.9130 - val_loss: 176.6230\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.5113 - val_loss: 169.1479\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.3596 - val_loss: 164.5938\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.2626 - val_loss: 160.5237\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.6116 - val_loss: 156.6780\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.2760 - val_loss: 153.4667\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.7447 - val_loss: 149.9766\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.2285 - val_loss: 149.5211\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.4820 - val_loss: 150.3478\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.8611 - val_loss: 166.0664\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.7393 - val_loss: 142.3179\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2981 - val_loss: 137.5464\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.8928 - val_loss: 136.6861\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.1512 - val_loss: 135.3422\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.0404 - val_loss: 132.1204\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.2613 - val_loss: 132.4898\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.3498 - val_loss: 128.3413\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.4613 - val_loss: 126.6549\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.8503 - val_loss: 126.2410\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.4668 - val_loss: 126.1837\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.1657 - val_loss: 128.1471\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.0151 - val_loss: 121.6373\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.0424 - val_loss: 122.4746\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8456 - val_loss: 119.3759\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.4526 - val_loss: 119.4485\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.6189 - val_loss: 118.1299\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8077 - val_loss: 124.3344\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 112.7839 - val_loss: 121.2451\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4100 - val_loss: 125.7148\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.8430 - val_loss: 115.5045\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 224502.8906 - val_loss: 168795.8594\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124938.4219 - val_loss: 86638.3281\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 60857.3594 - val_loss: 39152.2109\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 25279.5234 - val_loss: 14396.9863\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8301.5293 - val_loss: 3961.6199\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2094.3018 - val_loss: 992.0918\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 733.0793 - val_loss: 527.4949\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 598.1671 - val_loss: 496.8091\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 589.4904 - val_loss: 489.5299\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 576.3234 - val_loss: 487.8646\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 561.5359 - val_loss: 480.3040\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 549.8309 - val_loss: 469.9617\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 539.0410 - val_loss: 462.7388\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 527.9778 - val_loss: 458.4048\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 516.0252 - val_loss: 448.4939\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 503.9484 - val_loss: 436.2838\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 493.5266 - val_loss: 427.3722\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 482.2617 - val_loss: 422.1223\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 471.5105 - val_loss: 414.1731\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 460.1455 - val_loss: 406.4378\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 449.3588 - val_loss: 398.8251\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 439.3275 - val_loss: 391.7061\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 428.7059 - val_loss: 383.7602\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 418.9412 - val_loss: 375.0872\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 410.2474 - val_loss: 371.2274\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 399.6254 - val_loss: 362.7924\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 390.7798 - val_loss: 355.2540\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 383.6241 - val_loss: 351.5435\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 373.1114 - val_loss: 343.0167\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 365.2683 - val_loss: 336.5088\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 357.0796 - val_loss: 333.5252\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 349.0002 - val_loss: 327.9732\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 341.5824 - val_loss: 322.5086\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 333.8926 - val_loss: 316.9413\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 327.6566 - val_loss: 310.8067\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 320.9650 - val_loss: 308.7328\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 314.4265 - val_loss: 304.2580\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.0857 - val_loss: 296.9569\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 300.8601 - val_loss: 294.1794\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 295.1926 - val_loss: 290.9096\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.3055 - val_loss: 289.2532\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 284.2399 - val_loss: 282.1029\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 278.3223 - val_loss: 279.8423\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.4232 - val_loss: 274.8497\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 268.1024 - val_loss: 274.2458\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.1472 - val_loss: 269.3295\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.9163 - val_loss: 266.3958\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.8778 - val_loss: 262.3795\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.0543 - val_loss: 260.8371\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.6565 - val_loss: 257.8508\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 998.5071 - val_loss: 594.6831\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 509.8757 - val_loss: 427.9010\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 370.9819 - val_loss: 372.0372\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 337.9183 - val_loss: 370.6784\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316.5060 - val_loss: 356.9419\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 308.8297 - val_loss: 344.4342\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.6219 - val_loss: 344.4896\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.3799 - val_loss: 338.1679\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 286.5759 - val_loss: 333.4566\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.5914 - val_loss: 326.1528\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 279.9561 - val_loss: 332.8802\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.3840 - val_loss: 314.6853\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 268.6638 - val_loss: 308.3932\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.0536 - val_loss: 308.0353\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 262.4627 - val_loss: 302.3706\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.3075 - val_loss: 289.1955\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.9107 - val_loss: 285.3235\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.1341 - val_loss: 291.9042\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.8308 - val_loss: 274.0924\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 243.1370 - val_loss: 264.3356\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.2607 - val_loss: 268.9238\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.9875 - val_loss: 252.9200\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.4981 - val_loss: 252.7620\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.5175 - val_loss: 239.2358\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.2270 - val_loss: 241.7668\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.7059 - val_loss: 228.3115\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.9821 - val_loss: 244.3385\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 216.1728 - val_loss: 217.0251\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.4396 - val_loss: 212.6299\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.5339 - val_loss: 222.6628\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.4152 - val_loss: 205.3605\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.7730 - val_loss: 205.4616\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.5821 - val_loss: 203.9687\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.5029 - val_loss: 191.0215\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 185.0023 - val_loss: 200.7072\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.6394 - val_loss: 184.4626\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.2706 - val_loss: 192.0968\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 176.0193 - val_loss: 175.6886\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.1204 - val_loss: 165.7239\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.4015 - val_loss: 161.7408\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.4071 - val_loss: 172.9202\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.2509 - val_loss: 155.1274\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.9200 - val_loss: 167.3069\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.4958 - val_loss: 154.4648\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.9829 - val_loss: 152.4045\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.8241 - val_loss: 144.9965\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.3830 - val_loss: 146.9532\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.7733 - val_loss: 141.0177\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.4977 - val_loss: 138.1110\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.6748 - val_loss: 136.7545\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 26670.4746 - val_loss: 8436.2705\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4073.5867 - val_loss: 1444.9742\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1565.9364 - val_loss: 1848.7551\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1450.6840 - val_loss: 1261.3242\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1172.5402 - val_loss: 1056.6826\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1061.8339 - val_loss: 960.7797\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 957.4819 - val_loss: 861.7911\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 865.1957 - val_loss: 781.7941\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 784.0875 - val_loss: 686.6057\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 713.4354 - val_loss: 624.7517\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 649.7211 - val_loss: 555.0621\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 596.3378 - val_loss: 512.0390\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 545.4060 - val_loss: 461.7947\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 508.2231 - val_loss: 427.2678\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 475.6927 - val_loss: 405.3668\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 446.3840 - val_loss: 371.5167\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 423.9266 - val_loss: 348.0150\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 404.7921 - val_loss: 335.1487\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 388.0935 - val_loss: 317.3401\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 373.8326 - val_loss: 303.2550\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 358.9976 - val_loss: 295.9116\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 324.8807 - val_loss: 280.1035\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 286.9081 - val_loss: 248.1776\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.3267 - val_loss: 236.9315\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.4336 - val_loss: 228.2702\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.2861 - val_loss: 206.2484\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.6646 - val_loss: 210.0672\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.3502 - val_loss: 193.1128\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.4394 - val_loss: 185.3770\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 194.1211 - val_loss: 184.3771\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.9888 - val_loss: 174.4835\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.4568 - val_loss: 166.4933\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.9249 - val_loss: 162.7160\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.1721 - val_loss: 161.0525\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.0259 - val_loss: 160.4626\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.4533 - val_loss: 149.2109\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.0117 - val_loss: 143.2437\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.3551 - val_loss: 140.9887\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.2715 - val_loss: 136.5028\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.7871 - val_loss: 136.3634\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.4635 - val_loss: 130.1674\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.0914 - val_loss: 130.1440\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.7020 - val_loss: 126.7808\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.6662 - val_loss: 120.9636\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.4985 - val_loss: 119.5643\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.6945 - val_loss: 119.6686\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.9336 - val_loss: 117.3469\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.0167 - val_loss: 113.2997\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.8725 - val_loss: 114.5000\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.0022 - val_loss: 109.8621\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 4031.4583 - val_loss: 1739.6155\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1228.7800 - val_loss: 586.9073\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 583.0661 - val_loss: 476.7636\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 513.3131 - val_loss: 440.8542\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 448.1270 - val_loss: 386.3011\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 399.8784 - val_loss: 365.2161\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 362.9253 - val_loss: 337.9242\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 334.3840 - val_loss: 320.1993\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.8570 - val_loss: 297.1402\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 281.6151 - val_loss: 274.0674\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.4294 - val_loss: 246.1504\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.5867 - val_loss: 217.1486\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.9166 - val_loss: 191.5937\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 197.0036 - val_loss: 174.8112\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.5370 - val_loss: 159.2848\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.3012 - val_loss: 150.2668\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.0533 - val_loss: 143.4127\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.3719 - val_loss: 136.8145\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.1565 - val_loss: 131.5172\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.7494 - val_loss: 127.5691\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.0929 - val_loss: 123.3222\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.2782 - val_loss: 117.4614\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.5395 - val_loss: 115.2278\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.0010 - val_loss: 110.7668\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.7468 - val_loss: 108.1978\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.7996 - val_loss: 106.6909\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.6363 - val_loss: 104.6208\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.9681 - val_loss: 102.7037\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.7456 - val_loss: 101.3996\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.0268 - val_loss: 101.1685\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.9563 - val_loss: 98.9549\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.1173 - val_loss: 97.6316\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.6615 - val_loss: 96.6886\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.1368 - val_loss: 95.8549\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6321 - val_loss: 96.2931\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.0132 - val_loss: 95.3882\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.8731 - val_loss: 94.3251\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.7391 - val_loss: 93.5600\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.5825 - val_loss: 92.8489\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.4031 - val_loss: 94.7678\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.3795 - val_loss: 92.4009\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.1276 - val_loss: 92.8351\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.5950 - val_loss: 91.5152\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.3521 - val_loss: 94.7337\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.9856 - val_loss: 90.8232\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6283 - val_loss: 92.0707\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.8593 - val_loss: 89.5236\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.3374 - val_loss: 88.7165\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.6331 - val_loss: 88.0827\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.1081 - val_loss: 87.4951\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 3607.0691 - val_loss: 430.7221\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343.6622 - val_loss: 499.0739\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 304.6908 - val_loss: 286.6602\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 238.1348 - val_loss: 283.8158\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.0312 - val_loss: 256.8376\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.0556 - val_loss: 236.3929\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.1472 - val_loss: 228.9419\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.4100 - val_loss: 222.2085\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.7659 - val_loss: 217.0121\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.6292 - val_loss: 213.7682\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.9424 - val_loss: 210.1972\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.5426 - val_loss: 206.5830\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.5439 - val_loss: 200.8994\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.4857 - val_loss: 199.3503\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 168.8029 - val_loss: 193.5325\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.6715 - val_loss: 190.6194\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.0835 - val_loss: 189.0094\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.0559 - val_loss: 182.8326\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.2496 - val_loss: 182.9458\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.5802 - val_loss: 179.5583\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.8547 - val_loss: 174.4025\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.9461 - val_loss: 173.5227\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.2284 - val_loss: 169.9822\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.4333 - val_loss: 167.0742\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.6856 - val_loss: 167.0242\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.1518 - val_loss: 163.1985\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.3804 - val_loss: 167.3032\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3471 - val_loss: 161.3510\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.5171 - val_loss: 159.5360\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.2498 - val_loss: 165.8280\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.2906 - val_loss: 156.7482\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.1983 - val_loss: 156.3631\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.7450 - val_loss: 154.6905\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.0744 - val_loss: 160.6047\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.6606 - val_loss: 152.7430\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.9469 - val_loss: 157.4610\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.2837 - val_loss: 151.7000\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.7627 - val_loss: 157.5173\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.9991 - val_loss: 154.1336\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.0066 - val_loss: 151.0040\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.5169 - val_loss: 150.4217\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2921 - val_loss: 154.6591\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.5483 - val_loss: 150.5352\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.0016 - val_loss: 153.6097\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.7441 - val_loss: 154.2154\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.6742 - val_loss: 151.2992\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.3865 - val_loss: 148.3258\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.7062 - val_loss: 145.9315\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.0778 - val_loss: 146.3403\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.8042 - val_loss: 145.7003\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 25920.9707 - val_loss: 11423.3906\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5460.9907 - val_loss: 1440.9414\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 690.3483 - val_loss: 425.9720\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 506.4918 - val_loss: 441.4802\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 458.2173 - val_loss: 389.9161\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 423.7592 - val_loss: 388.7135\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 416.7852 - val_loss: 378.9341\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 410.2925 - val_loss: 371.7964\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 405.0101 - val_loss: 365.5172\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 399.4110 - val_loss: 359.7565\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 394.5043 - val_loss: 354.9660\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 388.6441 - val_loss: 347.8923\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 383.8463 - val_loss: 343.2124\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 378.6370 - val_loss: 337.7037\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 373.9810 - val_loss: 332.6896\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 368.5881 - val_loss: 327.4233\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 363.1745 - val_loss: 321.6576\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 358.5085 - val_loss: 318.0413\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 353.7401 - val_loss: 311.9926\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 348.4222 - val_loss: 308.3908\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 344.8927 - val_loss: 303.4062\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 340.2578 - val_loss: 298.6685\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335.1766 - val_loss: 294.9594\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 330.5489 - val_loss: 290.7820\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 326.1711 - val_loss: 287.2402\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 321.9744 - val_loss: 282.8558\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 317.7986 - val_loss: 277.9039\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 314.1311 - val_loss: 274.4620\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.1301 - val_loss: 271.0322\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 306.4778 - val_loss: 267.2552\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 302.6238 - val_loss: 262.6748\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 299.5209 - val_loss: 261.0804\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 294.3519 - val_loss: 256.3392\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 291.3142 - val_loss: 253.2759\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.7496 - val_loss: 249.7029\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 285.1602 - val_loss: 246.5356\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.8541 - val_loss: 246.1451\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.6460 - val_loss: 240.9430\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.7967 - val_loss: 237.9744\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 271.7747 - val_loss: 235.3763\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.2605 - val_loss: 233.1624\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.2675 - val_loss: 229.4404\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.7553 - val_loss: 227.9147\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.6272 - val_loss: 224.7416\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.5075 - val_loss: 221.8325\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.3059 - val_loss: 219.7145\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.9338 - val_loss: 217.2884\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.7817 - val_loss: 214.3266\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.4305 - val_loss: 213.6693\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 246.0860 - val_loss: 209.7683\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 16782.5332 - val_loss: 11693.8613\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8282.0586 - val_loss: 5736.4424\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4068.0398 - val_loss: 2932.8335\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2132.0559 - val_loss: 1635.3704\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1263.7202 - val_loss: 1020.0500\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 892.6021 - val_loss: 720.8879\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 742.9653 - val_loss: 607.1464\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 672.7917 - val_loss: 565.0667\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 623.4557 - val_loss: 531.4581\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 586.5463 - val_loss: 510.9083\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 548.4465 - val_loss: 474.4078\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 512.6269 - val_loss: 448.9457\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 484.8691 - val_loss: 424.1258\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 451.7232 - val_loss: 404.8403\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 430.2728 - val_loss: 382.1627\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 404.5573 - val_loss: 369.8503\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 383.1351 - val_loss: 342.4300\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 364.9412 - val_loss: 318.8754\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 341.7508 - val_loss: 299.6617\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 325.9577 - val_loss: 280.6528\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.2263 - val_loss: 262.5514\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.4849 - val_loss: 246.4798\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.6026 - val_loss: 232.0904\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.3584 - val_loss: 220.5755\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.1634 - val_loss: 213.4329\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.7687 - val_loss: 202.0670\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.2969 - val_loss: 192.7528\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.5761 - val_loss: 186.2289\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.8196 - val_loss: 181.2717\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.9974 - val_loss: 175.9538\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.4267 - val_loss: 171.5262\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.6698 - val_loss: 169.1021\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.1921 - val_loss: 164.2267\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.4646 - val_loss: 160.8774\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.2630 - val_loss: 161.1224\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.3206 - val_loss: 156.3133\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.2475 - val_loss: 156.0215\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.8321 - val_loss: 155.4638\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.0120 - val_loss: 150.9193\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.3298 - val_loss: 148.3878\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.0386 - val_loss: 146.7415\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.3602 - val_loss: 145.9946\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.5157 - val_loss: 144.0385\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.0357 - val_loss: 143.0148\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.0041 - val_loss: 142.2890\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.8351 - val_loss: 144.1066\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.6686 - val_loss: 139.9824\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.3789 - val_loss: 141.5214\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.5511 - val_loss: 138.7825\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.7135 - val_loss: 140.1422\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 992.0138 - val_loss: 629.3920\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 516.2761 - val_loss: 474.7541\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 417.7283 - val_loss: 441.8777\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 395.2237 - val_loss: 423.3409\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 375.0703 - val_loss: 405.4343\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.6385 - val_loss: 375.8578\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.2410 - val_loss: 349.4030\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316.7254 - val_loss: 326.3766\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 296.1787 - val_loss: 301.8169\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.8100 - val_loss: 279.7413\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.4169 - val_loss: 260.4636\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.3251 - val_loss: 249.7952\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.0664 - val_loss: 226.2923\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.9435 - val_loss: 211.5644\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.5790 - val_loss: 194.9172\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.4360 - val_loss: 190.5854\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.1825 - val_loss: 172.2338\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.3766 - val_loss: 166.3562\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.4404 - val_loss: 160.0056\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.7178 - val_loss: 149.7474\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.5586 - val_loss: 138.3187\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.5782 - val_loss: 136.8194\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6751 - val_loss: 140.3754\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.2388 - val_loss: 122.5403\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.0709 - val_loss: 122.7359\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.4878 - val_loss: 117.2641\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.5297 - val_loss: 117.0965\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.1619 - val_loss: 110.3179\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5605 - val_loss: 108.2344\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.0104 - val_loss: 106.0655\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.1016 - val_loss: 109.0190\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.1387 - val_loss: 103.2469\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 88.2848 - val_loss: 108.8052\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.9683 - val_loss: 101.0241\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84.8357 - val_loss: 104.4988\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.8445 - val_loss: 104.0893\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.8919 - val_loss: 103.9173\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84.7434 - val_loss: 99.9393\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.7340 - val_loss: 97.5898\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 83.4924 - val_loss: 99.3860\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 82.4638 - val_loss: 98.5375\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.5771 - val_loss: 96.1447\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.8156 - val_loss: 95.4619\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.8524 - val_loss: 101.0561\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.6662 - val_loss: 97.5393\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.5366 - val_loss: 97.4660\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.8235 - val_loss: 99.0399\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 79.2015 - val_loss: 93.1826\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.7584 - val_loss: 93.6802\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 78.8275 - val_loss: 93.1693\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 1730.8684 - val_loss: 417.9522\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 381.3741 - val_loss: 358.3763\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 346.6840 - val_loss: 299.7157\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 313.8258 - val_loss: 296.1209\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.5939 - val_loss: 288.3600\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 295.0457 - val_loss: 281.9650\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.5698 - val_loss: 275.9128\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.7450 - val_loss: 270.2643\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.4858 - val_loss: 264.9158\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.6365 - val_loss: 259.5617\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.5696 - val_loss: 254.7499\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.8374 - val_loss: 250.1359\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.8710 - val_loss: 245.6900\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.7783 - val_loss: 241.2915\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.1850 - val_loss: 237.5072\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.7068 - val_loss: 233.2838\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 228.7960 - val_loss: 229.5968\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 223.7837 - val_loss: 226.2124\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.8500 - val_loss: 222.0394\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.1873 - val_loss: 218.8529\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.9180 - val_loss: 215.7772\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.2858 - val_loss: 212.4595\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.4793 - val_loss: 209.4902\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.2524 - val_loss: 205.7344\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.7887 - val_loss: 203.4941\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.1187 - val_loss: 200.3479\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.2577 - val_loss: 197.5417\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.0291 - val_loss: 194.2295\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.7727 - val_loss: 191.8573\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.3752 - val_loss: 189.0187\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.6141 - val_loss: 186.5884\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.8489 - val_loss: 184.0133\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.9367 - val_loss: 181.6703\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.2328 - val_loss: 178.9608\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.8957 - val_loss: 177.2929\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.6263 - val_loss: 174.3543\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.5645 - val_loss: 175.2373\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.0531 - val_loss: 172.3598\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.1559 - val_loss: 169.0265\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.6682 - val_loss: 165.8387\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.5417 - val_loss: 164.6587\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.6447 - val_loss: 161.5109\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.1640 - val_loss: 159.8931\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.2219 - val_loss: 157.3140\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.1822 - val_loss: 154.7973\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.9577 - val_loss: 153.5732\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.8357 - val_loss: 152.1964\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.2782 - val_loss: 149.8852\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5698 - val_loss: 147.5213\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.2760 - val_loss: 145.6351\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 546.3020 - val_loss: 329.0164\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328.5258 - val_loss: 277.7930\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.7662 - val_loss: 243.6356\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.1257 - val_loss: 236.0688\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.4028 - val_loss: 229.0262\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.1921 - val_loss: 225.9526\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.3516 - val_loss: 217.4255\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.8025 - val_loss: 213.6615\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 231.7147 - val_loss: 201.0854\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.9577 - val_loss: 175.1476\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.1971 - val_loss: 153.2807\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.5253 - val_loss: 142.4098\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.1238 - val_loss: 136.5990\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.0093 - val_loss: 133.3201\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.9040 - val_loss: 130.0209\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.4921 - val_loss: 126.9089\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3525 - val_loss: 126.7802\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.6065 - val_loss: 125.6326\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.1549 - val_loss: 123.8970\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.7691 - val_loss: 121.7242\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.8398 - val_loss: 120.5250\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.2568 - val_loss: 124.1780\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.2285 - val_loss: 117.6936\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.8570 - val_loss: 116.6750\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.8644 - val_loss: 115.3524\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.3246 - val_loss: 112.9948\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.3266 - val_loss: 122.5379\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.1973 - val_loss: 110.9925\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.4159 - val_loss: 110.6351\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.9310 - val_loss: 109.1237\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.4666 - val_loss: 107.5822\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.0797 - val_loss: 107.3851\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.1198 - val_loss: 105.5732\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.0992 - val_loss: 103.8415\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.1607 - val_loss: 108.2550\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4329 - val_loss: 101.3410\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.2288 - val_loss: 101.3559\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.7162 - val_loss: 99.3284\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.5997 - val_loss: 98.3377\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.7064 - val_loss: 98.9687\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.2090 - val_loss: 95.8869\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.3278 - val_loss: 95.1640\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.0240 - val_loss: 95.6883\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.1314 - val_loss: 93.8623\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.5416 - val_loss: 93.8640\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.6425 - val_loss: 90.8347\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.6460 - val_loss: 96.1484\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.5172 - val_loss: 88.5161\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.6548 - val_loss: 89.2818\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.2657 - val_loss: 90.8433\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 126033.9141 - val_loss: 61193.9258\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 34681.4023 - val_loss: 13251.3271\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7209.0439 - val_loss: 4660.6294\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3737.5293 - val_loss: 4203.5723\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3079.7283 - val_loss: 3192.3237\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2662.0115 - val_loss: 2927.0615\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2400.5425 - val_loss: 2684.5122\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2174.9961 - val_loss: 2415.1814\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1935.9214 - val_loss: 2101.1975\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1649.8256 - val_loss: 1775.2771\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1395.0818 - val_loss: 1516.3367\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1210.2021 - val_loss: 1330.8213\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1041.5287 - val_loss: 1125.8792\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 900.3493 - val_loss: 971.6481\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 793.8412 - val_loss: 827.6511\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 689.4396 - val_loss: 667.0304\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 589.8940 - val_loss: 558.7076\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 517.2337 - val_loss: 462.7196\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 459.7794 - val_loss: 403.0544\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420.9761 - val_loss: 354.7117\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.0016 - val_loss: 316.7255\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 345.2407 - val_loss: 291.8879\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.0813 - val_loss: 263.8269\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 286.2168 - val_loss: 234.0618\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.6544 - val_loss: 209.1105\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.8642 - val_loss: 186.9199\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.8004 - val_loss: 169.5665\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.2590 - val_loss: 155.9099\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.3002 - val_loss: 151.7848\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.2604 - val_loss: 148.6143\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.6072 - val_loss: 134.2570\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.0332 - val_loss: 129.7471\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.2407 - val_loss: 135.8784\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.6114 - val_loss: 122.6155\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.3786 - val_loss: 121.7139\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9286 - val_loss: 128.9662\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.8984 - val_loss: 121.6451\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.7616 - val_loss: 115.0580\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.3369 - val_loss: 115.5632\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.3533 - val_loss: 108.9202\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.2069 - val_loss: 107.7481\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.6999 - val_loss: 116.1617\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.4652 - val_loss: 106.0622\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.8216 - val_loss: 103.6241\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.0802 - val_loss: 101.6173\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.0833 - val_loss: 101.6941\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.0523 - val_loss: 110.3767\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.2804 - val_loss: 96.5511\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.2861 - val_loss: 96.0029\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.7406 - val_loss: 94.4338\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 27997.9395 - val_loss: 18378.9062\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13031.3584 - val_loss: 8191.1572\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5708.1338 - val_loss: 3511.4663\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2464.7998 - val_loss: 1493.4618\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1090.4707 - val_loss: 713.6426\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 567.5691 - val_loss: 435.3267\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 374.0827 - val_loss: 324.9199\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.3380 - val_loss: 273.0081\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.9634 - val_loss: 248.7683\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.1813 - val_loss: 238.7133\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.5627 - val_loss: 234.1083\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.7280 - val_loss: 231.5587\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 228.9650 - val_loss: 229.2189\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.5861 - val_loss: 227.1849\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.6849 - val_loss: 226.1680\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.5006 - val_loss: 225.5166\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.7258 - val_loss: 224.5856\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.8859 - val_loss: 223.7955\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.2214 - val_loss: 223.1504\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.4707 - val_loss: 222.4144\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.9113 - val_loss: 221.5052\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.2335 - val_loss: 221.0737\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.7980 - val_loss: 220.3351\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219.3964 - val_loss: 220.1313\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.8072 - val_loss: 219.3419\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.3457 - val_loss: 218.6097\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.0459 - val_loss: 218.7879\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.7586 - val_loss: 218.0776\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.8784 - val_loss: 217.8404\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.4971 - val_loss: 217.5942\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.1491 - val_loss: 217.2276\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.7850 - val_loss: 216.8968\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 215.3557 - val_loss: 216.5748\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 215.0366 - val_loss: 216.0820\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.7464 - val_loss: 215.8383\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.3683 - val_loss: 215.2437\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.0856 - val_loss: 215.2203\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.6970 - val_loss: 214.5235\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.5369 - val_loss: 214.5744\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 213.0996 - val_loss: 213.8395\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.6375 - val_loss: 213.8717\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.4198 - val_loss: 213.1085\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.9027 - val_loss: 213.1185\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.5051 - val_loss: 212.8171\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 211.3156 - val_loss: 212.3159\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.6714 - val_loss: 211.5348\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 210.6963 - val_loss: 211.8096\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.2160 - val_loss: 211.1524\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.8355 - val_loss: 210.7453\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 209.4326 - val_loss: 210.7576\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 348138.7812 - val_loss: 247097.3438\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178671.6250 - val_loss: 120978.7344\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83700.8672 - val_loss: 53805.4531\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 35302.0508 - val_loss: 21569.7852\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13340.1689 - val_loss: 7879.3438\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4693.3364 - val_loss: 3115.9854\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1983.2264 - val_loss: 1738.8767\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1291.2987 - val_loss: 1397.8132\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1147.9814 - val_loss: 1256.2094\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1064.1327 - val_loss: 1161.0013\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1013.6951 - val_loss: 1103.1472\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 951.3902 - val_loss: 1013.2092\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 878.8820 - val_loss: 940.6441\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 804.2368 - val_loss: 854.0706\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 739.5033 - val_loss: 794.9114\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 700.4995 - val_loss: 759.2692\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 670.5569 - val_loss: 728.4111\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 645.3527 - val_loss: 699.9210\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 629.3826 - val_loss: 674.0798\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 606.6060 - val_loss: 656.2180\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 590.6681 - val_loss: 634.4667\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 575.7779 - val_loss: 620.3998\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 562.3151 - val_loss: 598.4735\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 548.6115 - val_loss: 579.2696\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 534.2343 - val_loss: 568.1634\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 519.6022 - val_loss: 550.1476\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 507.9747 - val_loss: 534.4134\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 495.5924 - val_loss: 519.4841\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 485.7785 - val_loss: 504.2508\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 474.7193 - val_loss: 496.3582\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 464.7932 - val_loss: 484.6598\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 456.2859 - val_loss: 470.0249\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 446.9443 - val_loss: 459.4278\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 438.4978 - val_loss: 450.6881\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 432.1161 - val_loss: 443.1086\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.4993 - val_loss: 433.4795\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420.8331 - val_loss: 427.9894\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 414.4211 - val_loss: 419.3692\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 410.0317 - val_loss: 411.7792\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 405.2766 - val_loss: 404.7263\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 400.8044 - val_loss: 398.2909\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 395.9431 - val_loss: 395.3559\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 393.8588 - val_loss: 388.6813\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 388.6443 - val_loss: 383.9909\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 384.7739 - val_loss: 378.5040\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 384.0528 - val_loss: 372.1524\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 379.9427 - val_loss: 371.5640\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 375.2506 - val_loss: 361.1578\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.1837 - val_loss: 358.2264\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.3613 - val_loss: 354.0674\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 3936.2178 - val_loss: 1171.7197\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1199.0125 - val_loss: 1147.3596\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1026.9281 - val_loss: 906.8546\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 859.8068 - val_loss: 807.5110\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 738.5878 - val_loss: 712.3740\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 628.3899 - val_loss: 604.4841\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 506.7111 - val_loss: 521.7790\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 441.5592 - val_loss: 460.2423\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 379.4409 - val_loss: 417.8399\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 336.8717 - val_loss: 384.4309\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.7814 - val_loss: 352.1959\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.5495 - val_loss: 329.1755\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.3967 - val_loss: 307.7111\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.2252 - val_loss: 290.0032\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.7501 - val_loss: 272.8355\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.8949 - val_loss: 255.5941\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.9862 - val_loss: 247.4746\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.1251 - val_loss: 234.5521\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.5013 - val_loss: 226.8331\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.6769 - val_loss: 216.6367\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.5634 - val_loss: 213.1103\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.0544 - val_loss: 205.1266\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.2526 - val_loss: 197.5050\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.2692 - val_loss: 192.3142\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.4930 - val_loss: 185.6362\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.9395 - val_loss: 179.5311\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.6257 - val_loss: 174.7870\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.3786 - val_loss: 171.0668\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.9246 - val_loss: 166.5328\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.0657 - val_loss: 170.7257\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.1157 - val_loss: 159.4854\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.3992 - val_loss: 157.4205\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.4684 - val_loss: 154.4375\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.1519 - val_loss: 152.6771\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6153 - val_loss: 149.8784\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.8268 - val_loss: 147.8900\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6588 - val_loss: 148.9921\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.0723 - val_loss: 147.5413\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.3104 - val_loss: 143.2416\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.5165 - val_loss: 140.8167\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.6761 - val_loss: 140.1628\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6417 - val_loss: 144.8848\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.1909 - val_loss: 137.5254\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.6204 - val_loss: 135.3032\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.3339 - val_loss: 136.0422\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.3341 - val_loss: 131.4588\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.3968 - val_loss: 130.4424\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.6156 - val_loss: 128.8390\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0103 - val_loss: 130.2102\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.0062 - val_loss: 126.3751\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 10412.7012 - val_loss: 3392.4998\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1613.6316 - val_loss: 1503.7134\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1206.3522 - val_loss: 1005.7416\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 812.7218 - val_loss: 813.5901\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 647.3007 - val_loss: 655.7303\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 562.4598 - val_loss: 576.5081\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 505.6172 - val_loss: 527.5480\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 462.4059 - val_loss: 479.3429\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 424.6029 - val_loss: 435.1967\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 393.2846 - val_loss: 405.9478\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.0901 - val_loss: 384.2839\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 347.5210 - val_loss: 363.4260\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.9906 - val_loss: 341.4680\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 309.9234 - val_loss: 322.3488\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.7992 - val_loss: 307.6115\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 273.3508 - val_loss: 288.8912\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 255.6593 - val_loss: 271.1432\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.2243 - val_loss: 253.4790\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.5374 - val_loss: 236.2271\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.9675 - val_loss: 221.7741\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.7790 - val_loss: 206.5991\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.9313 - val_loss: 195.1148\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.3709 - val_loss: 187.1259\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.5016 - val_loss: 177.1163\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.1722 - val_loss: 168.7636\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.6480 - val_loss: 163.1557\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.9942 - val_loss: 156.3395\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.7109 - val_loss: 152.2517\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3354 - val_loss: 148.1376\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.9993 - val_loss: 142.6528\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.5010 - val_loss: 140.3600\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.0737 - val_loss: 138.1497\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.9113 - val_loss: 134.6219\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.2313 - val_loss: 131.9652\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.9707 - val_loss: 132.8673\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.9799 - val_loss: 129.4366\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.7248 - val_loss: 126.8740\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.1553 - val_loss: 127.9379\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.6237 - val_loss: 127.8115\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0376 - val_loss: 124.1984\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.8412 - val_loss: 122.7060\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.8498 - val_loss: 121.7162\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6417 - val_loss: 121.4346\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.0460 - val_loss: 120.8363\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.9016 - val_loss: 117.8924\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2958 - val_loss: 116.3069\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.2910 - val_loss: 114.3290\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.7566 - val_loss: 113.9572\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.8309 - val_loss: 114.4676\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0085 - val_loss: 110.9420\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 8218.0068 - val_loss: 1571.5024\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1485.5527 - val_loss: 1612.7115\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1122.1566 - val_loss: 801.0942\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 736.9758 - val_loss: 586.5281\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 569.5253 - val_loss: 538.1864\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 526.7023 - val_loss: 491.1296\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 483.1352 - val_loss: 459.7351\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 445.9370 - val_loss: 434.2195\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 417.0945 - val_loss: 407.2273\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 393.7559 - val_loss: 391.8319\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 373.3535 - val_loss: 368.7198\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.6118 - val_loss: 348.5628\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 338.1949 - val_loss: 338.2852\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.7870 - val_loss: 323.8287\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 309.1484 - val_loss: 314.1249\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.2887 - val_loss: 297.6805\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.6746 - val_loss: 299.4674\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 276.3722 - val_loss: 279.3548\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.1359 - val_loss: 276.8083\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.0456 - val_loss: 267.0989\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.2839 - val_loss: 262.4458\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.2099 - val_loss: 250.8309\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.5694 - val_loss: 245.9375\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.9672 - val_loss: 259.2577\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.8021 - val_loss: 234.2597\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.2228 - val_loss: 238.6385\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.1758 - val_loss: 233.5728\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.6368 - val_loss: 219.8548\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 209.7075 - val_loss: 213.1766\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.8482 - val_loss: 211.0986\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.7899 - val_loss: 207.8510\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.9670 - val_loss: 202.6499\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.6063 - val_loss: 202.4844\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.9992 - val_loss: 197.3852\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.8244 - val_loss: 196.1783\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.3932 - val_loss: 186.6775\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.4500 - val_loss: 186.2274\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.2569 - val_loss: 188.3287\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.1406 - val_loss: 178.2435\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.9989 - val_loss: 179.2191\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.3253 - val_loss: 173.5932\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.5913 - val_loss: 176.6954\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.2235 - val_loss: 178.9915\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.0010 - val_loss: 165.3285\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.0661 - val_loss: 163.5747\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.8382 - val_loss: 164.5832\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5724 - val_loss: 159.2366\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.7451 - val_loss: 156.1720\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.8106 - val_loss: 154.4264\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.5696 - val_loss: 168.6161\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 6518.4111 - val_loss: 3971.4536\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2225.2568 - val_loss: 1208.7916\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 673.4520 - val_loss: 389.1575\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.2442 - val_loss: 217.3879\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.1624 - val_loss: 198.1318\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197.0329 - val_loss: 189.3401\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.5828 - val_loss: 183.9648\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.0400 - val_loss: 179.5359\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.2492 - val_loss: 175.8809\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.5416 - val_loss: 172.2737\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.3880 - val_loss: 170.8901\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 173.3005 - val_loss: 169.1579\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.0897 - val_loss: 168.0845\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 169.4536 - val_loss: 166.9283\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.8476 - val_loss: 165.9622\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.0243 - val_loss: 167.3057\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.8433 - val_loss: 166.2160\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.0891 - val_loss: 165.3321\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.3022 - val_loss: 167.6791\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.9776 - val_loss: 164.8868\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.0154 - val_loss: 166.0013\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.5386 - val_loss: 165.5270\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.6629 - val_loss: 165.0498\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.1978 - val_loss: 163.3494\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.1083 - val_loss: 164.2908\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.6233 - val_loss: 162.0392\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.5273 - val_loss: 162.9669\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.0477 - val_loss: 161.5846\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.8113 - val_loss: 162.2966\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.1116 - val_loss: 160.8665\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.2765 - val_loss: 160.1537\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.7993 - val_loss: 157.2581\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.3399 - val_loss: 160.4457\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.2076 - val_loss: 156.9741\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.3409 - val_loss: 157.4900\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.3156 - val_loss: 154.7825\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.5889 - val_loss: 158.4611\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.7480 - val_loss: 153.2760\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.4353 - val_loss: 154.5133\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.2340 - val_loss: 150.7064\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.8500 - val_loss: 153.7059\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.4986 - val_loss: 149.5796\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.2365 - val_loss: 148.5812\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.9454 - val_loss: 149.4312\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.3210 - val_loss: 146.0202\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.9248 - val_loss: 145.6695\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.6586 - val_loss: 144.8594\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9118 - val_loss: 145.0984\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.0441 - val_loss: 144.8494\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.2026 - val_loss: 143.9179\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 73444.4531 - val_loss: 45664.3086\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 36104.1328 - val_loss: 22878.0371\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 18883.1074 - val_loss: 12540.9014\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10739.5059 - val_loss: 7374.2061\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6448.3765 - val_loss: 4420.0654\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3896.5505 - val_loss: 2650.8057\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2292.1582 - val_loss: 1555.6000\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1317.5875 - val_loss: 908.6226\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 787.5594 - val_loss: 597.0920\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 565.3385 - val_loss: 492.7295\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 506.7430 - val_loss: 457.6074\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 476.9434 - val_loss: 443.2336\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 462.8345 - val_loss: 429.7630\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 450.9240 - val_loss: 416.3356\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 438.4475 - val_loss: 405.7262\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 428.0716 - val_loss: 395.5042\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 418.1349 - val_loss: 385.5937\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 409.1878 - val_loss: 375.7340\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 399.7344 - val_loss: 367.6613\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 391.6462 - val_loss: 358.9697\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 383.4684 - val_loss: 351.9223\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 376.0035 - val_loss: 344.3721\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 369.3129 - val_loss: 337.2444\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.4151 - val_loss: 331.6702\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.8076 - val_loss: 324.0992\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 349.0825 - val_loss: 318.2992\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 342.7467 - val_loss: 312.2789\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 336.6579 - val_loss: 305.5125\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 330.6431 - val_loss: 299.6603\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 324.6526 - val_loss: 294.2085\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.2697 - val_loss: 289.0424\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 313.5627 - val_loss: 283.4647\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 307.8750 - val_loss: 278.0104\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.0569 - val_loss: 272.5084\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.9420 - val_loss: 268.5959\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.1525 - val_loss: 262.4305\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 287.9807 - val_loss: 256.7316\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.8657 - val_loss: 252.4148\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.0559 - val_loss: 247.2439\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.0007 - val_loss: 242.6666\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.9960 - val_loss: 238.0509\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263.6559 - val_loss: 232.0262\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.8084 - val_loss: 229.8983\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 254.3718 - val_loss: 223.6954\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.0993 - val_loss: 220.5524\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.4760 - val_loss: 218.2254\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.4055 - val_loss: 214.3804\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.4152 - val_loss: 211.5887\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.3340 - val_loss: 208.7038\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.1283 - val_loss: 205.3384\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 38150.7578 - val_loss: 21470.1914\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12615.0820 - val_loss: 6832.7178\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4021.7085 - val_loss: 2222.1682\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1379.3685 - val_loss: 924.8758\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 788.4148 - val_loss: 711.1601\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 703.2218 - val_loss: 629.5876\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 624.0659 - val_loss: 569.5142\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 576.4194 - val_loss: 528.7485\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 540.1578 - val_loss: 497.0336\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 509.9534 - val_loss: 462.9717\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 479.9958 - val_loss: 441.8668\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 460.4846 - val_loss: 428.2634\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 445.3046 - val_loss: 411.0608\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 431.3753 - val_loss: 403.2841\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.3292 - val_loss: 390.6956\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 412.2130 - val_loss: 379.4775\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 402.8231 - val_loss: 373.2548\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 395.8904 - val_loss: 367.3790\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 388.5739 - val_loss: 357.9770\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 382.6837 - val_loss: 352.8796\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 376.4926 - val_loss: 347.5947\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 372.5268 - val_loss: 343.5127\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 366.6081 - val_loss: 335.7209\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.0424 - val_loss: 335.1698\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 357.7581 - val_loss: 329.2314\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 354.0287 - val_loss: 327.4820\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 350.2924 - val_loss: 323.4185\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 347.2267 - val_loss: 321.1611\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343.5797 - val_loss: 318.1805\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 340.7134 - val_loss: 315.8716\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 338.0168 - val_loss: 312.9736\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 335.3200 - val_loss: 311.3554\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.1055 - val_loss: 308.0009\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 330.2218 - val_loss: 306.7626\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 327.6447 - val_loss: 302.4154\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.5553 - val_loss: 300.7907\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 322.9556 - val_loss: 299.6214\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 320.1961 - val_loss: 296.3972\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 317.7829 - val_loss: 293.3851\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.0142 - val_loss: 294.1220\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 313.7030 - val_loss: 289.4290\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.4424 - val_loss: 287.3256\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.2458 - val_loss: 286.5411\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304.6219 - val_loss: 281.7229\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 302.9819 - val_loss: 280.3730\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 301.1573 - val_loss: 278.6624\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.0203 - val_loss: 276.7309\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.8422 - val_loss: 275.2412\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.6632 - val_loss: 272.0180\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 289.9660 - val_loss: 269.0936\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 7687.9614 - val_loss: 2614.9038\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2320.7349 - val_loss: 2253.9402\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1986.4270 - val_loss: 1762.1111\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1643.9850 - val_loss: 1593.5983\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1469.3643 - val_loss: 1431.0599\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1311.6621 - val_loss: 1292.2065\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1179.7161 - val_loss: 1171.0315\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1062.8623 - val_loss: 1060.6471\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 951.9761 - val_loss: 962.4185\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 859.1180 - val_loss: 877.2379\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 782.1241 - val_loss: 802.5918\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 704.3342 - val_loss: 737.0518\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 649.2989 - val_loss: 678.8501\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 592.1014 - val_loss: 620.4240\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 542.8849 - val_loss: 570.6335\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 496.8271 - val_loss: 534.7672\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 468.2036 - val_loss: 509.6792\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 441.7198 - val_loss: 481.2459\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 419.8206 - val_loss: 460.0188\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 397.0627 - val_loss: 441.5190\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 381.0802 - val_loss: 423.8021\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.4442 - val_loss: 411.8550\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 351.3371 - val_loss: 397.1577\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 338.1781 - val_loss: 385.1102\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 327.7668 - val_loss: 373.5221\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 318.0436 - val_loss: 365.8832\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.1290 - val_loss: 353.9397\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 298.9083 - val_loss: 348.5519\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 290.8794 - val_loss: 339.1032\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.8711 - val_loss: 331.8145\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.6822 - val_loss: 324.4899\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.8812 - val_loss: 323.6294\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.7504 - val_loss: 311.4659\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 256.6180 - val_loss: 308.7968\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.4380 - val_loss: 301.9447\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.4850 - val_loss: 298.6069\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.5795 - val_loss: 292.1745\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.5600 - val_loss: 293.1100\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.5860 - val_loss: 279.1653\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.1510 - val_loss: 275.2553\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.8183 - val_loss: 271.9778\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.8494 - val_loss: 266.5750\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.4390 - val_loss: 262.2906\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.1786 - val_loss: 258.4373\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.5067 - val_loss: 254.6535\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.8552 - val_loss: 249.3471\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197.0070 - val_loss: 245.4234\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.0339 - val_loss: 242.1284\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.8507 - val_loss: 238.6858\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.6591 - val_loss: 233.9747\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 22336.2910 - val_loss: 15665.8594\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12364.4297 - val_loss: 8833.6465\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7087.6201 - val_loss: 5221.0322\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4224.9380 - val_loss: 3102.5100\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2475.2825 - val_loss: 1797.8030\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1412.1061 - val_loss: 1025.3291\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 800.5602 - val_loss: 608.0153\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 474.0193 - val_loss: 417.7111\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 337.6118 - val_loss: 344.3786\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.1962 - val_loss: 325.6146\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.5782 - val_loss: 321.1526\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.5076 - val_loss: 317.2470\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.5107 - val_loss: 313.5974\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.6785 - val_loss: 309.4973\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.7127 - val_loss: 305.5659\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.8747 - val_loss: 301.5986\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.8223 - val_loss: 297.7765\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.0228 - val_loss: 294.3237\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.9373 - val_loss: 289.9913\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.0995 - val_loss: 286.0714\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.1418 - val_loss: 282.4156\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.6473 - val_loss: 278.7203\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.8543 - val_loss: 275.3997\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.6747 - val_loss: 271.2933\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.0056 - val_loss: 267.7614\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.9524 - val_loss: 264.3519\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.3418 - val_loss: 260.3073\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.5139 - val_loss: 256.7101\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.6331 - val_loss: 253.3912\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.1620 - val_loss: 249.8496\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.5118 - val_loss: 246.9337\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.3053 - val_loss: 243.2516\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.6895 - val_loss: 240.0036\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.5616 - val_loss: 237.1669\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.9233 - val_loss: 234.0875\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.4668 - val_loss: 230.6881\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.5322 - val_loss: 227.9921\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.9259 - val_loss: 225.3433\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.3665 - val_loss: 222.1966\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.9321 - val_loss: 219.2793\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.5234 - val_loss: 216.6372\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.8506 - val_loss: 213.7822\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.3739 - val_loss: 210.4719\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.1069 - val_loss: 208.3369\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.7281 - val_loss: 205.0357\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.2545 - val_loss: 202.3753\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.8662 - val_loss: 199.7361\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.7598 - val_loss: 196.8424\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.4909 - val_loss: 194.4713\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.2945 - val_loss: 192.2560\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 10128.6182 - val_loss: 5816.4707\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3771.3125 - val_loss: 2320.5046\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1511.8182 - val_loss: 1180.4336\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 795.1459 - val_loss: 799.8770\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 572.6050 - val_loss: 659.4830\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 488.3647 - val_loss: 590.3957\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 447.3644 - val_loss: 544.5442\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 422.1858 - val_loss: 508.9343\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 398.8759 - val_loss: 481.2109\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 379.6954 - val_loss: 452.0361\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 360.0846 - val_loss: 427.4063\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 344.3701 - val_loss: 404.2763\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 329.1664 - val_loss: 383.6560\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.8409 - val_loss: 366.7059\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.2364 - val_loss: 347.3599\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.6235 - val_loss: 331.0623\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.0939 - val_loss: 314.2413\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.0643 - val_loss: 295.1582\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.5921 - val_loss: 274.6188\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.0464 - val_loss: 258.3462\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.5710 - val_loss: 245.1534\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.4065 - val_loss: 234.7116\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.5009 - val_loss: 225.7894\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.6073 - val_loss: 217.2042\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.3399 - val_loss: 210.5783\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.1794 - val_loss: 205.4480\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.3222 - val_loss: 201.5877\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.3231 - val_loss: 196.7474\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.3575 - val_loss: 192.9070\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.7721 - val_loss: 190.8256\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.6781 - val_loss: 186.1119\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.3769 - val_loss: 183.5043\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.9529 - val_loss: 182.4144\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.9581 - val_loss: 178.4732\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.2450 - val_loss: 175.8279\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.9740 - val_loss: 173.5718\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.8319 - val_loss: 171.8626\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.7459 - val_loss: 169.1116\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.0246 - val_loss: 167.3448\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.3650 - val_loss: 165.5406\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.8813 - val_loss: 164.7078\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.8522 - val_loss: 162.6409\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.9212 - val_loss: 162.0992\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.4291 - val_loss: 159.7894\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.9003 - val_loss: 158.5625\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.1649 - val_loss: 157.5863\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.7780 - val_loss: 156.3714\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.5756 - val_loss: 155.1924\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.5148 - val_loss: 154.5068\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.1136 - val_loss: 154.1035\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 365412.9375 - val_loss: 264092.4375\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207908.7500 - val_loss: 146522.0156\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114711.8750 - val_loss: 79605.9297\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65751.1406 - val_loss: 52963.8359\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 46261.6758 - val_loss: 37722.3867\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 31983.1270 - val_loss: 25678.9238\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 21360.4648 - val_loss: 17021.6758\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14221.2256 - val_loss: 11529.4912\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9606.2422 - val_loss: 7930.2397\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6571.7842 - val_loss: 5555.6963\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4607.5649 - val_loss: 4067.6587\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3471.6882 - val_loss: 3284.4629\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2901.4941 - val_loss: 2856.6965\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2586.1077 - val_loss: 2553.9546\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2341.6606 - val_loss: 2348.3562\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2176.3406 - val_loss: 2187.3132\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2043.5347 - val_loss: 2069.4451\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1938.3668 - val_loss: 1981.1613\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1855.4369 - val_loss: 1913.4910\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1796.6194 - val_loss: 1856.8203\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1749.9434 - val_loss: 1812.5450\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1711.0983 - val_loss: 1779.1610\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1679.2369 - val_loss: 1752.2943\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1655.0909 - val_loss: 1730.0264\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1632.9662 - val_loss: 1713.4316\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1615.5206 - val_loss: 1701.9607\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1603.9637 - val_loss: 1690.6097\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1592.7699 - val_loss: 1682.3848\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1583.7001 - val_loss: 1676.0944\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1576.2834 - val_loss: 1670.1201\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1570.1608 - val_loss: 1664.6705\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1564.3328 - val_loss: 1659.8112\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1559.1565 - val_loss: 1656.1307\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1554.6937 - val_loss: 1652.6229\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1550.3657 - val_loss: 1649.0106\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1546.1647 - val_loss: 1645.7709\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1542.4666 - val_loss: 1643.0875\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1539.7601 - val_loss: 1640.4272\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1537.3287 - val_loss: 1638.8680\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1536.0770 - val_loss: 1637.4688\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1534.8544 - val_loss: 1636.2797\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1533.6908 - val_loss: 1635.1769\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1532.6057 - val_loss: 1633.9869\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1531.5647 - val_loss: 1632.9978\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1530.7445 - val_loss: 1632.1261\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1529.9209 - val_loss: 1631.3002\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1529.0370 - val_loss: 1630.5674\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1528.2831 - val_loss: 1629.7452\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1527.5006 - val_loss: 1628.9601\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1526.7469 - val_loss: 1628.1656\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 128461.1406 - val_loss: 100389.4219\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78575.2266 - val_loss: 61338.7266\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 47085.5156 - val_loss: 35702.8125\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 25097.1328 - val_loss: 16398.8027\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10042.1240 - val_loss: 5231.3325\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3292.8789 - val_loss: 1679.7765\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1560.5237 - val_loss: 1080.4385\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1211.3999 - val_loss: 907.7857\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1038.6848 - val_loss: 785.8181\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 901.6924 - val_loss: 692.9152\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 786.1431 - val_loss: 621.1617\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 687.5571 - val_loss: 542.2551\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 610.1523 - val_loss: 499.7254\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 538.0727 - val_loss: 446.1169\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 482.6625 - val_loss: 404.2622\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 430.6734 - val_loss: 370.8199\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 389.3440 - val_loss: 343.8888\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.5448 - val_loss: 318.8194\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 324.0179 - val_loss: 301.3850\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 300.6952 - val_loss: 282.8248\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.3503 - val_loss: 272.7772\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263.7272 - val_loss: 261.8555\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.3543 - val_loss: 252.2739\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.8132 - val_loss: 245.4118\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.9641 - val_loss: 241.6150\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.8611 - val_loss: 236.2037\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.8234 - val_loss: 232.8459\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.5062 - val_loss: 231.9284\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.0884 - val_loss: 227.9107\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.7131 - val_loss: 226.7231\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.2666 - val_loss: 228.2666\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.0872 - val_loss: 224.9190\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.9889 - val_loss: 226.4303\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.4017 - val_loss: 226.7977\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.7402 - val_loss: 223.5492\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.1042 - val_loss: 223.3236\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 195.1469 - val_loss: 223.7015\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.4639 - val_loss: 223.1280\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.4260 - val_loss: 222.2213\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.0842 - val_loss: 224.0863\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.0359 - val_loss: 221.8836\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.4517 - val_loss: 222.6057\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.1735 - val_loss: 223.6487\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.3971 - val_loss: 220.5612\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.6730 - val_loss: 220.8089\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.6237 - val_loss: 221.5899\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.7699 - val_loss: 220.3779\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.5676 - val_loss: 219.4208\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.3404 - val_loss: 219.6217\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.0794 - val_loss: 219.6520\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total Execution Time :  0:04:10.086581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c54RzfrOfoD",
        "outputId": "66e3afab-b34f-4b6f-88a0-c08ae90683f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' + str(std_of_mse))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  270.403477162317\n",
            "Standard Deviation of MSE of 50 Models : 358.24049637148136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1JWuh_COfoD"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWnQrP5OOfoD"
      },
      "source": [
        "#### <font color = green> Comparision of Mean of MSE with Mean of MSE from PART A </font>\n",
        "<p/>\n",
        "\n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <th>Mean of MSE of PART A</th>\n",
        "    <th>Mean of MSE of PART B</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>244.77</td>\n",
        "    <td>126.13</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "The table above compares the Mean of **MSE for PART A** and **Mean of MSE for PART B**. As can be seen, the value of Mean of MSE of PART B is significantly smaller than that of PART A. The mean squared error tells how close a regression line is to a set of points. The smaller the value, the closer the model is to finding the line of best fit. So the smaller value for PART B shows that the model is slightly closer to finding a line of best fit.\n",
        "\n",
        "To summarize, normalizing the features had a significant effect in reducing the MSE and finding the line of best fit\n",
        "\n",
        "<b>Note</b> : Depending on the data, it may be impossible to get a very small value for MSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szZqqkzHOfoE"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNa2InwyOfoE"
      },
      "source": [
        "# <font color = blue> END OF PART B </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTmG8P3fOfoE"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLjRzqpxOfoE"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI9GW9KxOfoE"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3zijoRROfoE"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAS1tI9zOfoE"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ14bhsiOfoE"
      },
      "source": [
        "# <font color = blue> PART C : BASELINE MODEL WITH 100 EPOCHS </font>\n",
        "\n",
        "\n",
        "In this part, all the tasks from <b>PART B</b> are performed, but this time the number of epochs are increased to 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro1ZJ5UTOfoE"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoT1YlZ1OfoE"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PGNX4hOfoF"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model with Normalized Features and 100 epochs</font>\n",
        "\n",
        "In order to train and test the the baseline model with normalized features and 100 epochs, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Normalize the features (X)</li>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Create a new model with 100 epochs</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dw8XKbjOfoF"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Normalize the features (X) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD0aAlMgOfoF"
      },
      "source": [
        "<b>Note</b> : As the features (X) have already been normalized the features (X), hence this part is skipped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtCZ5oJZOfoF"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cZOH-4GOfoF"
      },
      "source": [
        "# Creating X_train, X_test, Y_train and Y_test sets\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjVRWi5sOfoF"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uMD9thUOfoF"
      },
      "source": [
        "<b>Note </b> : Since the regression model has already been created using `def regression_model` in <b>TASK 1</b> and there are no changes being made to it, hence there is no need to write the code for the model again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU0u1mAcOfoF",
        "outputId": "03cb9f0c-577f-4113-e92a-287cf09aa4a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=100)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 188321.2500 - val_loss: 144256.8438\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126496.8125 - val_loss: 98340.7031\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 87895.6172 - val_loss: 69207.5391\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 63407.3711 - val_loss: 50855.2852\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 46853.9688 - val_loss: 36632.7070\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 32621.5312 - val_loss: 23772.7227\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 20493.8164 - val_loss: 13436.8213\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10982.4824 - val_loss: 5927.8418\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4568.4263 - val_loss: 1766.0303\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1479.4546 - val_loss: 861.1508\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 939.1639 - val_loss: 926.1511\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 911.4562 - val_loss: 856.4485\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 850.1511 - val_loss: 758.5235\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 803.5928 - val_loss: 723.5714\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 766.1877 - val_loss: 685.0134\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 734.3221 - val_loss: 656.5909\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 703.2537 - val_loss: 639.6837\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 675.8123 - val_loss: 608.7964\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 650.6002 - val_loss: 583.2288\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 628.6481 - val_loss: 556.6277\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 605.9086 - val_loss: 542.0905\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 586.6338 - val_loss: 532.5953\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 568.5333 - val_loss: 504.4271\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 550.1874 - val_loss: 494.4151\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 533.9961 - val_loss: 475.1101\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 518.5162 - val_loss: 463.8220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 504.1537 - val_loss: 456.7552\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 492.2204 - val_loss: 430.9755\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 477.7087 - val_loss: 429.5800\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 465.3323 - val_loss: 420.0073\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 454.8335 - val_loss: 410.4012\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 442.8001 - val_loss: 390.0936\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 432.5458 - val_loss: 388.2666\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 422.5588 - val_loss: 375.9712\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 412.4844 - val_loss: 374.7211\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 403.5681 - val_loss: 364.0877\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 395.0044 - val_loss: 353.1456\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 386.5579 - val_loss: 343.4346\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 378.3443 - val_loss: 342.6708\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 371.1086 - val_loss: 337.4756\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 364.4298 - val_loss: 319.6042\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 355.4859 - val_loss: 316.8810\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 347.7482 - val_loss: 317.5196\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 341.7768 - val_loss: 308.4839\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335.0261 - val_loss: 299.6199\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.4512 - val_loss: 294.6265\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 322.3570 - val_loss: 292.8990\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316.5664 - val_loss: 287.7156\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 310.6184 - val_loss: 281.0633\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 304.5665 - val_loss: 272.3426\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 299.8366 - val_loss: 268.8375\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.0490 - val_loss: 263.5023\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.6023 - val_loss: 262.4024\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 283.7913 - val_loss: 258.3095\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 279.1982 - val_loss: 251.2512\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 274.0822 - val_loss: 247.1955\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 271.8142 - val_loss: 238.5531\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 267.9991 - val_loss: 252.5677\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 259.8837 - val_loss: 230.4684\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 256.7566 - val_loss: 227.7055\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 252.1152 - val_loss: 235.8329\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 248.8043 - val_loss: 223.8128\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.0518 - val_loss: 222.6979\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.7614 - val_loss: 221.3637\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.5853 - val_loss: 212.3834\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.3801 - val_loss: 213.8413\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 229.3928 - val_loss: 207.6402\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 226.6067 - val_loss: 204.5709\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.9142 - val_loss: 204.4246\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.4423 - val_loss: 198.9922\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 216.9756 - val_loss: 203.9688\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 213.4336 - val_loss: 193.9922\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 210.8751 - val_loss: 192.8578\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 207.9570 - val_loss: 189.0595\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 205.8735 - val_loss: 191.4167\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 201.6931 - val_loss: 184.4861\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 199.4746 - val_loss: 184.6691\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 196.9842 - val_loss: 183.0597\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.1378 - val_loss: 177.2354\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.7758 - val_loss: 177.8489\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.4941 - val_loss: 177.5623\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.6695 - val_loss: 173.1260\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.7345 - val_loss: 173.4885\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.9932 - val_loss: 169.9837\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 180.7284 - val_loss: 171.2651\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 178.7253 - val_loss: 167.4751\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.6426 - val_loss: 163.4460\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.3094 - val_loss: 165.8776\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 172.8046 - val_loss: 162.4781\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.8208 - val_loss: 160.8712\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 169.9876 - val_loss: 158.5877\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 167.2945 - val_loss: 162.3596\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.3259 - val_loss: 156.4728\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 163.8908 - val_loss: 154.3198\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 162.7048 - val_loss: 154.7521\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 161.0851 - val_loss: 152.5494\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 159.2417 - val_loss: 151.1200\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 157.9515 - val_loss: 150.0039\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 156.1055 - val_loss: 150.2612\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.8426 - val_loss: 148.9322\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f40822cf710>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YU6UVFZOfoF"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXwkYOSGOfoF"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k06ycJdwOfoG"
      },
      "source": [
        "### <font color = #2980B9> Step 5 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am5b6lvPOfoG",
        "outputId": "657a854b-6a4f-41b7-aa92-b7c85d6c9998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the mean square error\n",
        "\n",
        "mse = calculate_mse()\n",
        "print('Mean Square Error (MSE) of the Baseline Model with Normalized Features is : ' , str(mse))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model with Normalized Features is :  159.7917327154235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX_9lTZ4OfoG"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aeAHQITOfoG"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEVCM6Y4OfoG"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors with 100 Epochs</font>\n",
        "\n",
        "In order to train 50 models with new features (normalized features) and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE) the following steps are performed :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjZfd1v0OfoG"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQcZgqxoOfoG"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqxWjU4FOfoG"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3cPUAN4OfoG",
        "outputId": "f4507880-936a-479d-ecce-2e0c3c537aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=100)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = model.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = mean_squared_error(Y_test, Y_predicted)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.2868 - val_loss: 136.8848\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.7324 - val_loss: 129.8038\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 9965.9424 - val_loss: 5780.5225\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4517.7168 - val_loss: 2852.2747\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2294.8240 - val_loss: 1499.7253\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1246.4083 - val_loss: 900.1678\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 765.0550 - val_loss: 581.9352\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 551.3828 - val_loss: 424.0838\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 421.4155 - val_loss: 344.8144\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 354.7723 - val_loss: 293.3468\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 313.8181 - val_loss: 263.8648\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.3428 - val_loss: 245.7200\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.9811 - val_loss: 230.8765\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.0715 - val_loss: 223.3712\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.2828 - val_loss: 216.7374\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.8766 - val_loss: 211.7879\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.5982 - val_loss: 203.3165\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.4837 - val_loss: 205.2536\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.9836 - val_loss: 195.3958\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 209.4518 - val_loss: 192.7506\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.8487 - val_loss: 190.6920\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.7990 - val_loss: 186.6993\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.8681 - val_loss: 185.0234\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.6191 - val_loss: 181.0593\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.3986 - val_loss: 189.7079\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.3005 - val_loss: 177.0629\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.6334 - val_loss: 179.7213\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.6083 - val_loss: 176.3824\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.6614 - val_loss: 171.4039\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.7570 - val_loss: 170.6028\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.7801 - val_loss: 169.7781\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.3831 - val_loss: 168.2178\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.3472 - val_loss: 167.3995\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.4803 - val_loss: 167.0889\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.3953 - val_loss: 163.2880\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.3717 - val_loss: 162.9979\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.2468 - val_loss: 162.1562\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.7829 - val_loss: 160.7775\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.3995 - val_loss: 162.8598\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.8640 - val_loss: 162.5513\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4061 - val_loss: 157.5830\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.3674 - val_loss: 157.4567\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.3005 - val_loss: 156.2887\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.9172 - val_loss: 159.0520\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.5115 - val_loss: 154.7858\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.0346 - val_loss: 155.2247\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.8456 - val_loss: 155.0480\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.9647 - val_loss: 152.3900\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.9626 - val_loss: 155.4583\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.8398 - val_loss: 151.5620\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4694 - val_loss: 153.3565\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.5621 - val_loss: 151.5653\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.6139 - val_loss: 149.3569\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.7871 - val_loss: 155.6815\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.3501 - val_loss: 156.1090\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.7268 - val_loss: 148.2689\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6581 - val_loss: 146.6399\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6411 - val_loss: 147.4023\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9193 - val_loss: 147.3231\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.0199 - val_loss: 145.1177\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6039 - val_loss: 144.3009\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.1645 - val_loss: 163.0707\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.7297 - val_loss: 143.5129\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.0174 - val_loss: 142.8533\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.9287 - val_loss: 142.1203\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.8748 - val_loss: 142.1138\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.1444 - val_loss: 144.1553\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.6231 - val_loss: 144.8542\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.8552 - val_loss: 146.0579\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.1804 - val_loss: 138.8450\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.7271 - val_loss: 138.4447\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5299 - val_loss: 146.2000\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.4829 - val_loss: 136.6364\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0567 - val_loss: 141.5713\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.5149 - val_loss: 136.1470\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8367 - val_loss: 137.9657\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8737 - val_loss: 139.1518\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8370 - val_loss: 141.6926\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.0428 - val_loss: 136.2114\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.1075 - val_loss: 132.2705\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.7747 - val_loss: 133.6319\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0672 - val_loss: 133.9469\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.2680 - val_loss: 131.5408\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.3895 - val_loss: 132.5659\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8386 - val_loss: 130.7046\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.3099 - val_loss: 132.2573\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.1118 - val_loss: 137.0714\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.8759 - val_loss: 135.5332\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.3903 - val_loss: 132.5927\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.5817 - val_loss: 139.4422\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6194 - val_loss: 128.4646\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.0589 - val_loss: 127.5893\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.1811 - val_loss: 127.0190\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.1958 - val_loss: 126.6820\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.7497 - val_loss: 126.0962\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8290 - val_loss: 125.9962\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.0807 - val_loss: 126.1662\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.1343 - val_loss: 125.7158\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.0534 - val_loss: 127.3440\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.7232 - val_loss: 127.2529\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.9242 - val_loss: 125.3553\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.4920 - val_loss: 124.8423\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 4568.3848 - val_loss: 2722.2400\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2854.3931 - val_loss: 1916.0763\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2132.2112 - val_loss: 1502.8221\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1566.9534 - val_loss: 1104.3719\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1043.1509 - val_loss: 798.3353\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 738.9203 - val_loss: 658.1992\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 630.0768 - val_loss: 610.0293\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 571.5892 - val_loss: 543.2834\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 521.0797 - val_loss: 492.4247\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 475.5647 - val_loss: 470.1664\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 445.7383 - val_loss: 421.0674\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 407.7822 - val_loss: 392.1683\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 379.3978 - val_loss: 374.0385\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.8352 - val_loss: 340.8629\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.6140 - val_loss: 318.2724\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 305.3741 - val_loss: 296.2644\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.5633 - val_loss: 282.1902\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.6841 - val_loss: 255.7825\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.7296 - val_loss: 238.2221\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.8796 - val_loss: 199.1023\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.5042 - val_loss: 157.5703\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.9797 - val_loss: 131.6544\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.3033 - val_loss: 119.1843\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.0369 - val_loss: 120.0849\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.7956 - val_loss: 110.1880\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.6832 - val_loss: 109.1486\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.0674 - val_loss: 110.1410\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.1892 - val_loss: 105.3517\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2467 - val_loss: 102.9709\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.5977 - val_loss: 100.7498\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.7210 - val_loss: 100.6124\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2546 - val_loss: 100.5089\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.5483 - val_loss: 96.6274\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.5809 - val_loss: 96.6755\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.2210 - val_loss: 94.3288\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.8999 - val_loss: 93.6691\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 110.2214 - val_loss: 94.2181\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.0010 - val_loss: 92.4188\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.7321 - val_loss: 94.0859\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.5387 - val_loss: 90.0366\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.8066 - val_loss: 89.7827\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.4446 - val_loss: 89.0191\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.9274 - val_loss: 87.4931\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5615 - val_loss: 87.0154\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0240 - val_loss: 89.8194\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.4794 - val_loss: 86.6776\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.7379 - val_loss: 88.9491\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.0197 - val_loss: 86.6494\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.7301 - val_loss: 83.8044\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0979 - val_loss: 85.1759\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.1557 - val_loss: 86.2670\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7037 - val_loss: 86.7826\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5734 - val_loss: 85.7491\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8002 - val_loss: 86.4483\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.1073 - val_loss: 81.5502\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.1721 - val_loss: 82.0410\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.2531 - val_loss: 80.6666\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5949 - val_loss: 81.7439\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.6275 - val_loss: 85.5212\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9623 - val_loss: 81.1123\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.5918 - val_loss: 82.5939\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.3512 - val_loss: 83.3159\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.7112 - val_loss: 79.2671\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.9857 - val_loss: 83.6097\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.1192 - val_loss: 78.2877\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7225 - val_loss: 77.8929\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.7226 - val_loss: 78.3910\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.4437 - val_loss: 80.4798\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.8077 - val_loss: 78.3789\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.7421 - val_loss: 97.5585\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.4020 - val_loss: 76.8743\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.4498 - val_loss: 79.1049\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.3478 - val_loss: 79.7974\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.6044 - val_loss: 82.5643\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3792 - val_loss: 75.4586\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.0802 - val_loss: 74.8163\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.2546 - val_loss: 74.0761\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.2177 - val_loss: 74.2425\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.8165 - val_loss: 74.8625\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.9313 - val_loss: 88.4000\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.9550 - val_loss: 75.2429\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.6102 - val_loss: 83.3730\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.3300 - val_loss: 76.6287\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.3514 - val_loss: 71.7706\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 98.9740 - val_loss: 76.4752\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.2957 - val_loss: 72.2606\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.9122 - val_loss: 76.2720\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.5251 - val_loss: 71.6217\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.7768 - val_loss: 69.0984\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.0554 - val_loss: 70.1382\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1512 - val_loss: 80.7624\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1968 - val_loss: 68.2910\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.9758 - val_loss: 72.1849\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.4609 - val_loss: 68.6307\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.1696 - val_loss: 68.3801\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.7119 - val_loss: 69.0726\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.8851 - val_loss: 70.6479\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.3772 - val_loss: 67.4254\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 88.7736 - val_loss: 66.7483\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.2131 - val_loss: 66.8362\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 1057.4891 - val_loss: 848.2120\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 814.0102 - val_loss: 737.8295\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 677.9092 - val_loss: 706.5099\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 575.3724 - val_loss: 572.4062\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 481.7140 - val_loss: 500.4441\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 418.7136 - val_loss: 467.3355\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 365.0920 - val_loss: 388.8339\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 325.3147 - val_loss: 345.2021\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.0219 - val_loss: 313.3708\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.8083 - val_loss: 290.9718\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.7955 - val_loss: 261.5241\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.4357 - val_loss: 241.8495\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.0485 - val_loss: 225.2179\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.1139 - val_loss: 218.9503\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.0515 - val_loss: 193.9451\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.3131 - val_loss: 182.9057\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.2584 - val_loss: 173.1402\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4356 - val_loss: 166.4292\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.3538 - val_loss: 157.7370\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6536 - val_loss: 151.7482\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.2675 - val_loss: 146.9869\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.8886 - val_loss: 145.7027\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.5694 - val_loss: 140.5393\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.8523 - val_loss: 148.1392\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.7290 - val_loss: 138.0352\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.1066 - val_loss: 133.6572\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2425 - val_loss: 131.6620\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6725 - val_loss: 128.9848\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.2840 - val_loss: 131.8485\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.2748 - val_loss: 126.5395\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.0544 - val_loss: 126.3905\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.5265 - val_loss: 125.5670\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.2521 - val_loss: 130.5956\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8160 - val_loss: 125.9728\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.8593 - val_loss: 137.1035\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8611 - val_loss: 122.3833\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.9395 - val_loss: 123.5643\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9376 - val_loss: 121.6389\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8638 - val_loss: 123.2701\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.1204 - val_loss: 126.0826\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.0557 - val_loss: 129.5803\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9403 - val_loss: 120.2418\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4400 - val_loss: 121.7508\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.2426 - val_loss: 123.7665\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3117 - val_loss: 122.1127\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.1186 - val_loss: 121.4926\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.9549 - val_loss: 121.4876\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.1694 - val_loss: 121.1426\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.3025 - val_loss: 119.9594\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6805 - val_loss: 119.0064\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.7645 - val_loss: 127.2702\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2913 - val_loss: 129.1881\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.0808 - val_loss: 124.6326\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.4556 - val_loss: 127.0257\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5492 - val_loss: 125.3154\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.7397 - val_loss: 119.6926\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.5172 - val_loss: 119.6511\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.5060 - val_loss: 118.1088\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.3898 - val_loss: 120.6670\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.0985 - val_loss: 117.8397\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.3096 - val_loss: 123.6056\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.8908 - val_loss: 133.9226\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.0168 - val_loss: 138.8943\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.9732 - val_loss: 129.1101\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.9669 - val_loss: 121.0373\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0786 - val_loss: 118.7985\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.5567 - val_loss: 120.2664\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6265 - val_loss: 118.1587\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.7784 - val_loss: 118.0981\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1358 - val_loss: 117.5858\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.3771 - val_loss: 121.9668\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.0475 - val_loss: 118.5283\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2930 - val_loss: 120.2138\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1264 - val_loss: 129.6997\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2513 - val_loss: 174.4380\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.7098 - val_loss: 147.1422\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5221 - val_loss: 118.6846\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7989 - val_loss: 118.0593\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.1866 - val_loss: 138.1604\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7559 - val_loss: 127.0138\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5788 - val_loss: 120.6648\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.3589 - val_loss: 120.9936\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.4320 - val_loss: 140.6356\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.7039 - val_loss: 121.2360\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.2083 - val_loss: 129.7002\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.2890 - val_loss: 123.7395\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.2417 - val_loss: 146.0811\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.0035 - val_loss: 127.3339\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7439 - val_loss: 126.3717\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5724 - val_loss: 117.6256\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0614 - val_loss: 123.7500\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.4560 - val_loss: 118.6477\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2123 - val_loss: 118.9050\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5131 - val_loss: 116.7881\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.6387 - val_loss: 118.8794\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.4917 - val_loss: 118.4912\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.5444 - val_loss: 137.5745\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.1217 - val_loss: 144.2932\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.7613 - val_loss: 120.0832\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.6622 - val_loss: 123.6434\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 6323.4482 - val_loss: 3672.6746\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2439.8186 - val_loss: 1817.2101\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1090.1959 - val_loss: 847.5473\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 517.4614 - val_loss: 488.8610\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 318.0510 - val_loss: 334.3802\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.7029 - val_loss: 286.4309\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.7140 - val_loss: 258.9971\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.3280 - val_loss: 249.1458\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.0143 - val_loss: 237.1087\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.4232 - val_loss: 228.3559\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.8789 - val_loss: 229.6004\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.4754 - val_loss: 221.4662\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.1952 - val_loss: 223.5353\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 204.6671 - val_loss: 212.7874\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.0852 - val_loss: 214.7007\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 195.7151 - val_loss: 207.8166\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.4454 - val_loss: 205.7321\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.7526 - val_loss: 207.4439\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.2568 - val_loss: 199.3192\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.0966 - val_loss: 208.6275\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.6071 - val_loss: 194.8218\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5117 - val_loss: 195.2378\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.3131 - val_loss: 191.5717\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.9264 - val_loss: 193.3645\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.6703 - val_loss: 185.6159\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0184 - val_loss: 193.5598\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.4089 - val_loss: 181.1745\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.4262 - val_loss: 182.5840\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.6839 - val_loss: 191.7203\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.9263 - val_loss: 176.7642\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.4390 - val_loss: 181.9756\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.8813 - val_loss: 173.2715\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.7293 - val_loss: 168.3869\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.4318 - val_loss: 169.8973\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.9879 - val_loss: 174.8396\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.7740 - val_loss: 165.7144\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.4561 - val_loss: 162.0057\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.9019 - val_loss: 160.3046\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.3370 - val_loss: 160.1630\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.0661 - val_loss: 167.0271\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.1031 - val_loss: 157.3619\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.5828 - val_loss: 154.3806\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.2924 - val_loss: 153.3152\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.2316 - val_loss: 155.3003\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.0947 - val_loss: 150.9944\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.3264 - val_loss: 151.8375\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.9055 - val_loss: 147.1791\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3991 - val_loss: 148.5293\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.0651 - val_loss: 160.8751\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.0753 - val_loss: 146.1367\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.1543 - val_loss: 141.0259\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.2079 - val_loss: 145.2813\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.4508 - val_loss: 139.5006\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.5502 - val_loss: 143.2655\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.7820 - val_loss: 143.0089\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.0068 - val_loss: 144.2261\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.6935 - val_loss: 137.9385\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.2856 - val_loss: 134.2894\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.9840 - val_loss: 138.2542\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9726 - val_loss: 131.2202\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.6080 - val_loss: 134.8624\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.5584 - val_loss: 137.7583\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.8252 - val_loss: 131.4294\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.1984 - val_loss: 134.2954\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.2447 - val_loss: 124.9697\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.9512 - val_loss: 125.3731\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.5629 - val_loss: 122.0364\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.0490 - val_loss: 122.2367\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.9284 - val_loss: 119.2776\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.5956 - val_loss: 117.6191\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3753 - val_loss: 116.7105\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.4327 - val_loss: 116.3338\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.2862 - val_loss: 116.5794\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5847 - val_loss: 116.4684\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.5675 - val_loss: 113.6960\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.5172 - val_loss: 111.7777\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3872 - val_loss: 112.1390\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.5467 - val_loss: 113.7882\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.0553 - val_loss: 110.0989\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2028 - val_loss: 110.8629\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.9434 - val_loss: 125.4551\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9593 - val_loss: 111.3000\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.9844 - val_loss: 106.9287\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.9397 - val_loss: 107.7756\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8822 - val_loss: 109.2621\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.7012 - val_loss: 114.8027\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.7975 - val_loss: 114.3443\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.8870 - val_loss: 109.0145\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.5722 - val_loss: 107.6038\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.1773 - val_loss: 105.8581\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.4588 - val_loss: 105.0924\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6578 - val_loss: 103.5948\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0773 - val_loss: 102.0165\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.6598 - val_loss: 101.3906\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2911 - val_loss: 100.8627\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.3906 - val_loss: 100.6804\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.3151 - val_loss: 100.3506\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2793 - val_loss: 101.7614\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.7882 - val_loss: 99.7599\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.1834 - val_loss: 99.2569\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 27651.1855 - val_loss: 13447.1943\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8342.8662 - val_loss: 3166.7603\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1979.8923 - val_loss: 927.3312\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 923.4805 - val_loss: 857.1765\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 859.3448 - val_loss: 791.0147\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 778.9301 - val_loss: 714.1086\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 716.0798 - val_loss: 666.5581\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 670.8378 - val_loss: 626.1298\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 628.4906 - val_loss: 592.1702\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 593.2837 - val_loss: 558.3444\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 557.0873 - val_loss: 531.7241\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 528.4250 - val_loss: 504.6892\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 499.7631 - val_loss: 482.3552\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 473.3752 - val_loss: 455.5247\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 447.5800 - val_loss: 432.1605\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 424.1119 - val_loss: 411.8686\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 401.9115 - val_loss: 391.4576\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 382.0023 - val_loss: 372.3194\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 364.8319 - val_loss: 358.4823\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 346.7981 - val_loss: 341.4839\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.1524 - val_loss: 328.4948\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 317.5503 - val_loss: 316.7344\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304.3871 - val_loss: 303.5690\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.0687 - val_loss: 293.2185\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.4016 - val_loss: 282.4385\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.0331 - val_loss: 272.7534\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.9449 - val_loss: 263.0617\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.4243 - val_loss: 253.9829\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.4268 - val_loss: 246.7710\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.9803 - val_loss: 239.3082\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.8445 - val_loss: 231.5260\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0406 - val_loss: 225.2007\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.9592 - val_loss: 219.0430\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.2856 - val_loss: 212.4621\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.7154 - val_loss: 207.7276\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.8727 - val_loss: 202.1079\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.8932 - val_loss: 195.9800\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.5214 - val_loss: 192.6075\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.8761 - val_loss: 185.6755\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.7241 - val_loss: 182.1624\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.4928 - val_loss: 177.2173\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.4478 - val_loss: 172.5696\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.8225 - val_loss: 169.0731\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.5371 - val_loss: 165.6275\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.1828 - val_loss: 161.4181\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.8611 - val_loss: 157.6348\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.5564 - val_loss: 154.3202\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.7523 - val_loss: 151.9562\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.0531 - val_loss: 150.0209\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.4826 - val_loss: 146.5260\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.1090 - val_loss: 143.5425\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.1364 - val_loss: 141.4692\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.5183 - val_loss: 138.8812\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.0312 - val_loss: 137.0549\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.4706 - val_loss: 135.0544\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.3622 - val_loss: 133.3081\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.8342 - val_loss: 131.5583\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.9668 - val_loss: 129.9065\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.8306 - val_loss: 128.1369\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3817 - val_loss: 127.4116\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.1821 - val_loss: 125.4739\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8440 - val_loss: 123.8715\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.0415 - val_loss: 122.7992\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.0804 - val_loss: 121.9456\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.8759 - val_loss: 120.2209\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.1948 - val_loss: 119.2068\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.0957 - val_loss: 118.1702\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8615 - val_loss: 117.3578\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0024 - val_loss: 116.4319\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 105.2052 - val_loss: 115.4180\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.5391 - val_loss: 114.9557\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0185 - val_loss: 114.0570\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9463 - val_loss: 112.8062\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.3035 - val_loss: 112.4305\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.2523 - val_loss: 112.0529\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.8501 - val_loss: 111.2253\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.3056 - val_loss: 109.6694\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.3355 - val_loss: 109.5288\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.2210 - val_loss: 109.7298\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8241 - val_loss: 108.3107\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.2150 - val_loss: 108.0700\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.9957 - val_loss: 106.6103\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.9658 - val_loss: 107.8509\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.4938 - val_loss: 106.6202\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.0054 - val_loss: 106.0297\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.2217 - val_loss: 105.7002\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7417 - val_loss: 104.2291\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.0139 - val_loss: 103.3606\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.5787 - val_loss: 103.5645\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.0157 - val_loss: 102.3054\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.1876 - val_loss: 102.2485\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.8788 - val_loss: 102.1492\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.3487 - val_loss: 102.5955\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1535 - val_loss: 101.7519\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.1634 - val_loss: 100.6939\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.2571 - val_loss: 99.6834\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.6751 - val_loss: 100.6914\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.0149 - val_loss: 98.2810\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.9008 - val_loss: 100.5885\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.0942 - val_loss: 98.7095\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 7796.0483 - val_loss: 6292.2456\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4990.0039 - val_loss: 4249.6406\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3326.8850 - val_loss: 2852.0234\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2249.2302 - val_loss: 2067.9958\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1723.2452 - val_loss: 1850.2791\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1575.4418 - val_loss: 1792.7454\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1539.6075 - val_loss: 1769.5890\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1528.4615 - val_loss: 1762.1509\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1523.8457 - val_loss: 1759.2081\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1521.4651 - val_loss: 1756.9114\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1520.0240 - val_loss: 1755.6064\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1518.8691 - val_loss: 1754.1893\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1517.8856 - val_loss: 1753.0682\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1516.9738 - val_loss: 1752.0366\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1516.0375 - val_loss: 1750.7325\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1515.1051 - val_loss: 1749.5820\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1514.1603 - val_loss: 1748.5449\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1513.2079 - val_loss: 1747.5211\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1512.2333 - val_loss: 1746.5176\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1511.2587 - val_loss: 1745.5270\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1510.2694 - val_loss: 1744.3979\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1509.2856 - val_loss: 1743.0972\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1508.2920 - val_loss: 1742.0023\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1507.2886 - val_loss: 1740.9498\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1506.2704 - val_loss: 1739.8940\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1505.2490 - val_loss: 1738.8679\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1504.2495 - val_loss: 1737.6876\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1503.2230 - val_loss: 1736.6169\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1502.2310 - val_loss: 1735.4768\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1501.2095 - val_loss: 1734.3536\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1500.1925 - val_loss: 1733.3127\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1499.1785 - val_loss: 1732.2322\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1498.1691 - val_loss: 1731.1423\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1497.1541 - val_loss: 1730.0558\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1496.1437 - val_loss: 1728.9597\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1495.1223 - val_loss: 1727.7057\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1494.1135 - val_loss: 1726.5515\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1493.0831 - val_loss: 1725.4528\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1492.0665 - val_loss: 1724.3519\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1491.0505 - val_loss: 1723.2482\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1490.0312 - val_loss: 1722.1403\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1489.0052 - val_loss: 1721.0355\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1487.9860 - val_loss: 1719.9236\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1486.9591 - val_loss: 1718.8101\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1485.9326 - val_loss: 1717.6960\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1484.8995 - val_loss: 1716.5922\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1483.8843 - val_loss: 1715.4685\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1482.8408 - val_loss: 1714.3705\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1481.8237 - val_loss: 1713.2437\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1480.7847 - val_loss: 1712.1307\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1479.7506 - val_loss: 1711.0206\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1478.7223 - val_loss: 1709.8977\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1477.6788 - val_loss: 1708.7854\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1476.6459 - val_loss: 1707.6605\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1475.6157 - val_loss: 1706.5259\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1474.5730 - val_loss: 1705.3993\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1473.5356 - val_loss: 1704.2731\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1472.4921 - val_loss: 1703.1547\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1471.4545 - val_loss: 1702.0303\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1470.4078 - val_loss: 1700.9139\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1469.3721 - val_loss: 1699.7861\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1468.3284 - val_loss: 1698.6588\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1467.2896 - val_loss: 1697.5208\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1466.2394 - val_loss: 1696.3920\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1465.1920 - val_loss: 1695.2622\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1464.1486 - val_loss: 1694.1316\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1463.1005 - val_loss: 1693.0007\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1462.0549 - val_loss: 1691.8701\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1461.0139 - val_loss: 1690.7324\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1459.9611 - val_loss: 1689.6055\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1458.9163 - val_loss: 1688.4734\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1457.8712 - val_loss: 1687.3395\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1456.8191 - val_loss: 1686.2080\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1455.7766 - val_loss: 1685.0651\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1454.7260 - val_loss: 1683.9265\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1453.6776 - val_loss: 1682.7906\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1452.6254 - val_loss: 1681.6627\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1451.5824 - val_loss: 1680.5282\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1450.5350 - val_loss: 1679.3926\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1449.4873 - val_loss: 1678.2565\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1448.4417 - val_loss: 1677.1212\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1447.3851 - val_loss: 1675.9976\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1446.3436 - val_loss: 1674.8583\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1445.2953 - val_loss: 1673.7179\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1444.2426 - val_loss: 1672.5825\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1443.1902 - val_loss: 1671.4520\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1442.1490 - val_loss: 1670.3083\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1441.1030 - val_loss: 1669.1632\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1440.0468 - val_loss: 1668.0317\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1438.9973 - val_loss: 1666.9020\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1437.9548 - val_loss: 1665.7662\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1436.9033 - val_loss: 1664.6332\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1435.8568 - val_loss: 1663.4966\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1434.8053 - val_loss: 1662.3695\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1433.7595 - val_loss: 1661.2380\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1432.7102 - val_loss: 1660.1045\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1431.6664 - val_loss: 1658.9636\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1430.6140 - val_loss: 1657.8333\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1429.5754 - val_loss: 1656.6835\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1428.5234 - val_loss: 1655.5472\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 338641.5312 - val_loss: 253165.6562\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214210.4688 - val_loss: 140913.3281\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103292.6875 - val_loss: 52984.2070\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 35030.4219 - val_loss: 13947.7617\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8704.3975 - val_loss: 4336.5269\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4450.9365 - val_loss: 4525.0854\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3588.1284 - val_loss: 2817.5554\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2378.7273 - val_loss: 1692.6146\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1501.5360 - val_loss: 1208.6001\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1026.1211 - val_loss: 1009.0888\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 854.0737 - val_loss: 898.4344\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 753.1243 - val_loss: 821.1992\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 681.5959 - val_loss: 762.0403\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 628.9490 - val_loss: 710.7015\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 586.5831 - val_loss: 667.3060\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 545.7676 - val_loss: 623.2375\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 510.4277 - val_loss: 582.3527\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 483.7979 - val_loss: 545.3411\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 449.2301 - val_loss: 513.3010\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 422.1832 - val_loss: 488.8454\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 398.6009 - val_loss: 456.0452\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 377.0914 - val_loss: 438.1885\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.0673 - val_loss: 405.7986\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 336.1958 - val_loss: 389.2666\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 322.5679 - val_loss: 368.4181\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.0315 - val_loss: 347.8774\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.6115 - val_loss: 330.5771\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 278.7718 - val_loss: 319.9151\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 269.7860 - val_loss: 299.7885\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.0361 - val_loss: 287.8791\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.5295 - val_loss: 281.3596\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.5435 - val_loss: 265.9615\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.1555 - val_loss: 257.0303\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.8363 - val_loss: 247.6549\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.4153 - val_loss: 238.9984\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.6797 - val_loss: 234.4479\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.9711 - val_loss: 225.6656\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.5787 - val_loss: 218.6088\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.9082 - val_loss: 218.3107\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.9139 - val_loss: 207.8993\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.0347 - val_loss: 201.7512\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.9065 - val_loss: 204.0035\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.3012 - val_loss: 194.1904\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.9445 - val_loss: 190.3914\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.4709 - val_loss: 187.3062\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.1478 - val_loss: 185.3411\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.6314 - val_loss: 183.7057\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.7063 - val_loss: 185.8093\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.9464 - val_loss: 176.7923\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.6233 - val_loss: 175.1686\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.0471 - val_loss: 176.3566\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.6746 - val_loss: 179.9993\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.5050 - val_loss: 171.2369\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.1263 - val_loss: 168.2573\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.5566 - val_loss: 175.4414\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.3093 - val_loss: 164.3674\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.6471 - val_loss: 166.6043\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.2478 - val_loss: 161.1936\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.6980 - val_loss: 159.7895\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.5512 - val_loss: 158.6217\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.9351 - val_loss: 157.8246\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.3517 - val_loss: 156.7529\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.9253 - val_loss: 155.4849\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.2243 - val_loss: 154.3440\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.2540 - val_loss: 155.0742\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.1056 - val_loss: 154.3844\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.7111 - val_loss: 154.3364\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.1838 - val_loss: 150.7715\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.5268 - val_loss: 151.1901\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.2513 - val_loss: 150.0962\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.6653 - val_loss: 150.7070\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.8159 - val_loss: 147.1164\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.6264 - val_loss: 148.4805\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.6015 - val_loss: 160.6190\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.7281 - val_loss: 146.9115\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.6249 - val_loss: 143.6025\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.5101 - val_loss: 143.4353\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.6635 - val_loss: 145.6465\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.1603 - val_loss: 141.3799\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.4408 - val_loss: 140.9537\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.5242 - val_loss: 140.4408\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.5815 - val_loss: 142.0389\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4695 - val_loss: 139.7114\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.1643 - val_loss: 138.1914\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.9780 - val_loss: 137.4781\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.9233 - val_loss: 138.7280\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.9697 - val_loss: 141.4709\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.1546 - val_loss: 134.6987\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.0168 - val_loss: 134.0421\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.9919 - val_loss: 134.0141\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.2303 - val_loss: 132.7253\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.3775 - val_loss: 133.1154\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.0606 - val_loss: 131.4208\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.2121 - val_loss: 130.3699\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.8071 - val_loss: 135.0576\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.4864 - val_loss: 128.3478\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.5409 - val_loss: 128.2478\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.5490 - val_loss: 127.9920\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.1319 - val_loss: 126.9862\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.9972 - val_loss: 127.0932\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 1536.1636 - val_loss: 883.8588\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 828.7469 - val_loss: 599.2487\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 504.8816 - val_loss: 333.8296\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 332.6216 - val_loss: 243.8338\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.4749 - val_loss: 207.9027\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.7288 - val_loss: 199.1041\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.8712 - val_loss: 182.9849\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.3382 - val_loss: 186.8613\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.8227 - val_loss: 176.3702\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5717 - val_loss: 169.7503\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.2268 - val_loss: 161.8539\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.6996 - val_loss: 154.1438\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.3841 - val_loss: 159.4723\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.4271 - val_loss: 145.3870\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.7071 - val_loss: 152.0569\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.0103 - val_loss: 139.4138\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.2460 - val_loss: 138.7532\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.6033 - val_loss: 134.3328\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.6701 - val_loss: 135.7558\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6580 - val_loss: 132.9950\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.0501 - val_loss: 129.1419\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.7518 - val_loss: 128.1078\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.8716 - val_loss: 129.0507\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.8209 - val_loss: 129.1398\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.7802 - val_loss: 132.2402\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.7641 - val_loss: 127.6315\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.2989 - val_loss: 126.8584\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.3681 - val_loss: 130.7457\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.7570 - val_loss: 129.8614\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2918 - val_loss: 122.8897\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.9162 - val_loss: 122.3797\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5804 - val_loss: 119.3133\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5411 - val_loss: 121.1580\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.8288 - val_loss: 123.9161\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5558 - val_loss: 123.7700\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0926 - val_loss: 130.8153\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0947 - val_loss: 137.1858\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2155 - val_loss: 125.0099\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.7649 - val_loss: 115.0605\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.5481 - val_loss: 123.7341\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6742 - val_loss: 124.1554\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.1059 - val_loss: 114.3094\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8066 - val_loss: 113.5082\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8972 - val_loss: 112.6526\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.7164 - val_loss: 112.8727\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.3168 - val_loss: 119.6532\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.2279 - val_loss: 116.3954\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.0208 - val_loss: 113.7441\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.7476 - val_loss: 112.7716\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.1066 - val_loss: 111.8941\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.0424 - val_loss: 111.2010\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.8861 - val_loss: 111.6845\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.0713 - val_loss: 110.3063\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.6059 - val_loss: 112.7463\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.8253 - val_loss: 114.7960\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.4870 - val_loss: 109.2768\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.6793 - val_loss: 108.9509\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.8956 - val_loss: 108.9514\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.9704 - val_loss: 109.0398\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.7085 - val_loss: 109.0211\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.5394 - val_loss: 107.5999\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.1739 - val_loss: 106.5265\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.2869 - val_loss: 106.7346\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.6529 - val_loss: 106.6948\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.9189 - val_loss: 106.7770\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.4515 - val_loss: 104.4076\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.8272 - val_loss: 104.9829\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.1716 - val_loss: 103.7359\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 79.5509 - val_loss: 104.7242\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.7540 - val_loss: 101.7145\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.4623 - val_loss: 103.5839\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.3563 - val_loss: 100.3896\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.1932 - val_loss: 99.4864\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.2839 - val_loss: 106.1665\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.0534 - val_loss: 99.3561\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.6294 - val_loss: 100.2653\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.0607 - val_loss: 99.5680\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.3572 - val_loss: 103.3196\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.7946 - val_loss: 99.5799\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.4021 - val_loss: 97.7902\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 75.1316 - val_loss: 107.9159\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.0256 - val_loss: 101.0265\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.4321 - val_loss: 100.8713\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.8747 - val_loss: 98.4030\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 71.2379 - val_loss: 96.0092\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.5908 - val_loss: 99.6021\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 70.4922 - val_loss: 97.5419\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.2186 - val_loss: 99.2300\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.3567 - val_loss: 98.0039\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.2539 - val_loss: 100.4999\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.7156 - val_loss: 95.2119\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 69.0169 - val_loss: 95.3048\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.2286 - val_loss: 109.0797\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.2556 - val_loss: 93.6253\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.6563 - val_loss: 97.5945\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.3982 - val_loss: 92.4653\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.0566 - val_loss: 92.6983\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.4157 - val_loss: 94.9280\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 69.4597 - val_loss: 95.4213\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.0218 - val_loss: 90.4541\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 50771.5469 - val_loss: 29927.2266\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 18839.0039 - val_loss: 9196.9141\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4973.6279 - val_loss: 1847.6428\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 947.1960 - val_loss: 411.5998\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 442.2892 - val_loss: 368.6549\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 436.9271 - val_loss: 356.0972\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 415.3332 - val_loss: 349.2199\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 404.7183 - val_loss: 346.4986\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 398.3947 - val_loss: 341.1096\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 392.5867 - val_loss: 333.9499\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 385.0471 - val_loss: 330.0868\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 377.8219 - val_loss: 323.0328\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.3070 - val_loss: 317.3731\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.1538 - val_loss: 311.6008\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 354.9659 - val_loss: 304.4891\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 347.1339 - val_loss: 299.5846\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 340.1451 - val_loss: 291.8589\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 331.6244 - val_loss: 287.9263\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 323.4426 - val_loss: 280.4056\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.5319 - val_loss: 273.4395\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.2112 - val_loss: 268.4187\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 299.8723 - val_loss: 262.6577\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.3698 - val_loss: 257.4245\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 285.8858 - val_loss: 252.4391\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 279.9574 - val_loss: 248.7372\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.8723 - val_loss: 243.3755\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.6277 - val_loss: 239.2269\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.4561 - val_loss: 236.1017\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.2243 - val_loss: 231.5689\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.2758 - val_loss: 228.8360\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.1284 - val_loss: 225.1825\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.4703 - val_loss: 221.3096\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.2711 - val_loss: 218.8821\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.5116 - val_loss: 213.6386\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 231.7517 - val_loss: 212.0722\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.5976 - val_loss: 206.8922\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.6932 - val_loss: 205.5987\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.9481 - val_loss: 200.9343\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0090 - val_loss: 196.4723\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.7628 - val_loss: 193.3474\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.6793 - val_loss: 190.4179\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.1797 - val_loss: 184.9439\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.4478 - val_loss: 182.0466\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.4691 - val_loss: 176.3533\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.3150 - val_loss: 173.0264\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.4651 - val_loss: 167.7343\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.5271 - val_loss: 163.9845\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.4208 - val_loss: 161.2505\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.0133 - val_loss: 157.0315\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.7451 - val_loss: 155.0242\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.3261 - val_loss: 151.1806\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.7324 - val_loss: 148.1968\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.1474 - val_loss: 146.2002\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.8613 - val_loss: 143.4189\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.1781 - val_loss: 141.3102\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.6982 - val_loss: 139.4441\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.6480 - val_loss: 137.4776\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.6015 - val_loss: 137.6108\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9177 - val_loss: 133.5823\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.6004 - val_loss: 134.8716\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.9867 - val_loss: 131.9713\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.2543 - val_loss: 130.4267\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.7214 - val_loss: 131.8007\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.1710 - val_loss: 127.1287\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.4191 - val_loss: 127.1777\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.5222 - val_loss: 127.1248\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.8825 - val_loss: 125.1074\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.9884 - val_loss: 126.6761\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.0331 - val_loss: 122.6216\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.0382 - val_loss: 123.0625\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2368 - val_loss: 121.9509\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0770 - val_loss: 119.9819\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.8129 - val_loss: 122.0129\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.6160 - val_loss: 119.1109\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.6284 - val_loss: 119.5031\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.3635 - val_loss: 117.7365\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5287 - val_loss: 121.7816\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.5863 - val_loss: 119.1831\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.3353 - val_loss: 116.1228\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6255 - val_loss: 119.8889\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.7435 - val_loss: 115.2345\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.4590 - val_loss: 119.3288\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.2209 - val_loss: 114.6587\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.4286 - val_loss: 116.1704\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.6914 - val_loss: 117.7498\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8375 - val_loss: 115.7097\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4718 - val_loss: 117.3819\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.0747 - val_loss: 113.7599\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0938 - val_loss: 116.1615\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6138 - val_loss: 115.0796\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9065 - val_loss: 113.4294\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.5558 - val_loss: 114.3001\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.2675 - val_loss: 113.6357\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.9188 - val_loss: 117.8398\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.1573 - val_loss: 112.0482\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.5804 - val_loss: 113.4114\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5866 - val_loss: 113.2562\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.7577 - val_loss: 110.5799\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.1011 - val_loss: 112.0153\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.3665 - val_loss: 112.6772\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 7459.9785 - val_loss: 2329.3342\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1401.8716 - val_loss: 1507.7900\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1224.9216 - val_loss: 1158.8652\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 947.7781 - val_loss: 1011.2382\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 843.2690 - val_loss: 887.0998\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 758.1012 - val_loss: 795.4410\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 694.1702 - val_loss: 715.1045\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 637.2259 - val_loss: 656.1804\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 588.4486 - val_loss: 592.6250\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 539.6439 - val_loss: 546.4208\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 502.9598 - val_loss: 505.0014\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 466.7123 - val_loss: 466.1823\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 436.3561 - val_loss: 433.1855\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 407.4829 - val_loss: 402.7379\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 381.6666 - val_loss: 377.7375\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.5768 - val_loss: 352.8723\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.2545 - val_loss: 330.4796\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 318.0491 - val_loss: 309.8087\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297.4081 - val_loss: 291.8969\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 279.6841 - val_loss: 274.7116\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.4485 - val_loss: 258.5537\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.5051 - val_loss: 244.9046\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 235.8357 - val_loss: 232.5180\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.9683 - val_loss: 219.2903\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.4531 - val_loss: 209.3296\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.7541 - val_loss: 199.0649\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.2357 - val_loss: 189.4129\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.0532 - val_loss: 181.0462\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.0832 - val_loss: 172.9587\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.0433 - val_loss: 164.8876\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.7979 - val_loss: 159.6029\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.1249 - val_loss: 154.0264\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.3367 - val_loss: 148.8123\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.8217 - val_loss: 146.4669\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.8095 - val_loss: 140.7003\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6015 - val_loss: 138.8645\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.5084 - val_loss: 135.4727\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.4362 - val_loss: 135.0929\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.6953 - val_loss: 132.1201\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2806 - val_loss: 133.4456\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.6326 - val_loss: 130.6708\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.9646 - val_loss: 127.8828\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.0959 - val_loss: 128.5812\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0656 - val_loss: 130.9853\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.2194 - val_loss: 125.7962\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.7453 - val_loss: 128.1670\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5960 - val_loss: 124.6339\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.0194 - val_loss: 121.4305\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6477 - val_loss: 121.4420\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.4252 - val_loss: 120.8801\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.8882 - val_loss: 132.0656\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.9162 - val_loss: 119.0696\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7781 - val_loss: 119.6397\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.8016 - val_loss: 118.9480\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.1374 - val_loss: 119.9598\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.1211 - val_loss: 118.1646\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.8622 - val_loss: 120.9951\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.0590 - val_loss: 118.5113\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.2913 - val_loss: 116.2516\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.9513 - val_loss: 118.5687\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.2641 - val_loss: 116.3656\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7015 - val_loss: 115.8294\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7838 - val_loss: 114.8732\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.4890 - val_loss: 114.6546\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.0602 - val_loss: 114.5869\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.7393 - val_loss: 114.2119\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.5645 - val_loss: 118.1200\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.4279 - val_loss: 115.2441\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.0582 - val_loss: 113.0322\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.9446 - val_loss: 112.2290\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.0418 - val_loss: 115.0652\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.0851 - val_loss: 111.1739\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.2901 - val_loss: 112.1526\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.2477 - val_loss: 109.3111\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.9994 - val_loss: 108.0953\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.4306 - val_loss: 110.8053\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.6475 - val_loss: 107.6013\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.4379 - val_loss: 106.2975\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.2310 - val_loss: 105.3713\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.5768 - val_loss: 107.6457\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.4864 - val_loss: 105.2662\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.5713 - val_loss: 103.5406\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.3888 - val_loss: 105.0221\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.8929 - val_loss: 102.6270\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.5613 - val_loss: 103.3993\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.1228 - val_loss: 102.0803\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 83.8013 - val_loss: 101.3535\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.0110 - val_loss: 100.5761\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 82.7076 - val_loss: 100.0049\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.8655 - val_loss: 100.0351\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.3488 - val_loss: 103.9459\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.5798 - val_loss: 99.1349\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81.0586 - val_loss: 102.7114\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.0783 - val_loss: 98.9751\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.0384 - val_loss: 103.4255\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 82.5318 - val_loss: 104.0351\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.7329 - val_loss: 98.2682\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81.9571 - val_loss: 97.0618\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 80.8496 - val_loss: 96.9518\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 79.6814 - val_loss: 96.7606\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 15837.5234 - val_loss: 9057.7734\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5314.2910 - val_loss: 2932.8142\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1919.4381 - val_loss: 1428.5991\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1350.7611 - val_loss: 1213.7299\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1183.2059 - val_loss: 1037.7943\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1001.0659 - val_loss: 903.7316\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 853.4300 - val_loss: 762.4859\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 729.7955 - val_loss: 659.4551\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 633.4230 - val_loss: 577.1688\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 555.4807 - val_loss: 511.5970\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 492.6898 - val_loss: 458.9705\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 444.7839 - val_loss: 419.3257\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 407.7043 - val_loss: 383.4366\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 378.3537 - val_loss: 360.2900\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.8782 - val_loss: 342.7922\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 337.7570 - val_loss: 325.4182\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 320.9096 - val_loss: 312.7316\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 309.0412 - val_loss: 302.4282\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.7271 - val_loss: 291.4922\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.1677 - val_loss: 283.0796\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 279.0825 - val_loss: 275.7734\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.2634 - val_loss: 268.8095\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.2264 - val_loss: 263.6337\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 255.3499 - val_loss: 258.4858\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 249.2932 - val_loss: 252.0585\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.8428 - val_loss: 248.6144\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.9732 - val_loss: 244.2141\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.5102 - val_loss: 239.4708\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.1649 - val_loss: 234.5886\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.5035 - val_loss: 231.1502\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 216.7454 - val_loss: 227.1584\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.1476 - val_loss: 224.3950\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.4640 - val_loss: 220.7582\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.8574 - val_loss: 215.1086\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 201.9214 - val_loss: 211.8981\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.1819 - val_loss: 208.7501\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.2968 - val_loss: 204.9549\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.4121 - val_loss: 202.1435\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.0934 - val_loss: 199.6331\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.9721 - val_loss: 196.2189\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.6516 - val_loss: 193.1461\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.0947 - val_loss: 189.9060\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.0518 - val_loss: 187.6361\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.0570 - val_loss: 184.6969\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.6250 - val_loss: 182.0613\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.4956 - val_loss: 178.9681\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.6613 - val_loss: 176.0128\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.2937 - val_loss: 173.2673\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.6795 - val_loss: 168.4339\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.1704 - val_loss: 166.4720\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.3097 - val_loss: 165.1541\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.1917 - val_loss: 160.7024\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.4747 - val_loss: 158.9625\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.7920 - val_loss: 156.1794\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.5392 - val_loss: 153.9673\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.9411 - val_loss: 152.1267\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.5619 - val_loss: 149.8076\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.9084 - val_loss: 148.2402\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.8408 - val_loss: 146.5621\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.1794 - val_loss: 142.9458\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.7425 - val_loss: 142.2009\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.5973 - val_loss: 139.2113\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.6976 - val_loss: 137.5560\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.6094 - val_loss: 135.2135\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.9547 - val_loss: 133.0717\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.5038 - val_loss: 131.8090\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.7822 - val_loss: 131.2409\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.6751 - val_loss: 128.4852\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.8863 - val_loss: 127.8010\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.6042 - val_loss: 126.1211\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.0714 - val_loss: 123.7552\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.9800 - val_loss: 123.7985\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.9093 - val_loss: 121.1850\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.9296 - val_loss: 120.3108\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3952 - val_loss: 119.1738\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.9849 - val_loss: 119.0712\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.7738 - val_loss: 117.5664\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.9572 - val_loss: 117.2259\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.5581 - val_loss: 115.2657\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.4949 - val_loss: 114.6100\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.5591 - val_loss: 113.4748\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8438 - val_loss: 113.0517\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.2339 - val_loss: 111.2842\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.0017 - val_loss: 108.4872\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9991 - val_loss: 109.8062\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.3754 - val_loss: 113.3678\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.2022 - val_loss: 107.8531\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.6085 - val_loss: 109.4835\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0228 - val_loss: 108.3925\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.8277 - val_loss: 107.6540\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.9320 - val_loss: 106.6197\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.9613 - val_loss: 105.0502\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.6937 - val_loss: 106.6546\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.1720 - val_loss: 105.6967\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1411 - val_loss: 105.6803\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5312 - val_loss: 105.3357\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.9119 - val_loss: 105.3243\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.4060 - val_loss: 103.8712\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.4911 - val_loss: 106.9600\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.4399 - val_loss: 102.1828\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 120846.6797 - val_loss: 103699.7344\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89713.5938 - val_loss: 77955.5234\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 67786.5938 - val_loss: 59777.9141\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52260.3594 - val_loss: 46523.6055\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 40745.9180 - val_loss: 36292.5547\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 31651.5449 - val_loss: 27922.3965\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 23987.7422 - val_loss: 20763.1406\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 16874.3477 - val_loss: 13254.9854\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8108.5859 - val_loss: 3713.6353\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2063.2454 - val_loss: 1306.1188\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1447.9185 - val_loss: 1229.2635\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1283.0424 - val_loss: 1141.8555\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1174.2733 - val_loss: 1086.2041\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1101.0098 - val_loss: 1019.1828\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1038.7119 - val_loss: 962.1357\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 981.4207 - val_loss: 910.1701\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 927.0947 - val_loss: 870.8257\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 877.8737 - val_loss: 828.8049\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 834.8385 - val_loss: 789.7525\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 792.5385 - val_loss: 755.7974\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 754.5234 - val_loss: 723.4644\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 717.6846 - val_loss: 691.1547\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 684.6236 - val_loss: 659.2036\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 652.9279 - val_loss: 637.6611\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 625.7676 - val_loss: 613.7975\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 599.2026 - val_loss: 587.4650\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 573.1202 - val_loss: 571.5746\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 548.9749 - val_loss: 549.8160\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 528.7836 - val_loss: 528.1575\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 506.4128 - val_loss: 515.7213\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 487.7632 - val_loss: 496.6920\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 468.9259 - val_loss: 480.1251\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 453.1171 - val_loss: 466.7295\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 435.1875 - val_loss: 450.6660\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.7110 - val_loss: 438.3802\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 406.6163 - val_loss: 425.5436\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 392.6138 - val_loss: 415.4910\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 379.6895 - val_loss: 402.6542\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 367.1405 - val_loss: 391.3408\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 355.0594 - val_loss: 382.7581\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 344.4191 - val_loss: 371.6017\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 333.5087 - val_loss: 362.8720\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 323.2012 - val_loss: 352.9287\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.2948 - val_loss: 342.6368\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304.9279 - val_loss: 336.9883\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.0020 - val_loss: 326.8528\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 286.3838 - val_loss: 318.1714\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.0662 - val_loss: 311.1166\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 270.7330 - val_loss: 303.4091\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.3985 - val_loss: 296.9679\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.4422 - val_loss: 287.8355\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.5183 - val_loss: 281.0917\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 242.0391 - val_loss: 275.1347\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.4367 - val_loss: 268.9665\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.9628 - val_loss: 263.2401\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.5255 - val_loss: 258.2121\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.6806 - val_loss: 251.2869\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.9669 - val_loss: 246.2897\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.9637 - val_loss: 242.1130\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.2910 - val_loss: 235.7932\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.3683 - val_loss: 228.2928\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.9684 - val_loss: 201.7010\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.3063 - val_loss: 193.0664\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.4415 - val_loss: 188.3874\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.0120 - val_loss: 186.7731\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.8655 - val_loss: 183.9931\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.3029 - val_loss: 182.2803\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.0705 - val_loss: 180.9690\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.5679 - val_loss: 179.7697\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.9110 - val_loss: 178.3924\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.7729 - val_loss: 179.4128\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.1582 - val_loss: 177.1194\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.7886 - val_loss: 175.9641\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.9702 - val_loss: 176.0898\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.5163 - val_loss: 175.1243\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.8326 - val_loss: 174.6933\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.0254 - val_loss: 173.1804\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.2133 - val_loss: 172.9709\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.5966 - val_loss: 172.2072\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.5166 - val_loss: 171.2198\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.0229 - val_loss: 170.7981\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.5774 - val_loss: 169.4585\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.4787 - val_loss: 169.2933\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.7439 - val_loss: 168.5593\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.5168 - val_loss: 168.8394\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.0364 - val_loss: 167.1652\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.7974 - val_loss: 167.2483\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.1402 - val_loss: 167.4829\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.7332 - val_loss: 166.2240\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.5658 - val_loss: 165.6938\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.2601 - val_loss: 164.8681\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.0572 - val_loss: 164.3214\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.3248 - val_loss: 163.9977\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.5500 - val_loss: 163.2972\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.0092 - val_loss: 163.1026\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.7384 - val_loss: 162.8218\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.0851 - val_loss: 162.3359\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.5160 - val_loss: 160.8281\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.2665 - val_loss: 161.4119\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.3273 - val_loss: 161.0048\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 366.1031 - val_loss: 294.6022\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 272.1357 - val_loss: 233.3612\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.0692 - val_loss: 205.8749\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.9841 - val_loss: 197.8345\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 185.7090 - val_loss: 180.7940\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.4258 - val_loss: 175.2537\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.0786 - val_loss: 163.4525\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.6321 - val_loss: 152.7706\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 138.8332 - val_loss: 149.5538\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0125 - val_loss: 135.1072\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.8687 - val_loss: 123.0292\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0636 - val_loss: 119.8137\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.7149 - val_loss: 116.7254\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.8660 - val_loss: 115.1836\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.7870 - val_loss: 111.0092\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.7280 - val_loss: 104.9840\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.3984 - val_loss: 110.1010\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.1922 - val_loss: 101.4131\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76.9418 - val_loss: 105.4196\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.8512 - val_loss: 95.8350\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.3780 - val_loss: 92.7828\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.9421 - val_loss: 92.5546\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.2491 - val_loss: 89.4598\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 70.7436 - val_loss: 91.1229\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.9193 - val_loss: 96.9997\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.5847 - val_loss: 85.6103\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.6457 - val_loss: 85.7475\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.2935 - val_loss: 82.1573\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 68.7749 - val_loss: 85.0111\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.1722 - val_loss: 79.9970\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.1496 - val_loss: 78.8809\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65.0001 - val_loss: 85.1919\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.5205 - val_loss: 75.7944\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63.1602 - val_loss: 75.9267\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 63.4387 - val_loss: 74.9353\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.3923 - val_loss: 74.0250\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.5811 - val_loss: 74.8457\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.1181 - val_loss: 72.4702\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63.4147 - val_loss: 70.7078\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 61.8613 - val_loss: 70.7511\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 60.8086 - val_loss: 70.7947\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 60.7049 - val_loss: 77.7407\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.9837 - val_loss: 69.0184\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 60.6613 - val_loss: 73.6681\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 60.0660 - val_loss: 70.5550\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 59.1491 - val_loss: 71.6046\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61.8172 - val_loss: 66.7222\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 58.6325 - val_loss: 71.1663\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 60.5832 - val_loss: 66.5156\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.2449 - val_loss: 68.0624\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 58.2853 - val_loss: 66.7368\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.2333 - val_loss: 69.1129\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 58.9513 - val_loss: 64.3389\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 59.0611 - val_loss: 67.7327\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.8413 - val_loss: 63.4169\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 57.0486 - val_loss: 65.5585\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 57.6582 - val_loss: 64.3272\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 66.1586 - val_loss: 85.3192\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 59.8462 - val_loss: 63.8150\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 57.5474 - val_loss: 62.1711\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 55.1334 - val_loss: 65.6197\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 54.9544 - val_loss: 64.8315\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.7963 - val_loss: 65.3182\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 54.7276 - val_loss: 64.3823\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54.4706 - val_loss: 60.6787\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 55.9465 - val_loss: 67.2649\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 55.2235 - val_loss: 59.2303\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 53.3228 - val_loss: 59.7607\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 54.4650 - val_loss: 59.6432\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 54.3274 - val_loss: 61.6694\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 58.6297 - val_loss: 58.4891\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.8212 - val_loss: 59.0462\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54.4864 - val_loss: 65.2642\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.9373 - val_loss: 57.4317\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.2137 - val_loss: 62.0199\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54.2151 - val_loss: 58.9343\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 57.8360 - val_loss: 56.4987\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52.2074 - val_loss: 57.5257\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 53.2364 - val_loss: 56.9760\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 51.9478 - val_loss: 58.5717\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52.1810 - val_loss: 61.2872\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.1880 - val_loss: 57.3784\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 52.1891 - val_loss: 56.6289\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 51.4414 - val_loss: 60.5429\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 56.9249 - val_loss: 55.8366\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.2888 - val_loss: 59.6458\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.5647 - val_loss: 58.4970\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 56.4635 - val_loss: 54.8959\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 50.1477 - val_loss: 62.0899\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52.0543 - val_loss: 55.5341\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 51.1894 - val_loss: 54.4838\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.6650 - val_loss: 55.4444\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 49.7936 - val_loss: 55.8036\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52.0113 - val_loss: 55.6549\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.4938 - val_loss: 62.2259\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.1660 - val_loss: 54.2780\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.7334 - val_loss: 55.6490\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.7614 - val_loss: 54.2953\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 53.3200 - val_loss: 55.5996\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.6099 - val_loss: 53.8601\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 77124.4297 - val_loss: 51680.7148\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 37953.9102 - val_loss: 24827.6406\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 17944.6270 - val_loss: 11746.5010\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8488.7246 - val_loss: 5657.1929\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4227.7798 - val_loss: 2846.4407\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2263.7952 - val_loss: 1563.9498\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1355.6436 - val_loss: 1009.0989\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 953.6286 - val_loss: 761.2803\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 764.6024 - val_loss: 610.9315\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 603.6100 - val_loss: 458.7314\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 438.7140 - val_loss: 377.2061\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.4341 - val_loss: 368.2744\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.8078 - val_loss: 341.8831\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 314.8552 - val_loss: 340.8035\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.6204 - val_loss: 333.7000\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.1750 - val_loss: 326.3316\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 291.8326 - val_loss: 323.7661\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.8299 - val_loss: 315.8904\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 279.9462 - val_loss: 310.0598\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 273.3048 - val_loss: 303.3193\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.7357 - val_loss: 298.4211\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 262.7586 - val_loss: 292.5517\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.9651 - val_loss: 286.9797\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.8174 - val_loss: 282.6732\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.6731 - val_loss: 276.5720\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.6402 - val_loss: 273.0157\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.1396 - val_loss: 267.3018\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.0782 - val_loss: 262.7155\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.0251 - val_loss: 257.7429\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.6818 - val_loss: 253.8002\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.9057 - val_loss: 249.2904\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.6064 - val_loss: 247.5216\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.5658 - val_loss: 241.5009\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.8689 - val_loss: 237.4189\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.8534 - val_loss: 234.2661\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206.5704 - val_loss: 229.2835\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.3977 - val_loss: 225.3680\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.1032 - val_loss: 224.6634\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.2326 - val_loss: 217.3189\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.0280 - val_loss: 215.4672\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.1638 - val_loss: 211.2180\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.2446 - val_loss: 207.8417\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.5608 - val_loss: 204.2459\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.6859 - val_loss: 199.8142\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.3976 - val_loss: 195.7919\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.0726 - val_loss: 193.5596\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.7375 - val_loss: 191.9037\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.6088 - val_loss: 187.9533\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.0290 - val_loss: 185.1727\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.2553 - val_loss: 184.3382\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.0370 - val_loss: 179.2995\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.0678 - val_loss: 179.4442\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.1264 - val_loss: 174.5873\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.2463 - val_loss: 172.7019\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.1104 - val_loss: 171.6745\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.3067 - val_loss: 168.7612\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.8525 - val_loss: 168.7006\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.5388 - val_loss: 164.8495\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.9400 - val_loss: 163.8838\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.4286 - val_loss: 161.6676\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.7396 - val_loss: 159.8783\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.2614 - val_loss: 158.6506\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.0233 - val_loss: 157.3026\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.6233 - val_loss: 155.7676\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.0718 - val_loss: 155.6916\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.8439 - val_loss: 152.6047\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.4980 - val_loss: 153.0193\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.0768 - val_loss: 150.3901\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.8473 - val_loss: 149.4796\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.1442 - val_loss: 148.0541\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.9124 - val_loss: 148.1756\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.3943 - val_loss: 146.3294\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.2382 - val_loss: 144.3152\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.2774 - val_loss: 143.1699\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.1234 - val_loss: 141.2554\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.7256 - val_loss: 142.7637\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.4265 - val_loss: 138.1806\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.0139 - val_loss: 137.6912\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.1349 - val_loss: 135.2666\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.5408 - val_loss: 135.3751\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.7356 - val_loss: 134.2130\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.2918 - val_loss: 133.2967\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.9338 - val_loss: 132.0736\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.0469 - val_loss: 130.9543\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.6060 - val_loss: 130.1071\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.5999 - val_loss: 128.4400\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.8737 - val_loss: 129.9169\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.8863 - val_loss: 127.3473\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5316 - val_loss: 125.8557\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.4738 - val_loss: 125.6445\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.9756 - val_loss: 124.8648\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.4877 - val_loss: 123.3256\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9464 - val_loss: 123.6557\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.1346 - val_loss: 122.8813\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.4800 - val_loss: 122.3003\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.8688 - val_loss: 122.4208\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.1244 - val_loss: 121.3208\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.3372 - val_loss: 120.4301\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.7193 - val_loss: 120.3142\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.9997 - val_loss: 120.3482\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 2476.3208 - val_loss: 1317.4081\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1029.9434 - val_loss: 810.7036\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 723.0545 - val_loss: 660.0061\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 597.9794 - val_loss: 558.5740\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 474.5283 - val_loss: 421.8038\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.9965 - val_loss: 362.4912\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.7416 - val_loss: 327.5840\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.1575 - val_loss: 306.9806\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.5957 - val_loss: 293.6811\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.9533 - val_loss: 284.0498\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.9350 - val_loss: 275.8002\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.7959 - val_loss: 269.4553\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.3246 - val_loss: 262.7663\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.9377 - val_loss: 256.0346\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.8563 - val_loss: 248.6504\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.9024 - val_loss: 238.0779\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.4487 - val_loss: 229.0836\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.2968 - val_loss: 220.6049\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.7112 - val_loss: 212.9363\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.1484 - val_loss: 205.3130\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.8820 - val_loss: 198.6349\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.9561 - val_loss: 193.6741\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.0139 - val_loss: 188.3156\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.4454 - val_loss: 184.8843\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.9087 - val_loss: 181.7911\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.1047 - val_loss: 181.8309\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.6375 - val_loss: 177.4395\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.0807 - val_loss: 178.2685\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.2145 - val_loss: 175.3277\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.4426 - val_loss: 174.4116\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.6427 - val_loss: 175.0330\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.2929 - val_loss: 174.4087\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.0659 - val_loss: 172.8124\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.9546 - val_loss: 172.2877\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8049 - val_loss: 170.5652\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.3610 - val_loss: 171.5025\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.5303 - val_loss: 168.5973\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.5822 - val_loss: 168.7788\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.0659 - val_loss: 166.7872\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.7995 - val_loss: 165.4851\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.7901 - val_loss: 165.1069\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.6758 - val_loss: 163.5434\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.1183 - val_loss: 164.2889\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.6415 - val_loss: 163.0792\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.8735 - val_loss: 161.3859\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.1267 - val_loss: 160.3509\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.7857 - val_loss: 160.3305\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.1435 - val_loss: 161.5720\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.8373 - val_loss: 159.6281\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0113 - val_loss: 157.9263\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8854 - val_loss: 157.3859\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.0075 - val_loss: 154.8306\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.3184 - val_loss: 156.8698\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7560 - val_loss: 155.5148\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.3950 - val_loss: 155.9754\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.5888 - val_loss: 154.8540\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6874 - val_loss: 152.3553\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.1337 - val_loss: 151.9463\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.6861 - val_loss: 152.7570\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.4736 - val_loss: 152.2041\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.2680 - val_loss: 149.7215\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.4604 - val_loss: 151.8698\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.3815 - val_loss: 147.3801\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.2077 - val_loss: 149.9809\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.9956 - val_loss: 150.8956\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.1803 - val_loss: 146.1789\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.1881 - val_loss: 146.1184\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.3277 - val_loss: 148.4372\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2820 - val_loss: 144.4988\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0889 - val_loss: 148.5879\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.1707 - val_loss: 144.2347\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5642 - val_loss: 142.7909\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.8015 - val_loss: 141.2641\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1001 - val_loss: 140.7834\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5368 - val_loss: 140.7973\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.9192 - val_loss: 139.3561\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.6576 - val_loss: 137.9063\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.8285 - val_loss: 138.5946\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6643 - val_loss: 141.0794\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6266 - val_loss: 140.4898\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.4334 - val_loss: 142.3062\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.7563 - val_loss: 139.7820\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.7594 - val_loss: 138.0713\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.8834 - val_loss: 136.1110\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7183 - val_loss: 137.1276\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1069 - val_loss: 136.1586\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6199 - val_loss: 137.4317\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.6942 - val_loss: 136.4173\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.2292 - val_loss: 134.9539\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.6995 - val_loss: 134.2157\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.9948 - val_loss: 132.0254\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.5658 - val_loss: 136.2205\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.0110 - val_loss: 134.6065\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.9908 - val_loss: 130.8649\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.9769 - val_loss: 131.9727\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.4784 - val_loss: 131.2296\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.1152 - val_loss: 129.1878\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.2803 - val_loss: 129.6513\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.3666 - val_loss: 131.0201\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.6889 - val_loss: 128.4267\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 1786.5386 - val_loss: 1127.2480\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 838.6808 - val_loss: 615.4655\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 561.6083 - val_loss: 472.1339\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 472.9878 - val_loss: 403.0948\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 410.1451 - val_loss: 357.5665\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 365.2463 - val_loss: 324.9340\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 332.3864 - val_loss: 300.2424\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.0536 - val_loss: 279.7313\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.3427 - val_loss: 261.9447\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 271.1058 - val_loss: 247.3704\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 256.3084 - val_loss: 234.6058\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.7862 - val_loss: 224.1866\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.0057 - val_loss: 214.0941\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.8524 - val_loss: 204.9465\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.6569 - val_loss: 197.1481\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.4242 - val_loss: 190.0114\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.4622 - val_loss: 184.3198\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.5765 - val_loss: 178.5644\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.5477 - val_loss: 174.7915\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.4894 - val_loss: 171.1357\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.1945 - val_loss: 167.5040\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.4577 - val_loss: 165.4623\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.9467 - val_loss: 162.8624\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.1426 - val_loss: 159.8872\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.3670 - val_loss: 157.7179\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.8416 - val_loss: 155.4220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.3933 - val_loss: 153.4881\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.3871 - val_loss: 151.0839\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.7793 - val_loss: 149.0535\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.6014 - val_loss: 147.0684\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.4043 - val_loss: 144.7184\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.1757 - val_loss: 142.1253\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.4293 - val_loss: 140.3190\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.6652 - val_loss: 137.9493\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.7628 - val_loss: 136.8334\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.3534 - val_loss: 135.1747\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.1219 - val_loss: 133.7050\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.1255 - val_loss: 132.7141\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.1295 - val_loss: 131.0445\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.1403 - val_loss: 129.4409\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0103 - val_loss: 128.1841\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6052 - val_loss: 126.9725\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9815 - val_loss: 125.5081\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7978 - val_loss: 124.8776\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.0003 - val_loss: 123.6865\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.5782 - val_loss: 122.7117\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.6749 - val_loss: 122.0616\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.1354 - val_loss: 120.5397\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4916 - val_loss: 120.2663\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.2865 - val_loss: 118.6571\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.8498 - val_loss: 117.8162\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.8521 - val_loss: 117.0774\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.5457 - val_loss: 116.5599\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5791 - val_loss: 116.0536\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4883 - val_loss: 116.2018\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.4865 - val_loss: 114.3624\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.7325 - val_loss: 114.1243\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5150 - val_loss: 113.6122\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.0307 - val_loss: 112.9452\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.3919 - val_loss: 113.6372\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.3658 - val_loss: 111.9927\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.2136 - val_loss: 111.9958\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.1793 - val_loss: 112.4235\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.8634 - val_loss: 111.9804\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.1856 - val_loss: 111.0266\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.1022 - val_loss: 112.1925\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.8659 - val_loss: 111.8282\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.9867 - val_loss: 110.9307\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.5185 - val_loss: 110.8182\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.7476 - val_loss: 111.7650\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.0079 - val_loss: 110.8726\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7805 - val_loss: 111.2587\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3553 - val_loss: 111.1549\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.7871 - val_loss: 112.4021\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.7746 - val_loss: 112.7138\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.4493 - val_loss: 110.9294\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5770 - val_loss: 110.9237\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5298 - val_loss: 111.2408\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.5953 - val_loss: 110.7225\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7762 - val_loss: 110.5793\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7852 - val_loss: 111.3510\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.1984 - val_loss: 110.6234\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.4940 - val_loss: 110.5747\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.1320 - val_loss: 110.6357\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.7783 - val_loss: 111.8698\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.3150 - val_loss: 110.5267\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.4958 - val_loss: 110.4030\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.5802 - val_loss: 110.9617\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1650 - val_loss: 110.2649\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.9087 - val_loss: 110.3539\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.5918 - val_loss: 109.7040\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.2551 - val_loss: 111.7173\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1374 - val_loss: 110.4452\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.2699 - val_loss: 109.6693\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.6333 - val_loss: 110.8806\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.2724 - val_loss: 109.8409\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.3140 - val_loss: 109.7680\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.6250 - val_loss: 109.8289\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1577 - val_loss: 111.4535\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.9664 - val_loss: 109.7980\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 89508.9375 - val_loss: 58948.3594\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 33862.7148 - val_loss: 14787.3975\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5538.2070 - val_loss: 1115.0566\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 979.2715 - val_loss: 863.8177\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 833.1265 - val_loss: 576.8013\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 549.6202 - val_loss: 580.1605\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 486.1290 - val_loss: 513.6620\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 442.3384 - val_loss: 458.6895\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 415.1800 - val_loss: 447.7968\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.5427 - val_loss: 442.6926\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.4483 - val_loss: 423.0823\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 359.9529 - val_loss: 405.5387\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 345.1797 - val_loss: 390.4575\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.8447 - val_loss: 376.7128\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 320.4239 - val_loss: 368.0808\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 308.0862 - val_loss: 347.6539\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.7202 - val_loss: 335.4774\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 287.5582 - val_loss: 334.4969\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 278.2542 - val_loss: 322.5273\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.8242 - val_loss: 309.2520\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.5677 - val_loss: 301.8333\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.2473 - val_loss: 291.5424\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.0021 - val_loss: 290.2781\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.6059 - val_loss: 277.7545\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.9082 - val_loss: 267.8892\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.8508 - val_loss: 268.2842\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.4513 - val_loss: 260.8830\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.2566 - val_loss: 249.8185\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.6419 - val_loss: 250.0798\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.5565 - val_loss: 240.1234\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.2838 - val_loss: 237.2676\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.0088 - val_loss: 229.5527\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.0798 - val_loss: 225.1768\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.3891 - val_loss: 221.9906\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186.0772 - val_loss: 215.4181\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.3528 - val_loss: 210.0900\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.2372 - val_loss: 212.7535\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.0870 - val_loss: 201.5370\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.2676 - val_loss: 200.9735\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.5730 - val_loss: 199.6954\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.2911 - val_loss: 196.6704\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.3119 - val_loss: 191.6013\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.2871 - val_loss: 186.7883\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.9323 - val_loss: 187.9886\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.4348 - val_loss: 182.0558\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.6356 - val_loss: 181.7346\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.3906 - val_loss: 177.8753\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.2749 - val_loss: 176.5855\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.3345 - val_loss: 175.1117\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.3021 - val_loss: 171.7815\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.8984 - val_loss: 171.4456\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.2394 - val_loss: 167.6903\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.2815 - val_loss: 165.3676\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.2995 - val_loss: 162.7430\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.8329 - val_loss: 164.9881\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.0557 - val_loss: 161.4108\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.8250 - val_loss: 158.7247\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.0856 - val_loss: 158.6354\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.8679 - val_loss: 160.6633\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.6002 - val_loss: 154.4740\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9679 - val_loss: 156.0630\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.5472 - val_loss: 154.2086\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.7148 - val_loss: 151.2983\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.7443 - val_loss: 151.2447\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.8606 - val_loss: 151.2146\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.3090 - val_loss: 148.5327\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.2374 - val_loss: 146.6534\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.5234 - val_loss: 145.9395\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2552 - val_loss: 147.8307\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.3673 - val_loss: 144.2402\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.7044 - val_loss: 146.7850\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.0981 - val_loss: 144.2149\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.5784 - val_loss: 144.5324\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.3832 - val_loss: 142.9512\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1909 - val_loss: 140.4929\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.2740 - val_loss: 143.0754\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9017 - val_loss: 142.4348\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.6812 - val_loss: 142.8660\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.0615 - val_loss: 138.3418\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7663 - val_loss: 141.1710\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.1774 - val_loss: 139.1551\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.4772 - val_loss: 140.3351\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.5718 - val_loss: 141.2391\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.4422 - val_loss: 137.3317\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5410 - val_loss: 140.5467\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.8210 - val_loss: 137.2004\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7178 - val_loss: 138.3046\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4310 - val_loss: 135.9017\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6310 - val_loss: 141.6732\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.0379 - val_loss: 138.1527\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3537 - val_loss: 133.4943\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.2501 - val_loss: 137.6894\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.7465 - val_loss: 134.9997\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6354 - val_loss: 134.7664\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.5427 - val_loss: 132.1299\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.3872 - val_loss: 136.0684\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.5327 - val_loss: 132.5248\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4302 - val_loss: 136.9636\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8042 - val_loss: 132.2510\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.5164 - val_loss: 138.0714\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 38917.4766 - val_loss: 28378.9863\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20393.0234 - val_loss: 14316.5459\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9219.4922 - val_loss: 6307.0732\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3696.3958 - val_loss: 2824.5774\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1862.0471 - val_loss: 1757.4325\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1277.7913 - val_loss: 1351.7908\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 998.9573 - val_loss: 1136.2086\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 845.2387 - val_loss: 964.3080\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 739.1010 - val_loss: 848.9218\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 654.2261 - val_loss: 758.3143\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 584.6906 - val_loss: 691.4432\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 536.6031 - val_loss: 635.5574\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 492.0894 - val_loss: 578.5600\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 457.0164 - val_loss: 562.2731\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 429.2795 - val_loss: 518.5677\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 408.3253 - val_loss: 504.2436\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 387.2104 - val_loss: 469.3409\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 373.5983 - val_loss: 456.2304\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.7918 - val_loss: 441.0024\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.9805 - val_loss: 432.9001\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 343.4620 - val_loss: 420.7520\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 336.7163 - val_loss: 411.8037\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328.7582 - val_loss: 402.5883\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 322.4292 - val_loss: 397.1100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.4016 - val_loss: 388.7867\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 309.9145 - val_loss: 383.2504\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.9925 - val_loss: 371.4227\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.4139 - val_loss: 374.6745\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.1334 - val_loss: 365.9615\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 289.4412 - val_loss: 358.5631\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 283.4215 - val_loss: 347.5152\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.8847 - val_loss: 342.1321\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.9508 - val_loss: 342.5942\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.5160 - val_loss: 333.1806\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.1277 - val_loss: 325.6328\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.1888 - val_loss: 319.9305\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.2395 - val_loss: 318.1880\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.1200 - val_loss: 308.6790\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 244.2190 - val_loss: 306.1620\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.3274 - val_loss: 295.2868\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.5023 - val_loss: 292.3276\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.6174 - val_loss: 304.7360\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.5885 - val_loss: 284.6473\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.3923 - val_loss: 295.1729\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.7582 - val_loss: 276.9689\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.6497 - val_loss: 278.6133\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.8043 - val_loss: 268.4475\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.3272 - val_loss: 268.2715\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.1196 - val_loss: 258.9265\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 188.1808 - val_loss: 256.9476\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.8011 - val_loss: 258.1842\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.8679 - val_loss: 247.9175\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.7865 - val_loss: 260.6053\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.7456 - val_loss: 241.4935\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.0849 - val_loss: 240.5124\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.2809 - val_loss: 237.0783\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.2116 - val_loss: 236.0149\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.4691 - val_loss: 239.6718\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.2325 - val_loss: 228.6844\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.0531 - val_loss: 234.6138\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.2781 - val_loss: 229.9763\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.1616 - val_loss: 221.0807\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.2192 - val_loss: 219.2757\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.6124 - val_loss: 223.4744\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.7250 - val_loss: 216.5736\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.1172 - val_loss: 219.9345\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.7912 - val_loss: 212.0971\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3909 - val_loss: 208.8852\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.6494 - val_loss: 219.9102\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.9838 - val_loss: 213.8713\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9602 - val_loss: 205.0867\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.1087 - val_loss: 208.5764\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.7228 - val_loss: 203.5311\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.0515 - val_loss: 211.2734\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.5945 - val_loss: 198.9880\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.0395 - val_loss: 196.5467\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.0470 - val_loss: 199.0316\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.7418 - val_loss: 195.8719\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.2778 - val_loss: 191.4515\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.2542 - val_loss: 195.1642\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.8046 - val_loss: 189.5035\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.9414 - val_loss: 195.4137\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.3761 - val_loss: 205.9072\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.8017 - val_loss: 190.2728\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.7060 - val_loss: 187.1135\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.9849 - val_loss: 182.8773\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.1551 - val_loss: 181.4519\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5598 - val_loss: 190.6443\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.5014 - val_loss: 189.5668\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8706 - val_loss: 181.9700\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.2228 - val_loss: 181.8919\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7421 - val_loss: 179.6313\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2619 - val_loss: 181.4140\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.0058 - val_loss: 181.0226\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4351 - val_loss: 180.6909\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8664 - val_loss: 184.7958\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.9682 - val_loss: 172.2172\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.9742 - val_loss: 171.5838\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.8379 - val_loss: 175.7998\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.2119 - val_loss: 174.4374\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 85964.2266 - val_loss: 52599.6680\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 33498.5781 - val_loss: 17266.9199\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9472.3467 - val_loss: 4253.0859\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2749.4407 - val_loss: 2533.2612\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2224.3074 - val_loss: 2116.5959\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1765.3379 - val_loss: 1743.5314\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1499.2806 - val_loss: 1494.3604\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1287.4420 - val_loss: 1258.1704\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1081.4037 - val_loss: 1084.8568\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 929.4713 - val_loss: 931.6290\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 802.9804 - val_loss: 801.4547\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 696.3344 - val_loss: 694.3639\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 604.8401 - val_loss: 605.4489\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 533.0843 - val_loss: 529.0392\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 472.7114 - val_loss: 473.2267\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 427.8030 - val_loss: 428.2737\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 392.3097 - val_loss: 390.8735\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.9948 - val_loss: 359.5696\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 336.7018 - val_loss: 334.1115\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.9740 - val_loss: 313.3782\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 302.9515 - val_loss: 296.6872\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.6533 - val_loss: 277.3815\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 276.6986 - val_loss: 263.5005\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.9416 - val_loss: 252.0804\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.1316 - val_loss: 237.6494\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.4611 - val_loss: 227.2820\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.4043 - val_loss: 220.5606\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.1162 - val_loss: 214.5878\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.5159 - val_loss: 210.2663\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.4194 - val_loss: 207.0675\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.2399 - val_loss: 204.1162\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.7340 - val_loss: 201.8738\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.4283 - val_loss: 199.3415\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.4207 - val_loss: 197.2191\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.9443 - val_loss: 195.6174\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.8873 - val_loss: 193.2829\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.4671 - val_loss: 192.6899\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.7246 - val_loss: 190.2345\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.1207 - val_loss: 188.2557\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.2150 - val_loss: 188.3370\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.6040 - val_loss: 185.5428\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.5893 - val_loss: 184.1356\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.6108 - val_loss: 183.5644\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.7773 - val_loss: 182.5397\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.1674 - val_loss: 182.2316\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 200.3916 - val_loss: 180.7992\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.8801 - val_loss: 180.7482\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.2245 - val_loss: 179.5163\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.3297 - val_loss: 177.9122\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.2151 - val_loss: 178.0137\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.2985 - val_loss: 176.0587\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.7305 - val_loss: 176.8996\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192.1929 - val_loss: 174.4787\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.3316 - val_loss: 174.7578\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.8195 - val_loss: 172.9329\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.9989 - val_loss: 173.3946\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.3627 - val_loss: 172.0950\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.8605 - val_loss: 172.5379\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.2648 - val_loss: 170.6998\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.4005 - val_loss: 171.8497\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.7698 - val_loss: 167.8704\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.9993 - val_loss: 168.1454\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.6025 - val_loss: 167.0144\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.4290 - val_loss: 167.0816\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.4102 - val_loss: 164.2538\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.3316 - val_loss: 165.9283\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.3004 - val_loss: 163.2941\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.1369 - val_loss: 164.4277\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.7653 - val_loss: 161.7058\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.0320 - val_loss: 164.8485\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.0613 - val_loss: 160.4539\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.0751 - val_loss: 163.8736\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.2365 - val_loss: 158.6126\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.6450 - val_loss: 159.1251\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.5085 - val_loss: 158.3381\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.3237 - val_loss: 157.5567\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.6848 - val_loss: 157.8276\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.3988 - val_loss: 155.9727\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.6095 - val_loss: 156.9162\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.8201 - val_loss: 157.0367\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.4189 - val_loss: 155.8291\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.4786 - val_loss: 156.0923\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.4282 - val_loss: 153.6877\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.8377 - val_loss: 153.8092\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.7872 - val_loss: 154.1476\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.1302 - val_loss: 152.3652\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.1556 - val_loss: 152.6688\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.1763 - val_loss: 153.3056\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.9218 - val_loss: 151.1154\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.2686 - val_loss: 156.2438\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.9394 - val_loss: 152.2542\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.5881 - val_loss: 150.8205\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.1825 - val_loss: 150.0033\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.4128 - val_loss: 149.8056\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.9745 - val_loss: 152.1975\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.2018 - val_loss: 154.0735\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.1270 - val_loss: 148.4205\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.8276 - val_loss: 148.3964\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.0736 - val_loss: 158.7574\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.2489 - val_loss: 147.2739\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 96436.9688 - val_loss: 73315.6797\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 55267.1367 - val_loss: 37318.0312\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 24096.5195 - val_loss: 13118.7373\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7231.6128 - val_loss: 3680.3755\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2959.9563 - val_loss: 2351.7727\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2213.4685 - val_loss: 1700.1139\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1600.8878 - val_loss: 1320.2264\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1259.1721 - val_loss: 1093.2799\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1046.5199 - val_loss: 952.6972\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 910.9422 - val_loss: 858.4836\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 823.1295 - val_loss: 789.3716\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 751.8677 - val_loss: 730.1854\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 689.3219 - val_loss: 669.0461\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 626.3945 - val_loss: 614.9394\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 573.2987 - val_loss: 565.6325\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 533.9179 - val_loss: 521.2363\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 502.0112 - val_loss: 487.1574\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 473.2762 - val_loss: 456.0041\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 449.4439 - val_loss: 431.3327\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 427.3785 - val_loss: 406.6617\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 408.1292 - val_loss: 384.1500\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 390.3045 - val_loss: 369.5796\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 372.5823 - val_loss: 348.0116\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.7952 - val_loss: 333.2400\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 341.4481 - val_loss: 322.6106\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 327.1479 - val_loss: 309.4575\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.3056 - val_loss: 298.5326\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.0432 - val_loss: 295.2725\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.2809 - val_loss: 286.3427\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.3499 - val_loss: 277.2003\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.2175 - val_loss: 277.9793\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.8955 - val_loss: 264.7497\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 271.0890 - val_loss: 259.7203\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.1920 - val_loss: 255.4183\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 260.5779 - val_loss: 251.3301\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.0519 - val_loss: 247.2646\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.2384 - val_loss: 241.3666\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 245.9286 - val_loss: 235.7957\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.3802 - val_loss: 233.7480\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 237.1895 - val_loss: 229.3038\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.0411 - val_loss: 224.5526\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.9093 - val_loss: 222.4220\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.5986 - val_loss: 221.0372\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.1448 - val_loss: 216.2637\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 218.8795 - val_loss: 215.7506\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.8327 - val_loss: 211.3091\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0197 - val_loss: 210.6249\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.5654 - val_loss: 206.4586\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.5692 - val_loss: 203.4762\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.8156 - val_loss: 203.3352\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.4300 - val_loss: 201.0695\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.3733 - val_loss: 197.1829\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.3623 - val_loss: 198.8522\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.6215 - val_loss: 194.3894\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.3464 - val_loss: 195.8676\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.5513 - val_loss: 191.8319\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.8443 - val_loss: 191.7603\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.3928 - val_loss: 189.1774\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.4606 - val_loss: 188.8033\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.7780 - val_loss: 185.2698\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.2570 - val_loss: 185.0983\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.7387 - val_loss: 182.1625\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.0664 - val_loss: 182.1675\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.7097 - val_loss: 182.5473\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.6431 - val_loss: 178.9326\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.5624 - val_loss: 178.9404\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0048 - val_loss: 177.3530\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.3141 - val_loss: 176.1753\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.8934 - val_loss: 175.2905\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.9256 - val_loss: 174.4003\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.4444 - val_loss: 172.8596\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.5739 - val_loss: 172.5972\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.7431 - val_loss: 172.0295\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.2685 - val_loss: 170.5913\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.4294 - val_loss: 172.0401\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.7725 - val_loss: 170.0446\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.5394 - val_loss: 168.9268\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.3744 - val_loss: 169.9538\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.6656 - val_loss: 167.9012\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.4661 - val_loss: 166.7294\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.3083 - val_loss: 166.6730\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.0918 - val_loss: 167.9273\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.7070 - val_loss: 165.8256\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.7396 - val_loss: 165.0279\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.9740 - val_loss: 164.1274\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.1500 - val_loss: 164.9263\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.2033 - val_loss: 163.0343\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.0855 - val_loss: 164.6778\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.4013 - val_loss: 162.9198\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.7423 - val_loss: 162.2231\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.8745 - val_loss: 161.8447\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.3918 - val_loss: 160.8824\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.9327 - val_loss: 164.0524\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.9402 - val_loss: 160.3938\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.8215 - val_loss: 159.3697\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.4849 - val_loss: 161.4360\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.3632 - val_loss: 158.8960\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.7161 - val_loss: 158.7617\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.1492 - val_loss: 158.3300\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.0182 - val_loss: 160.1032\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 369.8487 - val_loss: 340.7558\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 321.6335 - val_loss: 308.1579\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 283.2159 - val_loss: 286.4181\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.1737 - val_loss: 268.4911\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.4613 - val_loss: 251.6740\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.1078 - val_loss: 241.9195\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.7388 - val_loss: 221.8549\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.7717 - val_loss: 213.0985\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.1230 - val_loss: 205.8574\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.9910 - val_loss: 201.2398\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.3962 - val_loss: 189.3078\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.6008 - val_loss: 184.2611\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.5320 - val_loss: 181.0989\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.3204 - val_loss: 189.6251\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.4948 - val_loss: 168.1769\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.5972 - val_loss: 167.3234\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.6634 - val_loss: 161.0549\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.9084 - val_loss: 157.2336\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.9449 - val_loss: 164.4336\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.3616 - val_loss: 150.2626\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.4688 - val_loss: 147.7322\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.8142 - val_loss: 148.1654\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.2593 - val_loss: 141.5774\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6334 - val_loss: 144.3481\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0342 - val_loss: 137.8130\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6051 - val_loss: 134.2987\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.0856 - val_loss: 130.2160\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6858 - val_loss: 126.2784\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9210 - val_loss: 122.9911\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.7115 - val_loss: 119.6934\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.5882 - val_loss: 112.2921\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.0024 - val_loss: 107.4633\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.5623 - val_loss: 102.7137\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.0052 - val_loss: 98.9566\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.5945 - val_loss: 95.1509\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.4263 - val_loss: 92.7325\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.4277 - val_loss: 90.4531\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 79.6785 - val_loss: 91.1313\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.6792 - val_loss: 87.6898\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.8486 - val_loss: 86.4351\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.8922 - val_loss: 85.4824\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.5886 - val_loss: 85.2815\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.2357 - val_loss: 84.3288\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 72.1321 - val_loss: 83.7293\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.8721 - val_loss: 82.4927\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.2846 - val_loss: 81.2111\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.8419 - val_loss: 80.5228\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.3489 - val_loss: 85.4128\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.8722 - val_loss: 78.8479\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.4596 - val_loss: 77.0061\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65.2338 - val_loss: 75.8110\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.0362 - val_loss: 86.6685\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 68.8680 - val_loss: 89.2661\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.4866 - val_loss: 74.4874\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.0000 - val_loss: 72.5813\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61.7169 - val_loss: 71.4457\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61.4631 - val_loss: 76.5534\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.8523 - val_loss: 72.1263\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 60.8763 - val_loss: 71.8764\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 59.3049 - val_loss: 67.8616\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 59.3635 - val_loss: 67.0336\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 58.7246 - val_loss: 66.1686\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 58.1933 - val_loss: 65.1095\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 58.9320 - val_loss: 64.8083\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 56.9001 - val_loss: 64.0571\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 55.9407 - val_loss: 65.0119\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.5866 - val_loss: 65.5629\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.5884 - val_loss: 61.6193\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 56.7347 - val_loss: 62.2492\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 55.2369 - val_loss: 60.5796\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54.2465 - val_loss: 59.3357\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 54.3951 - val_loss: 60.0620\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54.1334 - val_loss: 58.0036\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 55.4087 - val_loss: 62.9407\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 55.9917 - val_loss: 59.2525\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 53.1042 - val_loss: 57.5034\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.3665 - val_loss: 57.4549\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.3634 - val_loss: 57.7836\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 52.1315 - val_loss: 56.8013\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.6707 - val_loss: 56.7681\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.1562 - val_loss: 59.3714\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 53.6307 - val_loss: 58.9114\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.9155 - val_loss: 59.9860\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 54.6704 - val_loss: 57.5277\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52.5952 - val_loss: 55.7899\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 53.1062 - val_loss: 55.5680\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 51.2913 - val_loss: 56.2085\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 51.2322 - val_loss: 55.5237\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.7820 - val_loss: 55.7480\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.8229 - val_loss: 54.4267\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 50.0949 - val_loss: 54.7445\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.5354 - val_loss: 54.6715\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50.0047 - val_loss: 55.4564\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 51.0838 - val_loss: 63.6578\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 55.5907 - val_loss: 55.1488\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 51.4425 - val_loss: 53.4410\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 51.9860 - val_loss: 54.6947\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 49.8673 - val_loss: 56.0892\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 49.5972 - val_loss: 58.4475\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 53.9525 - val_loss: 53.7609\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 21239.1152 - val_loss: 14920.6904\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10474.6670 - val_loss: 6515.4106\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4085.6284 - val_loss: 2181.2764\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1210.3348 - val_loss: 634.3698\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 403.5307 - val_loss: 354.8385\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 312.8353 - val_loss: 340.4008\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 306.6841 - val_loss: 330.2700\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.2992 - val_loss: 324.1265\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.4393 - val_loss: 320.8328\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.4043 - val_loss: 316.6018\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.7907 - val_loss: 312.3266\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.4776 - val_loss: 308.1667\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 279.4047 - val_loss: 304.1829\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.8404 - val_loss: 300.3194\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.7685 - val_loss: 297.1577\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.3311 - val_loss: 293.9636\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.9375 - val_loss: 291.3301\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.9783 - val_loss: 288.2384\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.4783 - val_loss: 284.7582\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.7207 - val_loss: 278.2440\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.2719 - val_loss: 275.5479\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.1267 - val_loss: 272.9588\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 246.4372 - val_loss: 267.5641\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.2344 - val_loss: 264.3313\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 243.1005 - val_loss: 262.2244\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.2752 - val_loss: 257.3326\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.7793 - val_loss: 255.4633\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.3850 - val_loss: 251.0724\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.6349 - val_loss: 251.2263\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.3829 - val_loss: 244.9232\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.8833 - val_loss: 242.0974\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.4050 - val_loss: 238.9974\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.8244 - val_loss: 236.0183\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.9199 - val_loss: 231.8467\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.7246 - val_loss: 229.6025\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.0267 - val_loss: 224.1357\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.0312 - val_loss: 220.5099\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.5992 - val_loss: 213.8844\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.9800 - val_loss: 207.7914\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.8491 - val_loss: 204.9537\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.9792 - val_loss: 200.5362\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.4425 - val_loss: 195.7628\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.6543 - val_loss: 194.4181\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.6882 - val_loss: 189.2054\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.3533 - val_loss: 187.9988\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.7579 - val_loss: 182.2583\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.2155 - val_loss: 182.9723\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.1639 - val_loss: 176.5669\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.6066 - val_loss: 177.9959\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.5228 - val_loss: 175.1722\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.8528 - val_loss: 172.0141\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.2992 - val_loss: 170.4499\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 161.0384 - val_loss: 167.9347\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.5880 - val_loss: 168.4600\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4635 - val_loss: 164.3002\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.0424 - val_loss: 164.7589\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.3975 - val_loss: 160.5161\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.6706 - val_loss: 160.9341\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.5984 - val_loss: 157.8110\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.0216 - val_loss: 158.5981\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.0339 - val_loss: 155.3349\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.5609 - val_loss: 155.1110\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.5299 - val_loss: 152.8909\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.3676 - val_loss: 150.9919\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3226 - val_loss: 152.0072\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.0585 - val_loss: 149.6686\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.1158 - val_loss: 148.0199\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.2639 - val_loss: 147.8369\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4940 - val_loss: 147.5106\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.3097 - val_loss: 143.3750\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.3084 - val_loss: 142.7313\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.3967 - val_loss: 141.5600\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.7741 - val_loss: 141.5690\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.2756 - val_loss: 139.4341\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.0452 - val_loss: 138.1538\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.3785 - val_loss: 139.9358\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9777 - val_loss: 137.8181\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.4304 - val_loss: 136.0221\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.0111 - val_loss: 137.5129\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.2555 - val_loss: 136.4184\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.9464 - val_loss: 132.1443\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.8909 - val_loss: 131.9480\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.5324 - val_loss: 131.3322\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.8187 - val_loss: 131.5195\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.1848 - val_loss: 130.3192\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1113 - val_loss: 128.4299\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.5010 - val_loss: 127.9851\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3335 - val_loss: 127.3436\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.5488 - val_loss: 126.6407\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.6308 - val_loss: 126.4469\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.8299 - val_loss: 124.1939\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.8009 - val_loss: 126.2987\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.2819 - val_loss: 122.0602\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6681 - val_loss: 123.3829\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2031 - val_loss: 122.4563\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.0058 - val_loss: 122.1957\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4116 - val_loss: 119.6782\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.2968 - val_loss: 124.1010\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.6863 - val_loss: 117.6344\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4523 - val_loss: 119.8447\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 21437.7441 - val_loss: 11719.8408\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6013.3071 - val_loss: 2611.5378\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1153.0242 - val_loss: 745.0390\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 522.4060 - val_loss: 689.2288\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 498.4609 - val_loss: 614.5410\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 446.5162 - val_loss: 571.5825\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 423.4062 - val_loss: 535.1832\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 403.2413 - val_loss: 499.8902\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 384.1261 - val_loss: 472.2001\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.3332 - val_loss: 448.6949\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.2493 - val_loss: 422.2478\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 341.7819 - val_loss: 399.6860\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.6348 - val_loss: 381.5837\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 318.2383 - val_loss: 362.8772\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.3710 - val_loss: 347.2010\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.9685 - val_loss: 333.4583\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.7758 - val_loss: 319.4503\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.8525 - val_loss: 308.3135\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 276.3000 - val_loss: 296.6201\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.9654 - val_loss: 287.1674\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.4431 - val_loss: 277.6007\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.6569 - val_loss: 270.0075\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.1599 - val_loss: 260.3941\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.3610 - val_loss: 252.7246\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.6224 - val_loss: 246.1068\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.8934 - val_loss: 239.6924\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.8796 - val_loss: 233.1460\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229.2709 - val_loss: 228.2272\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.7384 - val_loss: 221.9157\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 221.8947 - val_loss: 216.8720\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.2766 - val_loss: 212.7511\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.2946 - val_loss: 207.8846\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.7362 - val_loss: 203.5945\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.2960 - val_loss: 199.0505\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.5229 - val_loss: 195.4418\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.8450 - val_loss: 192.0699\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.8791 - val_loss: 187.4104\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.1680 - val_loss: 184.9549\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.6161 - val_loss: 180.5240\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.4787 - val_loss: 177.6095\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.3855 - val_loss: 174.1630\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.2679 - val_loss: 171.8016\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.8527 - val_loss: 168.5670\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.4328 - val_loss: 165.6417\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.8997 - val_loss: 163.0719\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.4691 - val_loss: 160.0730\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.5593 - val_loss: 159.6011\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.5736 - val_loss: 155.6629\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.0621 - val_loss: 153.6621\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.6168 - val_loss: 151.2038\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.4749 - val_loss: 149.8754\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.3094 - val_loss: 147.1355\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.5312 - val_loss: 146.4255\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.1515 - val_loss: 143.6897\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.8219 - val_loss: 143.1112\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.0146 - val_loss: 140.7839\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.8728 - val_loss: 140.0102\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.3802 - val_loss: 138.4850\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.2306 - val_loss: 136.9193\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.1060 - val_loss: 135.9385\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.6853 - val_loss: 134.4104\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.8102 - val_loss: 135.5589\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.1708 - val_loss: 132.5540\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.3466 - val_loss: 133.2697\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.3057 - val_loss: 130.8220\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.5956 - val_loss: 131.5453\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.1930 - val_loss: 129.3288\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.5838 - val_loss: 128.7043\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.3063 - val_loss: 128.0166\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.5408 - val_loss: 128.0580\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.9685 - val_loss: 127.7246\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.0313 - val_loss: 127.4954\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.9567 - val_loss: 125.8307\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.2373 - val_loss: 125.6940\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.7926 - val_loss: 125.1032\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.9588 - val_loss: 124.5131\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.6380 - val_loss: 124.2268\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.5694 - val_loss: 125.4898\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 142.7401 - val_loss: 124.3276\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.2313 - val_loss: 125.3801\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9773 - val_loss: 122.7142\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.2230 - val_loss: 122.5599\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.2840 - val_loss: 122.1020\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.5472 - val_loss: 122.2229\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.8385 - val_loss: 121.3345\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.6650 - val_loss: 120.9992\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.2563 - val_loss: 120.7141\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.5043 - val_loss: 120.4721\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.3695 - val_loss: 121.8691\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.1978 - val_loss: 119.7791\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.8012 - val_loss: 119.3903\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.5057 - val_loss: 119.4737\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.3175 - val_loss: 120.2149\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.4153 - val_loss: 119.9678\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.1778 - val_loss: 118.6997\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.6160 - val_loss: 117.9296\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.0325 - val_loss: 117.6520\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.9399 - val_loss: 117.3440\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.2521 - val_loss: 117.3550\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.0227 - val_loss: 118.4877\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 64005.3867 - val_loss: 43846.0547\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 35056.7539 - val_loss: 23097.1777\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 17769.1309 - val_loss: 10708.0234\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8066.5088 - val_loss: 4599.1865\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3683.5491 - val_loss: 2194.3010\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1842.6069 - val_loss: 1282.0793\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1147.3601 - val_loss: 926.4332\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 841.7432 - val_loss: 695.2700\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 643.4505 - val_loss: 544.0154\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 507.5761 - val_loss: 454.4781\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 417.0777 - val_loss: 384.2162\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 357.7872 - val_loss: 335.9312\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 324.6579 - val_loss: 316.8988\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.8299 - val_loss: 285.5779\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.9395 - val_loss: 272.5271\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 255.4351 - val_loss: 259.1992\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.0777 - val_loss: 249.9249\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.5589 - val_loss: 245.7392\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.6546 - val_loss: 237.6899\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.5168 - val_loss: 235.2267\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.3880 - val_loss: 229.0497\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 213.2920 - val_loss: 223.1006\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.5197 - val_loss: 223.5760\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.2593 - val_loss: 216.1613\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.1890 - val_loss: 210.8786\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.7146 - val_loss: 207.0394\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.6606 - val_loss: 204.5226\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.4893 - val_loss: 202.0186\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.8797 - val_loss: 199.6820\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.8374 - val_loss: 195.3676\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 174.6329 - val_loss: 192.3329\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.1636 - val_loss: 190.4579\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.1623 - val_loss: 186.3111\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.1801 - val_loss: 188.4920\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.8337 - val_loss: 181.9686\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.6088 - val_loss: 180.1026\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.7604 - val_loss: 177.2854\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.3380 - val_loss: 176.6669\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.5309 - val_loss: 172.7699\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.0323 - val_loss: 170.2566\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.9463 - val_loss: 168.8736\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.3842 - val_loss: 169.5682\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.5963 - val_loss: 164.9692\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.3832 - val_loss: 163.9239\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.2371 - val_loss: 162.2174\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.8568 - val_loss: 164.9521\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.4047 - val_loss: 161.6208\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3794 - val_loss: 158.7129\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3446 - val_loss: 159.0453\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.2573 - val_loss: 157.4227\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.6679 - val_loss: 156.1301\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.2277 - val_loss: 155.2816\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.7664 - val_loss: 155.6399\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.5960 - val_loss: 153.2472\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8566 - val_loss: 151.9618\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.9662 - val_loss: 155.0817\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.1493 - val_loss: 150.4633\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.0206 - val_loss: 151.9520\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.6538 - val_loss: 148.7331\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.5641 - val_loss: 152.1850\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.0831 - val_loss: 150.1349\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.4308 - val_loss: 146.7982\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.2144 - val_loss: 146.3902\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.2222 - val_loss: 144.8667\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.8697 - val_loss: 148.1903\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.6371 - val_loss: 148.5033\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2285 - val_loss: 142.8961\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5173 - val_loss: 143.4269\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2941 - val_loss: 142.1430\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.2737 - val_loss: 141.6819\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1429 - val_loss: 140.1673\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8942 - val_loss: 140.7855\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.9651 - val_loss: 146.2078\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.1770 - val_loss: 137.3123\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.0188 - val_loss: 136.5569\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.1289 - val_loss: 136.5056\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.3055 - val_loss: 134.9409\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.3235 - val_loss: 137.4666\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3831 - val_loss: 133.7521\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3912 - val_loss: 133.9773\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4842 - val_loss: 132.4949\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.4185 - val_loss: 134.6581\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.1655 - val_loss: 131.0960\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.9094 - val_loss: 133.4099\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.5494 - val_loss: 131.8743\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.5758 - val_loss: 129.8238\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.4110 - val_loss: 130.1797\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.5372 - val_loss: 128.6947\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.7132 - val_loss: 131.5821\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.8246 - val_loss: 128.5022\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6572 - val_loss: 127.2858\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4894 - val_loss: 126.7358\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.7102 - val_loss: 127.6718\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.5693 - val_loss: 126.5361\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2516 - val_loss: 131.4180\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.3743 - val_loss: 126.2775\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8174 - val_loss: 126.9188\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.9318 - val_loss: 125.1640\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.1809 - val_loss: 127.8008\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7818 - val_loss: 124.8794\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total Execution Time :  0:08:05.727960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPxTesMSOfoH",
        "outputId": "3ca62ec7-7c66-472f-941b-a448948e44a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' , str(std_of_mse))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  145.7193482478024\n",
            "Standard Deviation of MSE of 50 Models :  182.78431142517368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XBvRqPFOfoH"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1glOloVbOfoH"
      },
      "source": [
        "#### <font color = green> Comparision of Mean of MSE with Mean of MSE from PART B </font>\n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <th>Mean of MSE of PART A</th>\n",
        "    <th>Mean of MSE of PART B</th>\n",
        "    <th>Mean of MSE of PART C</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>244.77</td>\n",
        "    <td>126.13</td>\n",
        "    <td>149.31</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "The table above compares the Mean of **MSE for PART A**, **Mean of MSE for PART B** and **Mean of MSE for PART C**. As can be seen, the value of Mean of MSE of PART C is marginally larger than that of PART B. This shows that the effect of **normalizing the features** as well as **increasing the number of epochs by 2** did not improve the performance of the regression model and helps it in finding the line of best fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr0j3_87OfoH"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71BpfzuZOfoH"
      },
      "source": [
        "# <font color = blue> END OF PART C </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm_niybjOfoH"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGYfBFpbOfoH"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mudDH-O8OfoH"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjtY7pwxOfoI"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bysCsOEOfoJ"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxhKR3pcOfoJ"
      },
      "source": [
        "# <font color = blue> PART D : BASELINE MODEL WITH INCREASED HIDDEN LAYERS </font>\n",
        "\n",
        "\n",
        "In this part, all the tasks from <b>PART B</b> are performed, but this time the number of hidden layers are increased to 3\n",
        "\n",
        "<b>The new model will have : </b>\n",
        "<ul>\n",
        "        <li> Input layer with 10 nodes </li>\n",
        "        <li> 3 hidden layers, each with 10 nodes and ReLU activation function </li>\n",
        "        <li> Adam optimizer and mean squared error loss function </li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ-8eRWFOfoJ"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vgS2NH2OfoJ"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZRoEKIPOfoJ"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model with 100 epochs and Increased Hidden Layers</font>\n",
        "\n",
        "In order to train and test the the baseline model with normalized features, 100 epochs and increased hidden layers, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Normalize the features (X)</li>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Create a new model with 100 epochs</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW9FQ3pYOfoJ"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Normalize the features (X) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTJzJb6vOfoJ"
      },
      "source": [
        "<b>Note</b> : As the features (X) have already been normalized the features (X), hence this part is skipped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkr_jkwTOfoJ"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7OG0ODZOfoJ"
      },
      "source": [
        "# Creating X_train, X_test, Y_train and Y_test sets\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leHwFLK9OfoK"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Create a new regression model with 3 hidden layers, each with 10 nodes and ReLU activation  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7qk0EzOOfoK"
      },
      "source": [
        "def three_layer_regression_model () :\n",
        "    \n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ff30yAQOfoK"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYoJB9CNOfoK"
      },
      "source": [
        "<b>Note </b> : Since the regression model has already been created using `def regression_model` in <b>TASK 1</b> and there are no changes being made to it, hence there is no need to write the code for the model again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyAY5887OfoK",
        "outputId": "7d677c36-66f3-4c9e-9076-52be4895b660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=100)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 3523.8464 - val_loss: 2523.9502\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2244.8218 - val_loss: 1982.6268\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1717.9491 - val_loss: 1514.8070\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1334.4321 - val_loss: 1177.9709\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1036.6959 - val_loss: 897.7751\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 785.2277 - val_loss: 666.4526\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 575.2328 - val_loss: 504.6454\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 467.5401 - val_loss: 430.5016\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 414.9745 - val_loss: 385.4572\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 377.1884 - val_loss: 355.4574\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 350.4542 - val_loss: 335.3923\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 329.8420 - val_loss: 319.4032\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 313.2809 - val_loss: 305.8056\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 298.4805 - val_loss: 295.1317\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 286.5664 - val_loss: 285.2083\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 275.7111 - val_loss: 276.5677\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 265.6501 - val_loss: 268.7268\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.0375 - val_loss: 261.8654\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.9760 - val_loss: 256.1943\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.1655 - val_loss: 251.2870\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 232.3290 - val_loss: 245.4549\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 225.4236 - val_loss: 240.9079\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.8394 - val_loss: 236.2851\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 214.7328 - val_loss: 231.9736\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.9416 - val_loss: 227.7645\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 200.7907 - val_loss: 222.9844\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.8424 - val_loss: 219.4135\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.7807 - val_loss: 215.2831\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.3936 - val_loss: 211.3747\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180.2518 - val_loss: 208.0257\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 175.5780 - val_loss: 203.9835\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.0605 - val_loss: 200.5851\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 167.0461 - val_loss: 197.1994\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.5016 - val_loss: 193.5419\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 160.3707 - val_loss: 190.5311\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 156.9587 - val_loss: 187.2339\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.3062 - val_loss: 184.9567\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.5139 - val_loss: 182.9503\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.0142 - val_loss: 179.9253\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 145.3868 - val_loss: 177.6989\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 143.3027 - val_loss: 176.7933\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 140.7842 - val_loss: 173.7669\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 138.6830 - val_loss: 171.1641\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.9233 - val_loss: 168.5423\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 134.6339 - val_loss: 166.7574\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 132.9319 - val_loss: 164.8989\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.2804 - val_loss: 163.1687\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.5781 - val_loss: 161.6507\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.4868 - val_loss: 159.9058\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.9363 - val_loss: 158.0796\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 125.6102 - val_loss: 156.5458\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 124.8645 - val_loss: 155.7825\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 123.6401 - val_loss: 154.1012\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 124.6648 - val_loss: 152.7699\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 121.6434 - val_loss: 151.3271\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 120.2550 - val_loss: 150.6171\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 119.6386 - val_loss: 148.9774\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 118.3178 - val_loss: 147.9996\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 118.2407 - val_loss: 147.2696\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 116.6108 - val_loss: 146.0660\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.5509 - val_loss: 146.6580\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 116.3519 - val_loss: 144.2488\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.2346 - val_loss: 143.5886\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.1947 - val_loss: 142.3532\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.1147 - val_loss: 143.4230\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.9060 - val_loss: 140.5238\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 111.1834 - val_loss: 140.1754\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 111.3089 - val_loss: 138.8258\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 110.8300 - val_loss: 138.2429\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 109.8126 - val_loss: 137.8259\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 108.6442 - val_loss: 136.8749\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 108.6148 - val_loss: 136.2754\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 108.1549 - val_loss: 135.4558\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.0176 - val_loss: 135.2148\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.7231 - val_loss: 134.4706\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.5365 - val_loss: 134.0748\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.4199 - val_loss: 132.8075\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 107.2530 - val_loss: 134.9001\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 106.8294 - val_loss: 131.8513\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.3187 - val_loss: 132.7245\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 105.6911 - val_loss: 131.3114\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.3228 - val_loss: 130.7305\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.5099 - val_loss: 131.8496\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.8973 - val_loss: 129.3072\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 103.2786 - val_loss: 128.9645\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.5655 - val_loss: 128.9063\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.6182 - val_loss: 128.0385\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 101.7233 - val_loss: 127.4614\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.3989 - val_loss: 127.4840\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.5779 - val_loss: 127.5625\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 100.5357 - val_loss: 126.6608\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 100.8228 - val_loss: 125.8856\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.5080 - val_loss: 125.4539\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.1312 - val_loss: 124.8374\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.5824 - val_loss: 124.0499\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 106.0207 - val_loss: 130.0335\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.7951 - val_loss: 124.4959\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.0598 - val_loss: 122.6647\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.8789 - val_loss: 122.3646\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 99.3500 - val_loss: 123.2351\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4076f1fb10>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N_KEbf_OfoK"
      },
      "source": [
        "### <font color = #2980B9> Step 5 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdgLPptXOfoK"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEa7jV7HOfoK"
      },
      "source": [
        "### <font color = #2980B9> Step 6 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV-4SDWsOfoK",
        "outputId": "7b625643-d92d-4a5b-ab16-16738c4bd32a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the mean square error\n",
        "\n",
        "mse = calculate_mse()\n",
        "print('Mean Square Error (MSE) of the Baseline Model with Normalized Features is : ' , str(mse))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model with Normalized Features is :  105.83093867737546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4ERqotxOfoL"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6J-qPlTOfoL"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OdKAh0kOfoL"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors with new Features</font>\n",
        "\n",
        "In order to train 50 models with new features (normalized features) and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE) the following steps are performed :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MTJ0razOfoL"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDxTv-hTOfoL"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u69OWhNOfoL"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkay9ClwOfoL",
        "outputId": "5fcf8a03-4891-48fe-827f-f6de369ce866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=100)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = model.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = mean_squared_error(Y_test, Y_predicted)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.4537 - val_loss: 64.0925\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 71.1367 - val_loss: 66.4960\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 13086.3467 - val_loss: 4394.8179\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2279.9468 - val_loss: 1153.5604\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1496.7034 - val_loss: 1177.4883\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1232.7512 - val_loss: 974.4769\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1109.5674 - val_loss: 911.9124\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1004.3395 - val_loss: 849.0526\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 905.7426 - val_loss: 778.8432\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 810.8528 - val_loss: 703.8000\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 710.9915 - val_loss: 623.6385\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 625.7703 - val_loss: 549.0251\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 559.7558 - val_loss: 504.7087\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 506.3023 - val_loss: 462.6843\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 470.6000 - val_loss: 440.3155\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 440.1778 - val_loss: 417.5415\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 416.1038 - val_loss: 400.6041\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.8366 - val_loss: 379.7374\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 372.1946 - val_loss: 362.8657\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.7914 - val_loss: 349.9886\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 339.3932 - val_loss: 336.0493\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.9174 - val_loss: 323.2934\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 311.1457 - val_loss: 316.3550\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 299.3568 - val_loss: 304.1339\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.5108 - val_loss: 294.1953\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.9223 - val_loss: 291.7212\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.2519 - val_loss: 284.1827\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.3538 - val_loss: 275.6105\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.1565 - val_loss: 272.3722\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.2885 - val_loss: 264.9398\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.2027 - val_loss: 261.7654\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.7607 - val_loss: 257.1955\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 232.1188 - val_loss: 252.4198\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.0972 - val_loss: 245.9699\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.8465 - val_loss: 245.6311\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.5529 - val_loss: 235.0213\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219.9154 - val_loss: 242.3845\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 216.8183 - val_loss: 243.3828\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.1924 - val_loss: 226.3527\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.4778 - val_loss: 235.5068\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 203.1712 - val_loss: 223.3133\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 201.4381 - val_loss: 221.2560\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.5095 - val_loss: 224.8694\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.4933 - val_loss: 218.5505\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197.7758 - val_loss: 220.8164\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192.7856 - val_loss: 211.8701\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.9293 - val_loss: 207.7847\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.4567 - val_loss: 211.9929\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.6902 - val_loss: 201.1220\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.6946 - val_loss: 213.7695\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.3967 - val_loss: 199.0748\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.5367 - val_loss: 197.1500\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.6702 - val_loss: 203.5935\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.1038 - val_loss: 192.3987\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.2016 - val_loss: 201.9572\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.5317 - val_loss: 188.5113\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.3866 - val_loss: 196.4060\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.2987 - val_loss: 185.2787\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.6011 - val_loss: 192.2162\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.4922 - val_loss: 188.1139\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.4694 - val_loss: 182.6511\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.4816 - val_loss: 189.9097\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.6638 - val_loss: 186.4199\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.0056 - val_loss: 177.3059\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.0456 - val_loss: 174.1736\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.0952 - val_loss: 179.2932\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4055 - val_loss: 177.5431\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.8734 - val_loss: 178.6264\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.9632 - val_loss: 170.3841\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.2524 - val_loss: 176.2985\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.9939 - val_loss: 166.5652\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.6023 - val_loss: 168.8161\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.0458 - val_loss: 175.9120\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.8481 - val_loss: 163.5640\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.1505 - val_loss: 170.6505\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.7350 - val_loss: 163.2578\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.6292 - val_loss: 168.7298\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.1596 - val_loss: 161.2177\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.1329 - val_loss: 166.7076\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.3711 - val_loss: 158.5443\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.8976 - val_loss: 175.0688\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.3733 - val_loss: 155.2153\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.8239 - val_loss: 162.5739\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.9695 - val_loss: 159.1251\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4600 - val_loss: 153.6687\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.8232 - val_loss: 156.3083\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.2058 - val_loss: 163.2354\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.8785 - val_loss: 156.8876\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.0040 - val_loss: 155.6280\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.5345 - val_loss: 149.1743\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.7074 - val_loss: 149.2271\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.9066 - val_loss: 159.5305\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.6193 - val_loss: 154.6544\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.2103 - val_loss: 149.2891\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.3224 - val_loss: 149.7153\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.2155 - val_loss: 163.1727\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.0630 - val_loss: 148.7183\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.3213 - val_loss: 151.1997\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.3064 - val_loss: 150.0143\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.8501 - val_loss: 159.8762\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.0449 - val_loss: 140.7812\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.9238 - val_loss: 140.8456\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 12071.6377 - val_loss: 2942.1763\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2366.5193 - val_loss: 2530.9541\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2029.2542 - val_loss: 1710.1178\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1430.0305 - val_loss: 1258.9370\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1077.9465 - val_loss: 935.9958\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 809.4830 - val_loss: 759.3313\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 649.9477 - val_loss: 646.5228\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 561.4393 - val_loss: 571.3707\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 498.8673 - val_loss: 511.4281\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 448.7363 - val_loss: 456.3908\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 400.3310 - val_loss: 411.8194\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.0242 - val_loss: 364.1288\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.8749 - val_loss: 326.8171\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.4766 - val_loss: 305.6950\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 267.1768 - val_loss: 263.0351\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.5806 - val_loss: 238.3467\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.6400 - val_loss: 221.1719\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.9980 - val_loss: 196.7380\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.1346 - val_loss: 178.7025\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.3183 - val_loss: 164.6220\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.0421 - val_loss: 153.4686\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.1433 - val_loss: 153.7558\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.7412 - val_loss: 139.3240\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.7885 - val_loss: 132.0901\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.1173 - val_loss: 127.3637\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.7620 - val_loss: 126.7425\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.6330 - val_loss: 121.8361\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.7468 - val_loss: 119.5615\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.1284 - val_loss: 119.2992\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.4402 - val_loss: 116.5360\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4986 - val_loss: 116.1887\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4859 - val_loss: 115.0753\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.8052 - val_loss: 115.1883\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4719 - val_loss: 124.8606\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.8840 - val_loss: 113.8101\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.0236 - val_loss: 112.9769\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.7661 - val_loss: 114.8415\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6111 - val_loss: 112.3068\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8054 - val_loss: 112.2349\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.5084 - val_loss: 113.5719\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.3795 - val_loss: 114.3928\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.1952 - val_loss: 111.4271\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.2472 - val_loss: 111.3609\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.7676 - val_loss: 112.8360\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.9888 - val_loss: 110.4106\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.8963 - val_loss: 110.9024\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.8671 - val_loss: 110.9603\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.7477 - val_loss: 116.6782\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.9866 - val_loss: 149.6799\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.7175 - val_loss: 120.5841\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.9336 - val_loss: 110.0398\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8647 - val_loss: 117.3649\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.0145 - val_loss: 110.5063\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.3286 - val_loss: 110.2723\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0402 - val_loss: 108.6935\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.6358 - val_loss: 113.1019\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8985 - val_loss: 110.1901\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2609 - val_loss: 108.0623\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.6392 - val_loss: 108.5269\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.9659 - val_loss: 111.1874\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8509 - val_loss: 109.0490\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.1241 - val_loss: 109.7407\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5917 - val_loss: 108.4142\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.8156 - val_loss: 110.0319\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.6564 - val_loss: 117.7875\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.2858 - val_loss: 114.2483\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.1491 - val_loss: 112.7799\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5674 - val_loss: 107.5260\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.9560 - val_loss: 107.8595\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.1637 - val_loss: 107.0321\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4016 - val_loss: 106.7457\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.7057 - val_loss: 106.5567\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7086 - val_loss: 106.9391\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.8521 - val_loss: 107.2723\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.2814 - val_loss: 109.7510\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.0611 - val_loss: 106.2065\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5668 - val_loss: 107.8459\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.8852 - val_loss: 108.2476\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8617 - val_loss: 106.0550\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.9858 - val_loss: 107.0010\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.5382 - val_loss: 106.2054\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.1692 - val_loss: 107.2181\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.9559 - val_loss: 105.8135\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5606 - val_loss: 108.0684\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 104.7042 - val_loss: 105.3073\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.3166 - val_loss: 105.4578\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.0776 - val_loss: 105.5526\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5136 - val_loss: 105.4109\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3777 - val_loss: 108.9098\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.2896 - val_loss: 110.4177\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0641 - val_loss: 105.1819\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5471 - val_loss: 110.9915\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.7872 - val_loss: 105.6443\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.2857 - val_loss: 105.9189\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5307 - val_loss: 106.8651\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5610 - val_loss: 115.2089\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.4967 - val_loss: 111.1934\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9138 - val_loss: 115.9040\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.3560 - val_loss: 105.4757\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.2238 - val_loss: 108.7454\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 1098.3329 - val_loss: 831.2775\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 729.6346 - val_loss: 605.3633\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 553.8898 - val_loss: 491.7133\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 440.6335 - val_loss: 400.2453\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.3225 - val_loss: 345.7705\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 320.3581 - val_loss: 316.9982\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.2591 - val_loss: 283.6576\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.8174 - val_loss: 282.7070\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.2638 - val_loss: 254.8520\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.2871 - val_loss: 240.0881\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.0031 - val_loss: 233.2668\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.2968 - val_loss: 220.6287\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.9538 - val_loss: 215.4104\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 190.3512 - val_loss: 207.9104\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.1526 - val_loss: 199.7483\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 178.5867 - val_loss: 194.7828\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.5962 - val_loss: 193.0288\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.8425 - val_loss: 185.6559\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.6045 - val_loss: 182.1789\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.2868 - val_loss: 183.7067\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.1677 - val_loss: 176.3024\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.6989 - val_loss: 173.8518\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.6874 - val_loss: 171.5182\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.0798 - val_loss: 169.1433\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5956 - val_loss: 167.6783\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.8139 - val_loss: 163.3023\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.4112 - val_loss: 164.9657\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4285 - val_loss: 159.4813\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.2414 - val_loss: 154.9053\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.8420 - val_loss: 158.0087\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.6439 - val_loss: 157.0941\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.9704 - val_loss: 149.6026\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.5936 - val_loss: 157.4787\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.7122 - val_loss: 163.7416\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.9492 - val_loss: 147.7648\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6322 - val_loss: 149.1856\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.4484 - val_loss: 141.8418\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.1852 - val_loss: 141.7412\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.6682 - val_loss: 141.9602\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.4467 - val_loss: 141.3354\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.1466 - val_loss: 137.6042\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.3362 - val_loss: 134.5461\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.9140 - val_loss: 132.6611\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.0652 - val_loss: 131.1693\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.9049 - val_loss: 129.5611\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.9382 - val_loss: 136.9598\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.9015 - val_loss: 126.6175\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.5635 - val_loss: 125.4229\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.6841 - val_loss: 123.2926\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1644 - val_loss: 121.7228\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4397 - val_loss: 120.8525\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.2551 - val_loss: 118.9978\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1021 - val_loss: 118.3003\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.2192 - val_loss: 117.4600\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6111 - val_loss: 116.3927\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1972 - val_loss: 114.3938\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.6452 - val_loss: 112.7565\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8976 - val_loss: 114.7112\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.3385 - val_loss: 110.6401\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.2726 - val_loss: 111.2067\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.2771 - val_loss: 109.4144\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.4689 - val_loss: 113.1984\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.6445 - val_loss: 109.0535\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.7736 - val_loss: 108.8965\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.6914 - val_loss: 110.7417\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.9632 - val_loss: 106.3164\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.3318 - val_loss: 106.8330\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.5101 - val_loss: 105.6837\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.0863 - val_loss: 106.7739\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.0995 - val_loss: 106.4179\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.6327 - val_loss: 103.1211\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.9839 - val_loss: 105.3425\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.4148 - val_loss: 109.4471\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.4266 - val_loss: 106.7955\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.8851 - val_loss: 101.0232\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.2839 - val_loss: 102.9493\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.2543 - val_loss: 113.8322\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.6195 - val_loss: 107.6614\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.3951 - val_loss: 99.9386\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.3246 - val_loss: 100.8875\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.1742 - val_loss: 98.0305\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.1774 - val_loss: 107.8822\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.0100 - val_loss: 110.5896\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.8454 - val_loss: 99.7411\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.3622 - val_loss: 101.8478\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.3200 - val_loss: 96.6605\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.0173 - val_loss: 103.7592\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.8256 - val_loss: 95.9553\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.0983 - val_loss: 93.3844\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.1134 - val_loss: 99.5537\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.2559 - val_loss: 105.2236\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.5405 - val_loss: 92.3716\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.5081 - val_loss: 96.4107\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.6707 - val_loss: 94.1843\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.6675 - val_loss: 91.4620\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.3006 - val_loss: 95.8694\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.6389 - val_loss: 88.3874\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.3700 - val_loss: 87.3382\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81.5312 - val_loss: 99.4665\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.9154 - val_loss: 86.6740\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 7840.3701 - val_loss: 1240.5475\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1620.5634 - val_loss: 1466.4336\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1178.3501 - val_loss: 753.3790\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 759.1606 - val_loss: 568.2737\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 630.8184 - val_loss: 493.6991\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 547.7442 - val_loss: 427.0663\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 474.3643 - val_loss: 373.5071\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 411.4539 - val_loss: 326.0889\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.5094 - val_loss: 290.8838\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.5848 - val_loss: 249.2183\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.2949 - val_loss: 221.9346\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.6936 - val_loss: 195.9388\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.9772 - val_loss: 177.5331\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.8293 - val_loss: 163.1254\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.6629 - val_loss: 149.8789\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.2693 - val_loss: 138.1394\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.1080 - val_loss: 132.8443\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.6968 - val_loss: 127.1543\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.4677 - val_loss: 121.6273\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.8510 - val_loss: 118.5256\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.2803 - val_loss: 117.7634\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.2737 - val_loss: 117.4876\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.9356 - val_loss: 113.7433\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.8932 - val_loss: 115.1130\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.5022 - val_loss: 113.8181\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.9280 - val_loss: 111.7977\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.9735 - val_loss: 111.6513\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.7816 - val_loss: 111.2986\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.5560 - val_loss: 110.9611\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7416 - val_loss: 109.8682\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.9745 - val_loss: 111.4948\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.1097 - val_loss: 108.0967\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.3680 - val_loss: 107.0232\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.7239 - val_loss: 106.3594\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.3427 - val_loss: 108.6005\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.3158 - val_loss: 106.9691\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.3706 - val_loss: 104.7857\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.4455 - val_loss: 104.5200\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.8794 - val_loss: 109.3101\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.4233 - val_loss: 105.6705\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.0344 - val_loss: 103.6792\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3559 - val_loss: 104.3818\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.4212 - val_loss: 103.0583\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.6032 - val_loss: 101.8146\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3359 - val_loss: 104.3493\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.0173 - val_loss: 103.3550\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.0333 - val_loss: 101.4038\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1512 - val_loss: 100.0971\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4791 - val_loss: 101.5436\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.2717 - val_loss: 100.0451\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0809 - val_loss: 102.4726\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.2409 - val_loss: 101.3213\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.6404 - val_loss: 99.8093\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.8400 - val_loss: 100.5254\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.2302 - val_loss: 97.8239\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.8060 - val_loss: 106.6197\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.0360 - val_loss: 99.7314\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.2806 - val_loss: 105.9020\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.3019 - val_loss: 96.9008\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.2494 - val_loss: 96.8745\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.6011 - val_loss: 101.9963\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.3858 - val_loss: 97.2372\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.2329 - val_loss: 95.5252\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.1161 - val_loss: 103.8082\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.4815 - val_loss: 96.9929\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.8070 - val_loss: 96.5410\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.1416 - val_loss: 94.2666\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.8866 - val_loss: 97.6417\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.9706 - val_loss: 96.9531\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.4677 - val_loss: 94.8742\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.2795 - val_loss: 92.9688\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.5584 - val_loss: 93.5311\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.4706 - val_loss: 92.6801\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.6840 - val_loss: 96.7178\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.5627 - val_loss: 97.2682\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.8091 - val_loss: 92.2230\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.1213 - val_loss: 95.6067\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.6539 - val_loss: 97.9064\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.1957 - val_loss: 91.9542\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.1484 - val_loss: 94.9341\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3148 - val_loss: 92.8675\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.8539 - val_loss: 93.7576\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.4107 - val_loss: 91.5623\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.2606 - val_loss: 98.1573\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.9199 - val_loss: 90.1982\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.7088 - val_loss: 99.7370\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6883 - val_loss: 96.9924\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.8173 - val_loss: 98.8135\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.6542 - val_loss: 94.6126\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.8582 - val_loss: 91.3987\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.4935 - val_loss: 90.0403\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.2258 - val_loss: 88.0151\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.8963 - val_loss: 89.6776\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.2653 - val_loss: 88.7480\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.0706 - val_loss: 91.4621\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.8788 - val_loss: 87.2768\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.7580 - val_loss: 94.0114\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.9972 - val_loss: 105.6899\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.3916 - val_loss: 88.1903\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.7349 - val_loss: 88.0568\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 604.7327 - val_loss: 477.1991\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 387.5676 - val_loss: 332.1061\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.5724 - val_loss: 256.0669\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.5925 - val_loss: 209.0622\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.8447 - val_loss: 182.4486\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.5418 - val_loss: 167.4794\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.3907 - val_loss: 149.9200\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.5869 - val_loss: 131.3660\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.7724 - val_loss: 118.7108\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.9982 - val_loss: 114.9685\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.7670 - val_loss: 108.9341\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.5925 - val_loss: 105.4839\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.6392 - val_loss: 103.0021\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.1875 - val_loss: 100.6572\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.7964 - val_loss: 100.2928\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.9228 - val_loss: 96.8270\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.7175 - val_loss: 94.0184\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.2171 - val_loss: 96.3495\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.2703 - val_loss: 91.9857\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.4030 - val_loss: 92.3240\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.6626 - val_loss: 88.9979\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.6504 - val_loss: 87.9797\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.6774 - val_loss: 85.9720\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.3342 - val_loss: 85.5887\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.0560 - val_loss: 85.6041\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.0478 - val_loss: 83.3507\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.5755 - val_loss: 83.2613\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.1472 - val_loss: 85.6805\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.2937 - val_loss: 84.9434\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.3645 - val_loss: 80.8165\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.3225 - val_loss: 80.9185\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 83.0276 - val_loss: 90.9678\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.2281 - val_loss: 79.8737\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.5686 - val_loss: 81.0966\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.0819 - val_loss: 79.0775\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.9334 - val_loss: 79.3851\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.4725 - val_loss: 76.2010\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.1320 - val_loss: 77.4386\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76.5029 - val_loss: 76.6580\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 75.3067 - val_loss: 79.8953\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.9852 - val_loss: 76.9270\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.7745 - val_loss: 75.3846\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.6033 - val_loss: 75.9297\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 73.0017 - val_loss: 74.4799\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.9169 - val_loss: 75.2813\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 77.5518 - val_loss: 73.4826\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.2163 - val_loss: 74.1343\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.4019 - val_loss: 73.8766\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.0322 - val_loss: 72.9496\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.0385 - val_loss: 73.0959\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 70.7582 - val_loss: 72.5111\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.5406 - val_loss: 72.1377\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.1834 - val_loss: 76.4291\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.1503 - val_loss: 72.3140\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.4139 - val_loss: 74.1423\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.3595 - val_loss: 71.9314\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 69.1820 - val_loss: 71.5786\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.0266 - val_loss: 72.5714\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.5384 - val_loss: 72.2353\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.2353 - val_loss: 71.3516\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.0454 - val_loss: 70.7883\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.4266 - val_loss: 71.8591\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.6909 - val_loss: 70.0858\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.4051 - val_loss: 71.3681\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.5659 - val_loss: 70.1647\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.0841 - val_loss: 69.7429\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.2076 - val_loss: 73.3057\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.9971 - val_loss: 71.4934\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.8321 - val_loss: 68.7403\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.2122 - val_loss: 68.0516\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.0175 - val_loss: 72.1687\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 67.3947 - val_loss: 68.7288\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.4543 - val_loss: 67.8025\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65.6148 - val_loss: 67.0948\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.8436 - val_loss: 66.9158\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.3417 - val_loss: 68.5940\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.6389 - val_loss: 74.7482\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.9580 - val_loss: 66.4860\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.8031 - val_loss: 66.1025\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63.3823 - val_loss: 66.1211\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.9907 - val_loss: 65.8750\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.8783 - val_loss: 69.9251\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.3836 - val_loss: 65.7470\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.0435 - val_loss: 65.5369\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.7095 - val_loss: 66.5233\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63.1474 - val_loss: 69.0433\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.0504 - val_loss: 67.3352\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 65.2438 - val_loss: 66.2964\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.4710 - val_loss: 65.4789\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 62.1998 - val_loss: 65.6879\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 63.0761 - val_loss: 63.8571\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 61.4483 - val_loss: 64.2867\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 61.6438 - val_loss: 68.5806\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63.7351 - val_loss: 67.3793\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.0163 - val_loss: 65.2141\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61.4277 - val_loss: 64.0035\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 60.6863 - val_loss: 63.6559\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61.3841 - val_loss: 67.3554\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61.9277 - val_loss: 65.7837\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61.1618 - val_loss: 67.3604\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 187155.0156 - val_loss: 128280.3281\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98102.5078 - val_loss: 62376.5352\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 46227.3164 - val_loss: 27265.4609\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 19500.0918 - val_loss: 10539.9727\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7547.6211 - val_loss: 3832.7690\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3075.3994 - val_loss: 1923.7982\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1857.2914 - val_loss: 1502.1736\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1559.2278 - val_loss: 1375.0623\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1427.0922 - val_loss: 1284.1978\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1339.5726 - val_loss: 1209.2621\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1258.6937 - val_loss: 1136.4048\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1186.8976 - val_loss: 1066.6755\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1111.3623 - val_loss: 1007.9371\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1052.3649 - val_loss: 948.2371\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 996.0678 - val_loss: 897.3445\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 945.1295 - val_loss: 854.9959\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 899.1940 - val_loss: 815.3815\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 859.1080 - val_loss: 778.1930\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 820.3013 - val_loss: 746.5449\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 788.1898 - val_loss: 719.3712\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 754.8016 - val_loss: 684.3699\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 722.9957 - val_loss: 659.2267\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 694.6417 - val_loss: 639.7749\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 669.6426 - val_loss: 618.0656\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 645.2095 - val_loss: 599.2361\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 620.6549 - val_loss: 577.0468\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 597.3413 - val_loss: 556.8387\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 570.9312 - val_loss: 532.5881\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 530.8514 - val_loss: 478.8641\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 446.1028 - val_loss: 376.4583\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 344.9185 - val_loss: 271.2204\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.2948 - val_loss: 244.4805\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.8034 - val_loss: 229.1176\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.2641 - val_loss: 212.7583\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.7802 - val_loss: 204.6797\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.5260 - val_loss: 192.8761\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.6952 - val_loss: 186.2727\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.6169 - val_loss: 177.9445\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.9960 - val_loss: 172.5646\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.5262 - val_loss: 170.0016\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.9196 - val_loss: 163.3978\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.4887 - val_loss: 161.0372\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.8761 - val_loss: 154.6277\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4954 - val_loss: 153.3733\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.4345 - val_loss: 146.2025\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.9088 - val_loss: 144.4177\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.7767 - val_loss: 139.8931\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.1846 - val_loss: 142.1881\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4034 - val_loss: 137.0838\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.4400 - val_loss: 133.2675\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.3604 - val_loss: 134.2556\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.1928 - val_loss: 126.6580\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.7453 - val_loss: 132.6460\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.2204 - val_loss: 123.2701\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.9097 - val_loss: 122.5544\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.4517 - val_loss: 126.3879\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.7268 - val_loss: 124.3947\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.6857 - val_loss: 118.2358\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.1418 - val_loss: 118.0154\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.8102 - val_loss: 116.5615\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3861 - val_loss: 120.9409\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.7736 - val_loss: 112.6978\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6864 - val_loss: 113.4954\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.0063 - val_loss: 114.3937\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.1627 - val_loss: 110.8528\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.8843 - val_loss: 109.6066\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.8188 - val_loss: 110.1250\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.9012 - val_loss: 110.5035\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.7635 - val_loss: 107.4656\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7080 - val_loss: 113.1752\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2611 - val_loss: 105.7495\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.1269 - val_loss: 105.7669\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.6181 - val_loss: 109.5766\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.4982 - val_loss: 104.3575\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.6929 - val_loss: 104.5635\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1997 - val_loss: 107.3665\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.0824 - val_loss: 109.9557\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.1979 - val_loss: 103.1133\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.3697 - val_loss: 102.1381\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.8678 - val_loss: 107.6584\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9716 - val_loss: 105.5767\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.6061 - val_loss: 102.1762\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.4737 - val_loss: 101.4554\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.3833 - val_loss: 113.0487\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.7536 - val_loss: 104.7031\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7980 - val_loss: 104.1291\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.2980 - val_loss: 100.5938\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.5086 - val_loss: 103.3791\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.3379 - val_loss: 100.3536\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1652 - val_loss: 100.6837\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.1899 - val_loss: 106.8072\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1024 - val_loss: 99.2568\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.7081 - val_loss: 100.1014\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.8999 - val_loss: 99.3913\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.2440 - val_loss: 99.4801\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6290 - val_loss: 99.6301\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.6657 - val_loss: 104.2451\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.9305 - val_loss: 100.1427\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.0922 - val_loss: 100.7753\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.9193 - val_loss: 100.3587\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 36310.7305 - val_loss: 19826.0820\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13243.0615 - val_loss: 7164.0005\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5450.9404 - val_loss: 3474.0083\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2968.9092 - val_loss: 2185.8528\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2004.5868 - val_loss: 1547.4926\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1445.2555 - val_loss: 1132.6060\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1073.4259 - val_loss: 840.3323\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 811.0326 - val_loss: 636.6934\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 632.3007 - val_loss: 496.4310\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 509.2276 - val_loss: 405.1978\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 432.3902 - val_loss: 344.6548\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 380.9262 - val_loss: 308.4832\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 349.7556 - val_loss: 286.5438\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 331.6054 - val_loss: 272.5749\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.6925 - val_loss: 264.7167\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 312.4325 - val_loss: 259.8348\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 308.2492 - val_loss: 255.5162\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 303.9154 - val_loss: 252.5999\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 300.9373 - val_loss: 249.9042\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.8722 - val_loss: 247.4257\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.9958 - val_loss: 245.0643\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.2455 - val_loss: 242.4425\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.5663 - val_loss: 239.6521\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.9135 - val_loss: 236.9082\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.6388 - val_loss: 234.2445\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.9577 - val_loss: 231.3810\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.4614 - val_loss: 227.1017\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.0783 - val_loss: 223.8736\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.1847 - val_loss: 219.5661\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.8653 - val_loss: 215.8855\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.1160 - val_loss: 212.5909\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.1692 - val_loss: 209.0445\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.6905 - val_loss: 205.9417\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 240.6958 - val_loss: 202.6406\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.7971 - val_loss: 199.6549\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 231.2470 - val_loss: 196.0101\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.5044 - val_loss: 192.9304\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.4563 - val_loss: 190.2497\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.9136 - val_loss: 186.5290\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.7333 - val_loss: 183.8614\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.1979 - val_loss: 180.5050\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.3160 - val_loss: 176.9987\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.9485 - val_loss: 173.9671\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.3031 - val_loss: 170.5848\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.8735 - val_loss: 167.0979\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.4594 - val_loss: 163.5855\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.2668 - val_loss: 160.0180\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.0968 - val_loss: 156.7847\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.1284 - val_loss: 153.0337\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.6311 - val_loss: 149.0944\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.4484 - val_loss: 145.8317\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9097 - val_loss: 141.7410\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.6746 - val_loss: 137.8813\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.3978 - val_loss: 133.2588\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.5008 - val_loss: 129.2579\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3376 - val_loss: 125.8123\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.7063 - val_loss: 122.9221\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.9815 - val_loss: 119.7321\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.0270 - val_loss: 117.1772\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.3623 - val_loss: 115.3139\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.5392 - val_loss: 113.7158\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.9861 - val_loss: 111.1849\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7224 - val_loss: 109.2682\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4297 - val_loss: 107.5039\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6472 - val_loss: 105.8011\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 111.6342 - val_loss: 105.9168\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.4132 - val_loss: 103.6203\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6071 - val_loss: 101.9668\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0111 - val_loss: 101.2696\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.3065 - val_loss: 100.1574\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.9180 - val_loss: 99.7560\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.8853 - val_loss: 99.5279\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.4131 - val_loss: 98.3586\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.9799 - val_loss: 97.9522\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.8018 - val_loss: 96.8699\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.4507 - val_loss: 97.1732\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.1753 - val_loss: 96.3136\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.6451 - val_loss: 97.5506\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.1662 - val_loss: 98.1417\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3844 - val_loss: 95.0379\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.8668 - val_loss: 94.2781\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.4520 - val_loss: 94.1801\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.5707 - val_loss: 94.4557\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.8683 - val_loss: 93.3918\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.2557 - val_loss: 93.4436\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.5994 - val_loss: 92.5375\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.5676 - val_loss: 95.1626\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.1214 - val_loss: 92.3683\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.3279 - val_loss: 92.2823\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.6946 - val_loss: 91.3651\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.9798 - val_loss: 92.8486\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.1506 - val_loss: 93.9133\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.8768 - val_loss: 91.4583\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.1702 - val_loss: 91.6558\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.4716 - val_loss: 90.7084\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.8864 - val_loss: 91.4990\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.2641 - val_loss: 90.6154\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.3919 - val_loss: 89.9515\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.9711 - val_loss: 89.9719\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.4180 - val_loss: 91.5672\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 11790.8271 - val_loss: 2964.6458\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1135.4620 - val_loss: 644.7567\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 869.4899 - val_loss: 636.2328\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 666.6138 - val_loss: 543.4896\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 609.2079 - val_loss: 529.7007\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 585.7983 - val_loss: 501.1715\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 561.8211 - val_loss: 486.1779\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 541.9679 - val_loss: 473.3031\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 521.6793 - val_loss: 452.7007\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 500.8588 - val_loss: 439.9032\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 482.6628 - val_loss: 425.3488\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 465.7531 - val_loss: 412.1970\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 446.3435 - val_loss: 397.1387\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 431.0549 - val_loss: 385.5535\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 413.0859 - val_loss: 372.5764\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 399.3951 - val_loss: 362.2820\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 385.5706 - val_loss: 352.2087\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 369.9820 - val_loss: 341.2678\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.2421 - val_loss: 331.3720\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 345.9076 - val_loss: 320.9196\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.9581 - val_loss: 312.3920\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 321.0889 - val_loss: 304.5580\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 309.3377 - val_loss: 298.5480\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 302.4214 - val_loss: 289.8741\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.7868 - val_loss: 285.5063\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 279.8210 - val_loss: 276.9306\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.6974 - val_loss: 270.7856\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.4496 - val_loss: 265.0118\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.1279 - val_loss: 261.0307\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.9873 - val_loss: 255.2333\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.8643 - val_loss: 251.0710\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.6201 - val_loss: 246.0319\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.6868 - val_loss: 241.4246\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.1303 - val_loss: 237.0055\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.4964 - val_loss: 232.7104\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.2207 - val_loss: 228.9451\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.5407 - val_loss: 226.0636\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.1407 - val_loss: 221.8826\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.9053 - val_loss: 218.4971\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.0870 - val_loss: 215.4703\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.3349 - val_loss: 211.8457\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.2263 - val_loss: 208.1400\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.2408 - val_loss: 205.4415\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.3585 - val_loss: 203.6308\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.3996 - val_loss: 206.0590\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.7300 - val_loss: 200.0663\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.7442 - val_loss: 195.6751\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.4162 - val_loss: 191.1559\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.2509 - val_loss: 189.3577\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0800 - val_loss: 186.6927\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.4236 - val_loss: 183.3642\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.7790 - val_loss: 182.4307\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.4387 - val_loss: 179.8914\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.7874 - val_loss: 177.9561\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.0622 - val_loss: 175.3096\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.2541 - val_loss: 172.6199\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.8708 - val_loss: 170.4301\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.4935 - val_loss: 168.6721\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.9916 - val_loss: 167.2294\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.8878 - val_loss: 166.6065\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.5197 - val_loss: 163.6715\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 145.5553 - val_loss: 161.2256\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4061 - val_loss: 159.6652\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.0784 - val_loss: 160.0355\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.9357 - val_loss: 158.4387\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9979 - val_loss: 162.8375\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.9972 - val_loss: 156.0197\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4045 - val_loss: 152.6480\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.6106 - val_loss: 162.4936\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9877 - val_loss: 149.4378\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.0378 - val_loss: 149.1398\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6035 - val_loss: 147.0064\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.0482 - val_loss: 146.0995\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.3396 - val_loss: 145.5586\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.1188 - val_loss: 148.5789\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.1613 - val_loss: 145.7370\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.0603 - val_loss: 143.2046\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.2056 - val_loss: 140.5309\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.1286 - val_loss: 145.7740\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.2885 - val_loss: 140.4569\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0346 - val_loss: 137.7287\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.9024 - val_loss: 137.1485\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6081 - val_loss: 137.5645\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.6656 - val_loss: 145.8840\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.4076 - val_loss: 136.4608\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.2388 - val_loss: 132.8571\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.4253 - val_loss: 132.9695\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.2703 - val_loss: 142.1740\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.9801 - val_loss: 142.8905\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.4499 - val_loss: 131.1243\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.9237 - val_loss: 130.3602\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.2122 - val_loss: 131.2913\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4693 - val_loss: 129.2007\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.0635 - val_loss: 127.9207\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.8161 - val_loss: 129.6238\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3557 - val_loss: 140.3273\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.5175 - val_loss: 134.2469\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.7022 - val_loss: 126.8654\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.1755 - val_loss: 126.3708\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.9567 - val_loss: 128.7269\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 49484.5742 - val_loss: 21464.9375\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11164.0869 - val_loss: 4368.8452\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2985.5188 - val_loss: 2334.9810\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2103.1152 - val_loss: 1829.0178\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1627.6664 - val_loss: 1390.2942\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1399.9802 - val_loss: 1253.7155\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1294.5928 - val_loss: 1163.1877\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1206.2328 - val_loss: 1092.1366\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1140.4119 - val_loss: 1037.5724\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1076.1287 - val_loss: 981.6823\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1018.0720 - val_loss: 933.6785\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 962.0317 - val_loss: 889.0140\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 912.8625 - val_loss: 846.0414\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 867.1860 - val_loss: 800.3995\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 822.3172 - val_loss: 753.7922\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 778.8146 - val_loss: 708.4532\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 733.6495 - val_loss: 666.6437\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 691.9745 - val_loss: 627.4981\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 651.0897 - val_loss: 588.9061\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 611.0906 - val_loss: 553.2220\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 576.8209 - val_loss: 520.3050\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 540.4842 - val_loss: 489.6278\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 508.8215 - val_loss: 464.8594\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 464.2854 - val_loss: 430.0908\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 428.0506 - val_loss: 404.6788\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 400.7442 - val_loss: 377.4767\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.7263 - val_loss: 354.2754\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 339.8492 - val_loss: 330.8505\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.3404 - val_loss: 311.6620\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.1049 - val_loss: 291.0851\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.9466 - val_loss: 272.7506\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.0131 - val_loss: 259.1644\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 242.0958 - val_loss: 243.0841\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.9863 - val_loss: 230.5383\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.6414 - val_loss: 221.8662\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.3080 - val_loss: 211.6244\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.5657 - val_loss: 204.8018\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.2292 - val_loss: 196.9275\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.3507 - val_loss: 193.2882\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.3770 - val_loss: 186.0192\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.2639 - val_loss: 183.0860\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.8984 - val_loss: 178.3073\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.8327 - val_loss: 175.4677\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.1233 - val_loss: 171.4562\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.8065 - val_loss: 169.3470\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.2611 - val_loss: 164.6702\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.2106 - val_loss: 164.7457\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.7692 - val_loss: 159.5331\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4100 - val_loss: 157.1923\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.2544 - val_loss: 156.1029\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.2823 - val_loss: 153.4711\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5725 - val_loss: 153.7165\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.5914 - val_loss: 149.7223\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.4063 - val_loss: 149.0645\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.0733 - val_loss: 146.9789\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.1280 - val_loss: 145.3251\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.7561 - val_loss: 144.3393\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.9660 - val_loss: 142.4660\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.8643 - val_loss: 142.1615\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.5404 - val_loss: 140.2519\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.5028 - val_loss: 138.7679\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.1318 - val_loss: 137.5820\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.4164 - val_loss: 136.4047\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.8151 - val_loss: 135.4314\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.3051 - val_loss: 133.9234\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.7465 - val_loss: 133.1264\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.3895 - val_loss: 133.2865\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.6034 - val_loss: 131.0779\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.1684 - val_loss: 130.0285\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0845 - val_loss: 129.1295\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1766 - val_loss: 129.2040\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.5484 - val_loss: 127.1317\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.2234 - val_loss: 126.2130\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7343 - val_loss: 125.5925\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.8052 - val_loss: 126.8097\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.1484 - val_loss: 124.6109\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.6807 - val_loss: 122.1922\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.3541 - val_loss: 121.2243\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.3001 - val_loss: 120.1518\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.9038 - val_loss: 119.5462\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.7254 - val_loss: 120.0662\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8950 - val_loss: 117.5256\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6316 - val_loss: 116.1392\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.5501 - val_loss: 116.3465\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1156 - val_loss: 115.1807\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4167 - val_loss: 117.3732\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9364 - val_loss: 113.2265\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0610 - val_loss: 111.6128\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.3019 - val_loss: 110.8380\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.4212 - val_loss: 111.1649\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.8701 - val_loss: 110.3865\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 99.5925 - val_loss: 109.0694\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.4996 - val_loss: 108.6277\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.4390 - val_loss: 107.4037\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.5041 - val_loss: 106.3336\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.7044 - val_loss: 112.9981\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.1744 - val_loss: 106.7604\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.2106 - val_loss: 107.4013\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.5422 - val_loss: 105.6355\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.8385 - val_loss: 102.4819\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 201548.8750 - val_loss: 124436.4219\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81678.7188 - val_loss: 40425.6133\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 22288.6270 - val_loss: 7206.8335\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3688.9517 - val_loss: 2744.6714\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2804.4478 - val_loss: 2616.1885\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2295.6655 - val_loss: 2221.6851\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2193.8584 - val_loss: 2089.0850\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2048.2910 - val_loss: 1957.4822\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1919.6719 - val_loss: 1814.3091\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1787.0649 - val_loss: 1673.0002\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1660.8489 - val_loss: 1552.9801\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1547.6968 - val_loss: 1434.9449\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1441.7267 - val_loss: 1335.4734\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1351.6281 - val_loss: 1240.6970\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1257.7430 - val_loss: 1144.0643\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1171.9031 - val_loss: 1058.1963\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1092.2870 - val_loss: 973.6337\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1013.5264 - val_loss: 900.8459\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 945.6757 - val_loss: 834.0799\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 884.2610 - val_loss: 773.4310\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 831.3306 - val_loss: 716.0804\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 770.4982 - val_loss: 666.3056\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 722.8640 - val_loss: 618.1030\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 680.9680 - val_loss: 576.9124\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 635.3784 - val_loss: 540.7558\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 601.1427 - val_loss: 505.7833\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 567.3276 - val_loss: 475.0403\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 540.2810 - val_loss: 448.8140\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 511.0526 - val_loss: 423.7250\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 489.4367 - val_loss: 404.0609\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 461.5724 - val_loss: 382.1505\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 441.1857 - val_loss: 363.9068\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420.9955 - val_loss: 346.0463\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 402.6219 - val_loss: 329.3264\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 386.2618 - val_loss: 313.6786\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 369.4575 - val_loss: 300.3491\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.8208 - val_loss: 286.8731\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 340.6659 - val_loss: 275.0168\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.0636 - val_loss: 262.8786\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 311.6712 - val_loss: 251.5179\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.2280 - val_loss: 242.4386\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.3750 - val_loss: 232.8247\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.3414 - val_loss: 222.5118\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.8498 - val_loss: 217.2173\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.7187 - val_loss: 207.2919\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.3377 - val_loss: 200.6260\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.6145 - val_loss: 193.4068\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.0305 - val_loss: 188.3273\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.3621 - val_loss: 180.6041\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.5087 - val_loss: 175.4653\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.4923 - val_loss: 170.0203\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.0116 - val_loss: 165.6914\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.0740 - val_loss: 159.6228\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192.1257 - val_loss: 158.3983\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.8684 - val_loss: 152.9812\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 183.0182 - val_loss: 147.3075\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.0636 - val_loss: 144.3234\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0668 - val_loss: 140.0799\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.0452 - val_loss: 137.1399\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.1443 - val_loss: 133.7993\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.1908 - val_loss: 132.1264\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.1158 - val_loss: 128.3406\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.7873 - val_loss: 125.5265\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.9043 - val_loss: 122.5789\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4488 - val_loss: 120.2939\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.8241 - val_loss: 117.4168\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.4773 - val_loss: 116.4188\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.1451 - val_loss: 118.4217\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.1404 - val_loss: 116.1810\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.6857 - val_loss: 111.8938\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.2735 - val_loss: 109.4311\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.0970 - val_loss: 107.1049\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.5476 - val_loss: 105.7428\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.6749 - val_loss: 105.0613\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.0929 - val_loss: 103.2013\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.4449 - val_loss: 101.3568\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.4958 - val_loss: 100.2743\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6000 - val_loss: 99.6112\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8994 - val_loss: 99.1640\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.2017 - val_loss: 97.5233\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.7106 - val_loss: 96.8969\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.8664 - val_loss: 95.8892\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9740 - val_loss: 95.9503\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.2243 - val_loss: 93.9397\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8569 - val_loss: 95.3418\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.7589 - val_loss: 92.9739\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.3536 - val_loss: 91.6264\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.4361 - val_loss: 90.9626\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.3458 - val_loss: 91.8305\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.2864 - val_loss: 95.3095\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.7041 - val_loss: 89.3068\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.6597 - val_loss: 89.0034\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.0287 - val_loss: 88.1130\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.6497 - val_loss: 87.8468\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.9545 - val_loss: 85.6434\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.9000 - val_loss: 84.3549\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.0740 - val_loss: 84.9280\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84.6972 - val_loss: 85.0786\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.2343 - val_loss: 82.5530\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.4605 - val_loss: 82.1129\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 50966.0586 - val_loss: 15478.5273\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5474.7246 - val_loss: 1322.3739\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1836.3154 - val_loss: 1304.9139\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1065.7531 - val_loss: 762.1174\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 806.8728 - val_loss: 707.7845\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 732.2233 - val_loss: 637.4975\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 680.5095 - val_loss: 598.3427\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.5366 - val_loss: 570.1213\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 610.7770 - val_loss: 543.7264\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 579.2909 - val_loss: 504.5726\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 530.6575 - val_loss: 453.4070\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 488.9983 - val_loss: 419.6730\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 460.3554 - val_loss: 398.9859\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 442.8501 - val_loss: 379.8142\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.6341 - val_loss: 366.1192\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 400.0854 - val_loss: 349.9546\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 382.6749 - val_loss: 335.3364\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 366.1008 - val_loss: 321.5085\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.9235 - val_loss: 309.9999\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 337.9389 - val_loss: 298.3446\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 325.0797 - val_loss: 290.7004\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 312.8291 - val_loss: 279.0423\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 300.6487 - val_loss: 269.5906\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.9682 - val_loss: 260.7869\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 279.9113 - val_loss: 252.4689\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.1070 - val_loss: 247.1050\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.8617 - val_loss: 239.1709\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.1168 - val_loss: 231.7454\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.0061 - val_loss: 225.8307\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.1643 - val_loss: 219.3137\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.1517 - val_loss: 218.3910\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 223.0983 - val_loss: 209.7431\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.4518 - val_loss: 206.2999\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.1044 - val_loss: 201.7032\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.7678 - val_loss: 196.9328\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.4414 - val_loss: 190.1918\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.7591 - val_loss: 188.6940\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.4699 - val_loss: 182.6840\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.9891 - val_loss: 182.7181\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.0573 - val_loss: 177.1021\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.0996 - val_loss: 171.3560\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.8231 - val_loss: 172.6274\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.0451 - val_loss: 164.8387\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.1042 - val_loss: 160.6498\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.1010 - val_loss: 161.0629\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.9186 - val_loss: 155.5825\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.0818 - val_loss: 154.2925\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.9929 - val_loss: 151.0345\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.0513 - val_loss: 149.7053\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3293 - val_loss: 150.4032\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.0423 - val_loss: 140.5572\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.5057 - val_loss: 147.2523\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.1900 - val_loss: 138.9086\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 130.7216 - val_loss: 133.8948\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.0962 - val_loss: 130.9683\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.1532 - val_loss: 129.2337\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.8769 - val_loss: 129.5302\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0724 - val_loss: 124.2604\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.7721 - val_loss: 121.2839\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.8404 - val_loss: 121.8183\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.0266 - val_loss: 118.8980\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9086 - val_loss: 116.8805\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.0242 - val_loss: 114.6210\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.6512 - val_loss: 118.0275\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1223 - val_loss: 110.4540\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5109 - val_loss: 111.9660\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.6761 - val_loss: 107.7972\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1007 - val_loss: 110.1121\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.6137 - val_loss: 105.6079\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.6881 - val_loss: 102.8922\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.5507 - val_loss: 102.5012\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.2723 - val_loss: 104.0470\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.8236 - val_loss: 99.4153\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.0556 - val_loss: 104.0834\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.9643 - val_loss: 98.2383\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.1151 - val_loss: 97.5313\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.4601 - val_loss: 97.7658\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.5764 - val_loss: 97.3945\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.3303 - val_loss: 94.7978\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.4397 - val_loss: 97.5592\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.6783 - val_loss: 94.9332\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.5267 - val_loss: 98.2742\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.2362 - val_loss: 97.1850\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.4315 - val_loss: 98.1582\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.0493 - val_loss: 94.6956\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.3739 - val_loss: 93.2916\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.8832 - val_loss: 91.5479\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.6451 - val_loss: 90.9743\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.4590 - val_loss: 105.2986\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.6246 - val_loss: 100.2853\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.5693 - val_loss: 92.2691\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.5927 - val_loss: 95.8887\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.7497 - val_loss: 93.8497\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 85.1240 - val_loss: 88.0074\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 82.8040 - val_loss: 88.1593\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.1365 - val_loss: 89.0629\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 82.3190 - val_loss: 86.1653\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84.8912 - val_loss: 86.7891\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.1262 - val_loss: 86.7373\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.5165 - val_loss: 85.2822\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 170707.7656 - val_loss: 127694.1094\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100172.8750 - val_loss: 74996.4141\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 59186.5508 - val_loss: 44451.1484\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 35288.7305 - val_loss: 26342.1660\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20773.3027 - val_loss: 15259.7256\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11975.7041 - val_loss: 8437.9287\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6680.7549 - val_loss: 4574.0767\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3641.3240 - val_loss: 2453.5503\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2038.6713 - val_loss: 1385.9558\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1262.3435 - val_loss: 941.1895\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 943.6133 - val_loss: 763.4496\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 778.0833 - val_loss: 589.9169\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 600.1696 - val_loss: 474.8269\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 499.8359 - val_loss: 407.4725\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 434.7570 - val_loss: 362.7325\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 386.4742 - val_loss: 329.1382\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 348.6868 - val_loss: 303.8127\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.6429 - val_loss: 287.1447\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 299.7353 - val_loss: 273.5580\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 283.2807 - val_loss: 262.1540\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.5075 - val_loss: 250.2547\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 254.2843 - val_loss: 241.3906\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 244.0179 - val_loss: 234.0328\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.2106 - val_loss: 229.2151\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.9612 - val_loss: 222.2568\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.8829 - val_loss: 217.0842\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.4318 - val_loss: 212.0995\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.9700 - val_loss: 209.2825\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.5576 - val_loss: 205.1190\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 201.4613 - val_loss: 202.6032\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.4196 - val_loss: 199.7517\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.8977 - val_loss: 199.0175\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.7591 - val_loss: 196.1411\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.4758 - val_loss: 194.4240\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.0229 - val_loss: 193.1819\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.2736 - val_loss: 191.7908\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.5462 - val_loss: 190.7024\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.4828 - val_loss: 192.0086\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.4855 - val_loss: 188.7009\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.1215 - val_loss: 188.0654\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.7717 - val_loss: 187.0983\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.3460 - val_loss: 187.5221\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.4835 - val_loss: 185.7919\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.8923 - val_loss: 185.1557\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.5878 - val_loss: 185.0900\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.6217 - val_loss: 184.1459\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.3162 - val_loss: 184.2145\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.3863 - val_loss: 182.8238\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.0911 - val_loss: 183.0346\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.9907 - val_loss: 181.9472\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.9842 - val_loss: 182.4519\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.2014 - val_loss: 181.2660\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.8355 - val_loss: 180.2351\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.3489 - val_loss: 179.6440\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.5331 - val_loss: 179.5710\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.1453 - val_loss: 179.3651\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172.5506 - val_loss: 178.2613\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0899 - val_loss: 178.1969\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 170.8487 - val_loss: 178.0555\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.6154 - val_loss: 177.0096\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0415 - val_loss: 178.7791\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.8927 - val_loss: 175.9315\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.6321 - val_loss: 176.4183\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.5540 - val_loss: 174.9599\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.8199 - val_loss: 175.3766\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.7482 - val_loss: 173.6683\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.3018 - val_loss: 173.2712\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.7522 - val_loss: 175.0891\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.2067 - val_loss: 172.5731\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.5491 - val_loss: 172.2309\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.0806 - val_loss: 172.1286\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.4602 - val_loss: 170.7474\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.5955 - val_loss: 171.2612\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.4681 - val_loss: 170.6079\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.9360 - val_loss: 172.5655\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.4054 - val_loss: 169.8380\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.5625 - val_loss: 170.8755\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.9578 - val_loss: 169.0991\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.8018 - val_loss: 171.3104\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.7812 - val_loss: 169.3207\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.0257 - val_loss: 170.3242\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.6344 - val_loss: 168.6252\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.0793 - val_loss: 167.5624\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.7138 - val_loss: 167.8790\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.0650 - val_loss: 166.7209\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.9371 - val_loss: 166.5043\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.5857 - val_loss: 166.2874\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.8893 - val_loss: 165.7097\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.8613 - val_loss: 167.1322\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.9626 - val_loss: 165.3069\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.6030 - val_loss: 165.5391\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.4449 - val_loss: 165.0121\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.1475 - val_loss: 164.1909\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9137 - val_loss: 164.0528\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.9211 - val_loss: 165.5046\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.3274 - val_loss: 163.1254\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.8469 - val_loss: 163.1739\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.5653 - val_loss: 163.0019\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9255 - val_loss: 166.0273\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.4606 - val_loss: 162.4477\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 14719.8633 - val_loss: 6186.7012\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2676.2810 - val_loss: 464.7037\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.1275 - val_loss: 299.3506\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.4045 - val_loss: 210.8210\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.8305 - val_loss: 192.6597\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.9163 - val_loss: 188.5699\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.8150 - val_loss: 184.8415\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.0084 - val_loss: 182.8055\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.0007 - val_loss: 180.6407\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.7045 - val_loss: 178.7622\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.7415 - val_loss: 177.1945\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.7380 - val_loss: 174.7260\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.6240 - val_loss: 173.0078\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.8153 - val_loss: 171.2762\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.1242 - val_loss: 169.0253\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.1233 - val_loss: 167.1515\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.9595 - val_loss: 166.0858\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.0606 - val_loss: 163.7489\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.8340 - val_loss: 162.6935\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3805 - val_loss: 160.4422\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.7225 - val_loss: 159.6099\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.3272 - val_loss: 156.9362\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.4945 - val_loss: 155.4559\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.7011 - val_loss: 153.6868\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.2734 - val_loss: 152.6849\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.6166 - val_loss: 150.0605\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.8020 - val_loss: 149.0798\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.7159 - val_loss: 146.2712\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.3491 - val_loss: 145.5394\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5263 - val_loss: 143.3399\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.2564 - val_loss: 142.0110\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.2830 - val_loss: 139.9604\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.8823 - val_loss: 138.2180\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0868 - val_loss: 137.8279\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.8061 - val_loss: 134.8534\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.3444 - val_loss: 133.3639\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8474 - val_loss: 132.7458\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.5533 - val_loss: 130.0723\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.3324 - val_loss: 129.4404\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1859 - val_loss: 127.0477\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.0828 - val_loss: 126.6484\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.9717 - val_loss: 125.0198\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5551 - val_loss: 126.1432\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.1694 - val_loss: 121.5932\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.9429 - val_loss: 120.5367\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.3646 - val_loss: 118.9390\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.5281 - val_loss: 118.0132\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.6667 - val_loss: 117.1514\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.2093 - val_loss: 117.1529\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7951 - val_loss: 114.4565\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.3408 - val_loss: 113.7978\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.2236 - val_loss: 113.9329\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.2861 - val_loss: 111.4096\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.6728 - val_loss: 111.8804\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.1421 - val_loss: 109.6041\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.0850 - val_loss: 109.2914\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.3526 - val_loss: 108.4565\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.9679 - val_loss: 106.9652\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.8980 - val_loss: 106.0318\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.4587 - val_loss: 105.9062\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.5176 - val_loss: 105.9197\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.7166 - val_loss: 103.7975\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.6598 - val_loss: 103.2078\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.1206 - val_loss: 102.4812\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.1802 - val_loss: 101.2267\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.4459 - val_loss: 100.7707\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 83.0490 - val_loss: 100.7930\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.3721 - val_loss: 102.0528\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.1985 - val_loss: 98.9077\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81.3486 - val_loss: 99.1645\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.3766 - val_loss: 99.4017\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.4033 - val_loss: 96.6184\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.0819 - val_loss: 97.0096\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.8188 - val_loss: 97.3637\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.9936 - val_loss: 95.3242\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.0164 - val_loss: 95.1665\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.9424 - val_loss: 94.0365\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.0351 - val_loss: 96.2576\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76.8165 - val_loss: 93.1104\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.8315 - val_loss: 93.9479\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76.2921 - val_loss: 92.4659\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.6720 - val_loss: 91.3351\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.6723 - val_loss: 96.5925\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.9908 - val_loss: 92.6334\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.4476 - val_loss: 90.2024\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.8834 - val_loss: 89.5290\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.3590 - val_loss: 96.5069\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 75.5167 - val_loss: 89.1028\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.2168 - val_loss: 91.3271\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.7114 - val_loss: 89.2812\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.3081 - val_loss: 87.4404\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.1180 - val_loss: 86.9540\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.8238 - val_loss: 92.5153\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.8322 - val_loss: 86.1055\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.1894 - val_loss: 87.3488\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.3378 - val_loss: 85.5016\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 71.6530 - val_loss: 90.0148\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.9834 - val_loss: 85.1229\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.6325 - val_loss: 84.4116\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.2782 - val_loss: 83.5513\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 2042.5719 - val_loss: 1381.1785\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 886.3976 - val_loss: 711.4434\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 628.4700 - val_loss: 537.7765\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 473.0999 - val_loss: 430.8484\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 404.2307 - val_loss: 368.6512\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.3396 - val_loss: 319.3159\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 311.9865 - val_loss: 277.8902\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 275.5362 - val_loss: 244.4301\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.4770 - val_loss: 218.7061\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.3973 - val_loss: 195.3985\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.5394 - val_loss: 181.2085\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.2556 - val_loss: 165.9592\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.0076 - val_loss: 157.3183\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0570 - val_loss: 151.6901\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.4721 - val_loss: 144.8833\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.0401 - val_loss: 135.6436\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.0225 - val_loss: 131.2936\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.8726 - val_loss: 136.1237\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.4918 - val_loss: 124.0188\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.3609 - val_loss: 123.2765\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.4902 - val_loss: 124.9903\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.4124 - val_loss: 121.2831\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.9567 - val_loss: 115.2869\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.8168 - val_loss: 113.6978\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.3776 - val_loss: 111.9023\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.3091 - val_loss: 114.0108\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5882 - val_loss: 110.2909\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.8713 - val_loss: 121.7773\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.1772 - val_loss: 108.1013\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5918 - val_loss: 106.9680\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.3430 - val_loss: 106.5838\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.1110 - val_loss: 106.0759\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3636 - val_loss: 106.0376\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6189 - val_loss: 103.8123\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.7845 - val_loss: 103.7497\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.3045 - val_loss: 105.2552\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.0759 - val_loss: 104.3548\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.3796 - val_loss: 103.0749\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.5431 - val_loss: 102.4062\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.2987 - val_loss: 103.1981\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 107.6811 - val_loss: 102.5519\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.5365 - val_loss: 105.0979\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.2309 - val_loss: 101.3913\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.7351 - val_loss: 103.3484\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5219 - val_loss: 101.1405\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7535 - val_loss: 105.8811\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.1364 - val_loss: 102.4090\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3035 - val_loss: 103.5967\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.6717 - val_loss: 122.7609\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.0975 - val_loss: 111.8227\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.2375 - val_loss: 103.3198\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.0283 - val_loss: 104.1533\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.2721 - val_loss: 104.4709\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.5496 - val_loss: 104.2857\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7194 - val_loss: 104.6093\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.4979 - val_loss: 102.0584\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.5907 - val_loss: 106.3538\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.2093 - val_loss: 103.0217\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.6606 - val_loss: 104.4690\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.4185 - val_loss: 107.5652\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.0310 - val_loss: 104.4628\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.0427 - val_loss: 109.5190\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.1054 - val_loss: 104.8050\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.2728 - val_loss: 107.0267\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0876 - val_loss: 106.6022\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.9279 - val_loss: 105.3105\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8152 - val_loss: 105.9837\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.5464 - val_loss: 105.2245\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.1306 - val_loss: 106.2040\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3374 - val_loss: 105.7939\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.7796 - val_loss: 106.7479\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.3525 - val_loss: 105.2450\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.1646 - val_loss: 106.7313\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.5370 - val_loss: 110.1916\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.5134 - val_loss: 109.6502\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.7565 - val_loss: 106.0753\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.5074 - val_loss: 112.6131\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.7918 - val_loss: 106.3444\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.2141 - val_loss: 111.6647\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.3921 - val_loss: 112.6952\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.6985 - val_loss: 106.5490\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.6201 - val_loss: 105.2476\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.6914 - val_loss: 110.9252\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.4412 - val_loss: 105.1062\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.3399 - val_loss: 106.9069\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.9272 - val_loss: 114.6695\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.6857 - val_loss: 106.6110\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.8882 - val_loss: 107.4240\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.9486 - val_loss: 106.7296\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.6413 - val_loss: 105.2734\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.8551 - val_loss: 106.0436\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.4283 - val_loss: 113.7010\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.1698 - val_loss: 109.3376\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7257 - val_loss: 103.4056\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.7801 - val_loss: 104.7909\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.0715 - val_loss: 104.6542\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.6818 - val_loss: 104.0741\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.8072 - val_loss: 106.1163\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.2573 - val_loss: 106.1954\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.2062 - val_loss: 103.8772\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 115234.5625 - val_loss: 88166.6797\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67950.5000 - val_loss: 43229.0195\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 27204.7266 - val_loss: 13034.5459\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7036.1187 - val_loss: 3143.6816\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2022.5166 - val_loss: 1984.3671\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1738.6587 - val_loss: 1946.0560\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1667.4318 - val_loss: 1794.0425\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1544.0934 - val_loss: 1697.0261\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1457.3467 - val_loss: 1607.7964\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1382.4199 - val_loss: 1518.3756\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1307.2747 - val_loss: 1434.1293\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1237.1083 - val_loss: 1353.9918\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1170.0573 - val_loss: 1278.1517\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1110.6653 - val_loss: 1209.7318\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1048.2775 - val_loss: 1140.3699\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 991.1448 - val_loss: 1076.9623\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 937.4803 - val_loss: 1018.4241\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 888.2880 - val_loss: 960.7646\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 841.4494 - val_loss: 907.6334\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 798.5234 - val_loss: 859.3335\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 757.2493 - val_loss: 813.0880\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 719.2771 - val_loss: 769.7335\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 683.5792 - val_loss: 730.1652\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 650.8502 - val_loss: 693.1567\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 621.1639 - val_loss: 658.0221\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 592.2381 - val_loss: 625.3252\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 564.9647 - val_loss: 596.1077\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 541.4605 - val_loss: 567.3466\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 520.3217 - val_loss: 541.5769\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 497.3443 - val_loss: 517.0159\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 477.1308 - val_loss: 494.9256\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 459.5005 - val_loss: 473.4908\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 442.2168 - val_loss: 453.9409\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.6335 - val_loss: 437.3664\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 411.7697 - val_loss: 419.2691\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 397.7960 - val_loss: 403.8697\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 386.8988 - val_loss: 388.9277\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.6115 - val_loss: 376.3478\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.8127 - val_loss: 362.2768\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 351.6075 - val_loss: 350.8640\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 342.0013 - val_loss: 339.7598\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.0203 - val_loss: 329.5411\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 326.2513 - val_loss: 319.2233\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.9710 - val_loss: 311.3959\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.4925 - val_loss: 302.8143\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 303.0016 - val_loss: 294.6059\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.6569 - val_loss: 287.2950\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.7445 - val_loss: 280.6375\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.0275 - val_loss: 274.8086\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.6496 - val_loss: 266.7155\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.7620 - val_loss: 262.5193\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.8988 - val_loss: 255.3621\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.5173 - val_loss: 250.2662\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.8026 - val_loss: 246.0750\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.6751 - val_loss: 240.5231\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 249.3520 - val_loss: 235.6481\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.6762 - val_loss: 231.8752\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.9148 - val_loss: 229.2941\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.5909 - val_loss: 223.5742\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.6311 - val_loss: 220.4369\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 230.0303 - val_loss: 216.0908\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.7334 - val_loss: 212.2690\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.3300 - val_loss: 210.4442\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.2039 - val_loss: 206.2829\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.9102 - val_loss: 203.3432\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0467 - val_loss: 199.3066\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 209.8814 - val_loss: 196.7020\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.6819 - val_loss: 194.9381\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 203.6780 - val_loss: 191.5297\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.2040 - val_loss: 188.6491\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.1092 - val_loss: 188.5104\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.0848 - val_loss: 183.2211\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.0578 - val_loss: 180.6647\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.0150 - val_loss: 179.3715\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.6315 - val_loss: 176.8369\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 185.5752 - val_loss: 176.2049\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183.2521 - val_loss: 173.1606\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.2158 - val_loss: 170.5970\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.0777 - val_loss: 168.7231\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.1583 - val_loss: 167.4985\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.8281 - val_loss: 165.0517\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.0982 - val_loss: 165.4417\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 170.8973 - val_loss: 160.5687\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.2527 - val_loss: 160.3752\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.9831 - val_loss: 158.5860\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.0016 - val_loss: 155.9896\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.1482 - val_loss: 154.8051\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.7118 - val_loss: 152.6438\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.9099 - val_loss: 151.3697\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.9882 - val_loss: 149.2998\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.5858 - val_loss: 147.9673\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.3218 - val_loss: 145.8440\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.5667 - val_loss: 147.0362\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.7665 - val_loss: 142.9743\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.7147 - val_loss: 141.9814\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.3291 - val_loss: 140.3281\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.9594 - val_loss: 141.0375\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.5518 - val_loss: 139.3144\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.3303 - val_loss: 137.9471\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.3239 - val_loss: 135.4552\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 2500.5444 - val_loss: 1081.6060\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 873.2372 - val_loss: 731.7695\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 609.3687 - val_loss: 539.3697\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 441.1194 - val_loss: 383.4081\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 340.3255 - val_loss: 322.8568\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 312.9258 - val_loss: 303.6865\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 299.6017 - val_loss: 296.2723\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.3835 - val_loss: 289.4075\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.9892 - val_loss: 282.7809\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.3777 - val_loss: 264.5838\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.0074 - val_loss: 238.7198\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.2570 - val_loss: 216.6173\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.7242 - val_loss: 202.1765\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.6047 - val_loss: 198.0878\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.5856 - val_loss: 187.1203\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.4282 - val_loss: 191.0315\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.0734 - val_loss: 178.3154\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.5184 - val_loss: 176.6868\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.8484 - val_loss: 172.5359\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.0578 - val_loss: 165.9845\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.0879 - val_loss: 164.6388\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.8916 - val_loss: 158.9831\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.8251 - val_loss: 157.1833\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4703 - val_loss: 153.6389\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.4028 - val_loss: 151.5860\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.5113 - val_loss: 148.2031\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.5605 - val_loss: 145.8541\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.9988 - val_loss: 144.0471\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.4391 - val_loss: 149.0632\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.5308 - val_loss: 139.7807\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.2365 - val_loss: 138.3641\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.3102 - val_loss: 137.4032\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9110 - val_loss: 137.1847\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.2579 - val_loss: 133.7497\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.1417 - val_loss: 135.0606\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.4242 - val_loss: 133.2045\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.5140 - val_loss: 129.0002\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.4240 - val_loss: 128.7637\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.2706 - val_loss: 126.3890\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.3951 - val_loss: 125.9615\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.3368 - val_loss: 124.2549\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.4987 - val_loss: 129.4485\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.1440 - val_loss: 123.1742\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.1580 - val_loss: 121.5738\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.6772 - val_loss: 121.0851\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.6795 - val_loss: 120.0119\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.2800 - val_loss: 121.3849\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.9916 - val_loss: 119.2623\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.2225 - val_loss: 118.4979\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2122 - val_loss: 117.8049\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.0181 - val_loss: 119.0057\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.9325 - val_loss: 117.2186\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.3846 - val_loss: 116.8076\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1303 - val_loss: 118.3308\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.0166 - val_loss: 116.0827\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.9497 - val_loss: 115.9797\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.6465 - val_loss: 115.2487\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.3377 - val_loss: 115.5500\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.2605 - val_loss: 119.5133\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.6729 - val_loss: 115.5722\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.5135 - val_loss: 114.8072\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.9105 - val_loss: 114.4564\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.5968 - val_loss: 117.0986\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.8119 - val_loss: 117.3359\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7711 - val_loss: 113.8625\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.5923 - val_loss: 113.9094\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9177 - val_loss: 118.2963\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.8851 - val_loss: 113.2031\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.1728 - val_loss: 117.1343\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4309 - val_loss: 113.3340\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4028 - val_loss: 116.6661\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2962 - val_loss: 112.2719\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.2801 - val_loss: 114.8057\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8742 - val_loss: 111.9575\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9866 - val_loss: 111.5001\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.8123 - val_loss: 112.3372\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.4363 - val_loss: 111.7609\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.1640 - val_loss: 113.6012\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4724 - val_loss: 110.3762\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2005 - val_loss: 110.2068\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0996 - val_loss: 110.8083\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.6214 - val_loss: 115.6967\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.0796 - val_loss: 109.5700\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.1073 - val_loss: 111.6935\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.8442 - val_loss: 109.5315\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.6990 - val_loss: 109.7546\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.6293 - val_loss: 111.3181\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8521 - val_loss: 109.4774\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8148 - val_loss: 108.8879\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.8292 - val_loss: 110.8321\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.6974 - val_loss: 108.7121\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.0832 - val_loss: 109.8984\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.9639 - val_loss: 108.4135\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.4790 - val_loss: 108.3670\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.1635 - val_loss: 108.8992\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1618 - val_loss: 108.3412\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1027 - val_loss: 108.1836\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7382 - val_loss: 107.6958\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.0125 - val_loss: 110.5145\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.8092 - val_loss: 107.1525\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 1970.6221 - val_loss: 1397.4325\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1283.5582 - val_loss: 1033.0619\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1013.0373 - val_loss: 845.2322\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 843.3862 - val_loss: 706.2708\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 694.1423 - val_loss: 602.2231\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 572.6677 - val_loss: 522.8666\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 489.5390 - val_loss: 462.1031\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.4566 - val_loss: 417.8154\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 382.9984 - val_loss: 382.5424\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 351.0318 - val_loss: 359.1717\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328.5230 - val_loss: 345.5604\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.2445 - val_loss: 330.7611\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.6415 - val_loss: 320.4954\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 283.6219 - val_loss: 311.4917\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.7999 - val_loss: 304.8950\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.2697 - val_loss: 301.8606\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 261.7618 - val_loss: 293.6498\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.6210 - val_loss: 293.8336\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.2637 - val_loss: 285.7124\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.9621 - val_loss: 282.1302\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.8318 - val_loss: 280.4695\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.6438 - val_loss: 277.2395\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.4938 - val_loss: 272.4092\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.8123 - val_loss: 267.2603\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.3995 - val_loss: 264.3502\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.5280 - val_loss: 259.1667\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.8977 - val_loss: 262.5584\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.9657 - val_loss: 250.7396\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.0827 - val_loss: 248.7950\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.8345 - val_loss: 240.1053\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.6394 - val_loss: 235.0074\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.8064 - val_loss: 231.2961\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.7886 - val_loss: 224.6793\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.5269 - val_loss: 230.8839\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.5568 - val_loss: 212.2938\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.2871 - val_loss: 209.5322\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.2933 - val_loss: 199.1082\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.4309 - val_loss: 204.7765\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.4792 - val_loss: 185.3387\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.8840 - val_loss: 189.9173\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4304 - val_loss: 180.9732\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.3269 - val_loss: 189.8509\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.6469 - val_loss: 205.5693\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.4239 - val_loss: 163.8574\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.5617 - val_loss: 160.1049\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.6871 - val_loss: 154.7964\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.0028 - val_loss: 152.3364\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.5091 - val_loss: 152.2100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.9373 - val_loss: 145.5217\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.3439 - val_loss: 151.7396\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2380 - val_loss: 141.7615\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1669 - val_loss: 140.8272\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.9582 - val_loss: 135.2537\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8569 - val_loss: 135.5493\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.9903 - val_loss: 133.2884\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.7544 - val_loss: 129.9931\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.2615 - val_loss: 130.5923\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.4986 - val_loss: 125.7793\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.2522 - val_loss: 125.8539\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112.3310 - val_loss: 123.0439\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.7440 - val_loss: 121.8799\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.4584 - val_loss: 123.3796\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.9194 - val_loss: 129.5448\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5074 - val_loss: 118.6129\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.5802 - val_loss: 117.6231\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8774 - val_loss: 116.0379\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.2441 - val_loss: 115.1741\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.5240 - val_loss: 113.0660\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.0669 - val_loss: 113.0197\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.4285 - val_loss: 116.3330\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.4323 - val_loss: 116.4012\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.9537 - val_loss: 110.3563\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.8366 - val_loss: 114.0390\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.1141 - val_loss: 116.0190\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.9802 - val_loss: 110.7271\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.6532 - val_loss: 108.2844\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.0254 - val_loss: 121.5273\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.4317 - val_loss: 105.7123\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.8662 - val_loss: 105.3024\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.1305 - val_loss: 103.1817\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.4168 - val_loss: 106.4406\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 100.3532 - val_loss: 115.3653\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.4972 - val_loss: 115.2224\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1783 - val_loss: 101.4120\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.6483 - val_loss: 100.5987\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.6287 - val_loss: 102.1901\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.9704 - val_loss: 104.5902\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 88.2097 - val_loss: 98.8691\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.1601 - val_loss: 99.2182\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.8701 - val_loss: 99.4861\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.5135 - val_loss: 100.6820\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.8725 - val_loss: 107.6352\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.0559 - val_loss: 97.8650\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.1256 - val_loss: 98.2849\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.2418 - val_loss: 95.4446\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.2641 - val_loss: 95.4416\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.0687 - val_loss: 97.0084\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84.7804 - val_loss: 94.5415\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.5946 - val_loss: 93.7666\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.5848 - val_loss: 100.4353\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 86001.1016 - val_loss: 51065.1133\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 30407.7988 - val_loss: 14442.1650\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7326.3574 - val_loss: 3304.7837\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2156.7307 - val_loss: 2210.7080\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1858.1498 - val_loss: 2059.0566\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1680.1349 - val_loss: 1844.0245\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1502.9668 - val_loss: 1674.8135\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1378.9299 - val_loss: 1528.1865\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1244.8586 - val_loss: 1380.3790\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1127.7961 - val_loss: 1252.8540\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1026.0077 - val_loss: 1139.0826\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 934.9842 - val_loss: 1032.7870\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 849.2829 - val_loss: 941.9443\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 775.3190 - val_loss: 856.6038\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 707.8928 - val_loss: 780.0920\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 647.2130 - val_loss: 710.2787\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 593.8243 - val_loss: 647.8124\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 544.5408 - val_loss: 590.4691\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 499.8406 - val_loss: 542.7029\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 461.3294 - val_loss: 498.6645\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 428.3534 - val_loss: 457.7822\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 395.8485 - val_loss: 424.1766\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 369.8550 - val_loss: 393.6511\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 345.4361 - val_loss: 365.5843\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 326.4164 - val_loss: 340.5234\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 306.6006 - val_loss: 320.7045\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.5541 - val_loss: 303.5087\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.8256 - val_loss: 286.8887\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.9677 - val_loss: 272.7498\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.2066 - val_loss: 258.7040\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.9825 - val_loss: 249.4290\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.1736 - val_loss: 238.6176\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.0294 - val_loss: 230.3850\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.0772 - val_loss: 224.0088\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.1089 - val_loss: 216.1379\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.0689 - val_loss: 210.7389\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.5233 - val_loss: 205.2610\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.0887 - val_loss: 201.3144\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.0237 - val_loss: 196.3003\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.9104 - val_loss: 192.0413\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.1923 - val_loss: 190.3790\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.2506 - val_loss: 186.4711\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.9169 - val_loss: 183.1901\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.8974 - val_loss: 180.7489\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.3057 - val_loss: 178.5271\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.6026 - val_loss: 176.5900\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.0948 - val_loss: 174.1626\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.9966 - val_loss: 172.7640\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.8898 - val_loss: 170.4264\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.7172 - val_loss: 168.3475\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.2547 - val_loss: 169.7002\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.9726 - val_loss: 165.3728\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.4312 - val_loss: 164.4376\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.8567 - val_loss: 162.8647\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.7613 - val_loss: 161.8279\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.5907 - val_loss: 159.9840\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.2376 - val_loss: 159.8460\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.1908 - val_loss: 158.1462\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.3761 - val_loss: 156.2886\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 162.8541 - val_loss: 156.6351\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.5219 - val_loss: 154.1874\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.4114 - val_loss: 153.1237\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.1857 - val_loss: 152.3910\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.9123 - val_loss: 151.2789\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.5695 - val_loss: 150.2596\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.1749 - val_loss: 149.3969\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.5413 - val_loss: 148.1908\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.6232 - val_loss: 148.1735\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.2963 - val_loss: 146.5847\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.2378 - val_loss: 145.7343\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.6994 - val_loss: 145.6100\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.6104 - val_loss: 144.9112\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.0819 - val_loss: 143.2771\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.1528 - val_loss: 142.8656\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.9989 - val_loss: 141.9959\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.6796 - val_loss: 141.2009\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.8435 - val_loss: 140.5058\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.8174 - val_loss: 139.7744\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.1759 - val_loss: 139.3989\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.2013 - val_loss: 138.3800\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.5498 - val_loss: 137.9401\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.7590 - val_loss: 137.2751\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.1495 - val_loss: 136.4987\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.6617 - val_loss: 136.5216\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.8595 - val_loss: 135.2610\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.2664 - val_loss: 134.7672\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.4876 - val_loss: 134.1461\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.6949 - val_loss: 133.6256\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.9271 - val_loss: 132.8712\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.6413 - val_loss: 132.2537\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.9215 - val_loss: 131.8024\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.2403 - val_loss: 131.6148\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.6236 - val_loss: 130.5872\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.3397 - val_loss: 130.0756\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.6057 - val_loss: 129.4993\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.3747 - val_loss: 129.2670\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 133.8595 - val_loss: 128.6143\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.7507 - val_loss: 128.2903\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.3781 - val_loss: 127.5328\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.7270 - val_loss: 127.0327\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 680.3596 - val_loss: 641.7695\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 569.5132 - val_loss: 550.9906\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 498.0417 - val_loss: 455.7810\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 432.4797 - val_loss: 394.1461\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 397.1726 - val_loss: 365.5297\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 379.9608 - val_loss: 348.4496\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.1180 - val_loss: 331.7729\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.6946 - val_loss: 317.5850\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.0772 - val_loss: 302.4561\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 300.7510 - val_loss: 294.3508\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.1282 - val_loss: 297.9133\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.6902 - val_loss: 272.6095\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 261.7105 - val_loss: 272.0167\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.3450 - val_loss: 257.0800\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.4113 - val_loss: 247.6715\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.7041 - val_loss: 237.5205\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.5606 - val_loss: 231.5014\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.4668 - val_loss: 227.5803\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.8791 - val_loss: 224.9542\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.7439 - val_loss: 213.5960\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.1257 - val_loss: 204.5458\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.4747 - val_loss: 205.4699\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.6535 - val_loss: 226.1551\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.5777 - val_loss: 193.2391\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.7691 - val_loss: 186.2568\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.4884 - val_loss: 191.3455\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.3402 - val_loss: 176.4969\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.5905 - val_loss: 173.3549\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.0686 - val_loss: 176.9212\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4435 - val_loss: 172.1805\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.2583 - val_loss: 168.9669\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4484 - val_loss: 157.7836\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.1140 - val_loss: 163.9137\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.4165 - val_loss: 156.1827\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.6463 - val_loss: 153.5362\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.0666 - val_loss: 156.2730\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.4385 - val_loss: 143.3121\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.6988 - val_loss: 148.5737\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.5728 - val_loss: 139.6609\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.2966 - val_loss: 136.9771\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 123.4746 - val_loss: 133.5582\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.9033 - val_loss: 134.2776\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8671 - val_loss: 132.1382\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6251 - val_loss: 132.8463\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.4026 - val_loss: 128.4921\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.4170 - val_loss: 141.0486\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9226 - val_loss: 125.7921\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.2285 - val_loss: 126.2258\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.6379 - val_loss: 123.7626\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.3735 - val_loss: 123.1076\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.4592 - val_loss: 127.0506\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1417 - val_loss: 123.1430\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.4455 - val_loss: 121.1226\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8062 - val_loss: 121.5680\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5996 - val_loss: 120.6998\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.5751 - val_loss: 122.2523\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.8153 - val_loss: 126.4181\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.8188 - val_loss: 130.9920\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.4233 - val_loss: 115.6496\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.1564 - val_loss: 118.1919\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.0075 - val_loss: 120.1700\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.8426 - val_loss: 123.2221\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.8290 - val_loss: 122.8224\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.0818 - val_loss: 112.5942\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.0130 - val_loss: 114.3747\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.5163 - val_loss: 114.3845\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.3499 - val_loss: 111.7344\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.3618 - val_loss: 111.1397\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.8304 - val_loss: 112.8209\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.9223 - val_loss: 109.4247\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.2004 - val_loss: 110.0274\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.9449 - val_loss: 110.1614\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.1391 - val_loss: 110.9677\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.5718 - val_loss: 110.4488\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.8457 - val_loss: 108.5190\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.3052 - val_loss: 106.9012\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.7794 - val_loss: 108.8562\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 85.5264 - val_loss: 112.9150\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.1592 - val_loss: 105.3812\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.7237 - val_loss: 105.8489\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.0972 - val_loss: 112.7410\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.2344 - val_loss: 108.4680\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.2217 - val_loss: 105.5503\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.0465 - val_loss: 103.0917\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.6889 - val_loss: 103.6234\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.7323 - val_loss: 100.4894\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81.8451 - val_loss: 107.6282\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.2373 - val_loss: 100.7920\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.9538 - val_loss: 98.7007\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76.3110 - val_loss: 96.9614\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 74.8588 - val_loss: 97.1843\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.0062 - val_loss: 109.9391\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.2235 - val_loss: 97.5754\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 72.2851 - val_loss: 99.7817\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.1393 - val_loss: 96.5670\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 72.0091 - val_loss: 100.5984\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.4819 - val_loss: 94.1073\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.2818 - val_loss: 91.1469\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.6810 - val_loss: 92.2478\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.0531 - val_loss: 91.1149\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 1680.0693 - val_loss: 1262.8285\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1116.2142 - val_loss: 979.1501\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 971.9130 - val_loss: 884.2510\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 866.0988 - val_loss: 805.1824\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 784.7490 - val_loss: 719.5494\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 710.8964 - val_loss: 652.8694\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 641.2165 - val_loss: 597.0044\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 583.2803 - val_loss: 541.0118\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 536.8399 - val_loss: 498.4425\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 496.0282 - val_loss: 458.8204\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 457.8240 - val_loss: 424.9424\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 424.5799 - val_loss: 392.4652\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 395.3957 - val_loss: 365.5630\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 371.0531 - val_loss: 342.2412\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 346.6823 - val_loss: 321.1833\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 326.9942 - val_loss: 301.8363\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 313.8105 - val_loss: 284.8150\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.3452 - val_loss: 274.8028\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.5990 - val_loss: 256.7906\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.5835 - val_loss: 242.6570\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.9919 - val_loss: 230.3915\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.5908 - val_loss: 223.0309\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.6588 - val_loss: 210.6625\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.7077 - val_loss: 199.9166\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.3847 - val_loss: 192.0574\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.2922 - val_loss: 184.2991\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.0705 - val_loss: 175.7958\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5014 - val_loss: 168.8569\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.2791 - val_loss: 162.4399\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.0079 - val_loss: 156.3644\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.8560 - val_loss: 149.1422\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.8620 - val_loss: 160.0012\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4230 - val_loss: 148.1953\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.1916 - val_loss: 135.1312\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.5856 - val_loss: 133.6691\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.4233 - val_loss: 125.9576\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.9925 - val_loss: 125.8705\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6415 - val_loss: 118.6513\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3703 - val_loss: 120.1780\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.6049 - val_loss: 115.9378\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.9979 - val_loss: 111.5211\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0967 - val_loss: 108.5403\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.1914 - val_loss: 108.2249\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.8404 - val_loss: 113.8115\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.9243 - val_loss: 109.0355\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.4212 - val_loss: 102.8144\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.7151 - val_loss: 107.4052\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.9764 - val_loss: 101.1717\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.4060 - val_loss: 101.7929\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.5678 - val_loss: 104.1347\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.5937 - val_loss: 99.2957\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84.3082 - val_loss: 103.1717\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.7176 - val_loss: 105.9003\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.9254 - val_loss: 98.8578\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.9248 - val_loss: 98.7335\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.4251 - val_loss: 96.5767\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.4136 - val_loss: 97.7159\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.1150 - val_loss: 95.2046\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 77.7103 - val_loss: 94.0248\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76.2739 - val_loss: 93.1345\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.1514 - val_loss: 92.4511\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.5369 - val_loss: 91.9253\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.7679 - val_loss: 92.9862\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.3657 - val_loss: 94.5874\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 72.3529 - val_loss: 90.5297\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 72.5738 - val_loss: 89.6535\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 71.8985 - val_loss: 89.4635\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.7054 - val_loss: 95.1536\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.2643 - val_loss: 97.6566\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 69.6704 - val_loss: 88.3737\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.7108 - val_loss: 88.5648\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.2047 - val_loss: 87.9941\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.3869 - val_loss: 87.0313\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 68.6044 - val_loss: 90.1673\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.9491 - val_loss: 86.3028\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.7591 - val_loss: 85.9175\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.4781 - val_loss: 86.1561\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.0722 - val_loss: 85.8170\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.4462 - val_loss: 89.3488\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 67.6215 - val_loss: 86.5049\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.0770 - val_loss: 84.7602\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66.3589 - val_loss: 85.0723\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65.8417 - val_loss: 83.8387\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 65.4262 - val_loss: 83.9212\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 65.0170 - val_loss: 83.6515\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 65.5477 - val_loss: 83.5450\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 64.6390 - val_loss: 84.0990\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.7972 - val_loss: 84.1957\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 65.3017 - val_loss: 83.2446\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.4862 - val_loss: 83.4195\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63.8260 - val_loss: 82.3324\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 64.0921 - val_loss: 84.8265\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.6900 - val_loss: 85.4515\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.2648 - val_loss: 81.6653\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 62.8087 - val_loss: 81.5723\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.7755 - val_loss: 82.0713\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 62.8188 - val_loss: 80.7316\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 62.7370 - val_loss: 80.9545\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63.5840 - val_loss: 81.9976\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 66.7644 - val_loss: 86.0872\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 11ms/step - loss: 26666.8281 - val_loss: 7490.9795\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5935.4463 - val_loss: 6625.4722\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5030.1709 - val_loss: 4364.2974\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3741.1104 - val_loss: 3385.9907\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2853.9214 - val_loss: 2771.6030\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2397.5605 - val_loss: 2325.7278\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2070.7173 - val_loss: 2007.8883\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1828.9768 - val_loss: 1776.9399\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1623.2671 - val_loss: 1573.8467\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1449.9348 - val_loss: 1393.0002\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1296.3112 - val_loss: 1237.2443\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1160.2185 - val_loss: 1108.8395\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1042.6598 - val_loss: 984.4275\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 927.2695 - val_loss: 877.8084\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 835.0132 - val_loss: 780.8985\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 744.9631 - val_loss: 696.1862\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 663.4223 - val_loss: 620.9681\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 592.9739 - val_loss: 560.3441\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 535.1628 - val_loss: 495.4957\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 477.0096 - val_loss: 444.6645\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 428.1542 - val_loss: 399.7735\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 384.9350 - val_loss: 361.1508\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 349.5432 - val_loss: 328.3611\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 314.6254 - val_loss: 298.1072\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.1928 - val_loss: 272.1071\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.1882 - val_loss: 252.8610\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.0336 - val_loss: 234.9372\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.2475 - val_loss: 220.7266\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.7641 - val_loss: 209.7715\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.8830 - val_loss: 197.3954\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189.5069 - val_loss: 189.0610\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.0549 - val_loss: 182.0422\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.0504 - val_loss: 176.4652\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.7528 - val_loss: 172.3959\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.5926 - val_loss: 167.5526\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.1328 - val_loss: 163.9110\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.0189 - val_loss: 160.9496\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.4426 - val_loss: 159.2311\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.1313 - val_loss: 157.6123\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.2701 - val_loss: 155.0075\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.1657 - val_loss: 151.9969\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.3601 - val_loss: 151.4137\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.5975 - val_loss: 149.7155\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.3199 - val_loss: 147.9985\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.5441 - val_loss: 148.1507\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.7909 - val_loss: 145.1420\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.0530 - val_loss: 144.0881\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.8713 - val_loss: 143.4083\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.4592 - val_loss: 142.3094\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.6808 - val_loss: 142.3883\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.6104 - val_loss: 139.5464\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.3845 - val_loss: 142.6317\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.8448 - val_loss: 138.0209\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.8900 - val_loss: 138.6687\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.2163 - val_loss: 135.6057\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.2746 - val_loss: 135.2132\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.6117 - val_loss: 135.7202\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.4432 - val_loss: 133.9456\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.6570 - val_loss: 132.5438\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.9956 - val_loss: 133.2563\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.6764 - val_loss: 136.7817\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.6190 - val_loss: 129.8916\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.4247 - val_loss: 129.3144\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0804 - val_loss: 131.6756\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.5310 - val_loss: 129.1771\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.8457 - val_loss: 132.1700\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.3397 - val_loss: 126.7505\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2825 - val_loss: 128.1442\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.4608 - val_loss: 127.3976\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.4118 - val_loss: 130.5891\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.6343 - val_loss: 126.0371\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8081 - val_loss: 124.3635\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3296 - val_loss: 123.9273\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.4961 - val_loss: 123.8731\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.1771 - val_loss: 125.9576\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.0267 - val_loss: 123.1590\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.2903 - val_loss: 124.0578\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.5426 - val_loss: 125.4494\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.1231 - val_loss: 123.0710\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2240 - val_loss: 121.8142\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0388 - val_loss: 124.6903\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.8699 - val_loss: 121.1649\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.7450 - val_loss: 121.0720\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0948 - val_loss: 120.7650\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.5121 - val_loss: 124.0901\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.5363 - val_loss: 119.7696\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.9037 - val_loss: 127.2616\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.6292 - val_loss: 120.4435\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6478 - val_loss: 129.1912\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.4611 - val_loss: 118.3938\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.2704 - val_loss: 121.7985\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.1781 - val_loss: 119.8193\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.9997 - val_loss: 120.1778\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.2593 - val_loss: 121.8895\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.1853 - val_loss: 120.9050\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.9468 - val_loss: 123.1169\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.9262 - val_loss: 122.0471\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.6928 - val_loss: 117.8385\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3721 - val_loss: 118.4038\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.8339 - val_loss: 118.8742\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 20709.0488 - val_loss: 3520.9180\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4057.1021 - val_loss: 4044.3848\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3223.9377 - val_loss: 2692.2739\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2684.5186 - val_loss: 2439.5750\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2358.1057 - val_loss: 2165.8906\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2110.8433 - val_loss: 1921.2817\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1856.6221 - val_loss: 1695.7362\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1635.3754 - val_loss: 1484.0034\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1417.5426 - val_loss: 1281.0852\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1234.3373 - val_loss: 1099.8430\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1055.7621 - val_loss: 945.1874\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 902.9678 - val_loss: 807.9808\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 770.0139 - val_loss: 683.2213\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 649.7118 - val_loss: 581.7952\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 548.9807 - val_loss: 487.0766\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 461.1284 - val_loss: 413.1619\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 391.8350 - val_loss: 352.9371\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 334.2964 - val_loss: 302.2526\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.2584 - val_loss: 260.0457\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.0005 - val_loss: 228.5557\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.8453 - val_loss: 204.4171\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.5932 - val_loss: 185.1952\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.1309 - val_loss: 170.1381\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.5671 - val_loss: 161.6037\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.6445 - val_loss: 151.9412\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.2553 - val_loss: 145.4731\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.8675 - val_loss: 140.2972\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.4938 - val_loss: 136.3383\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.4391 - val_loss: 133.1267\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.9081 - val_loss: 133.2594\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.3729 - val_loss: 128.1467\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.8263 - val_loss: 133.9463\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.3132 - val_loss: 126.3772\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.9671 - val_loss: 123.0254\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.4615 - val_loss: 126.5638\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.0173 - val_loss: 120.0782\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.6411 - val_loss: 118.9010\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.8592 - val_loss: 117.7084\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.6269 - val_loss: 118.2786\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2629 - val_loss: 115.8190\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.8402 - val_loss: 115.4848\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.8558 - val_loss: 115.2003\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.6566 - val_loss: 113.2323\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0040 - val_loss: 113.4715\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.8363 - val_loss: 115.9815\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.2276 - val_loss: 111.1659\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.7904 - val_loss: 125.4866\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.6478 - val_loss: 117.1346\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0424 - val_loss: 110.0482\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.9795 - val_loss: 109.9512\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.0633 - val_loss: 119.2358\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.1952 - val_loss: 109.4341\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.5614 - val_loss: 112.8683\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.3194 - val_loss: 108.3151\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.5445 - val_loss: 107.9958\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.8568 - val_loss: 106.7208\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.8450 - val_loss: 106.5855\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.9491 - val_loss: 106.2016\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3004 - val_loss: 106.0084\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.5084 - val_loss: 107.9360\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7593 - val_loss: 105.5206\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.1647 - val_loss: 105.6503\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.4406 - val_loss: 112.9102\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.3369 - val_loss: 115.5811\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.6824 - val_loss: 107.3568\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.3329 - val_loss: 104.4811\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.5102 - val_loss: 107.7913\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.5139 - val_loss: 107.9012\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.1376 - val_loss: 105.6007\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.8742 - val_loss: 107.6125\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.2523 - val_loss: 103.7717\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.9140 - val_loss: 104.8591\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6067 - val_loss: 103.6264\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.2304 - val_loss: 104.1004\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.1842 - val_loss: 103.9246\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.7203 - val_loss: 103.2978\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.3212 - val_loss: 104.3552\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.3207 - val_loss: 103.2949\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.1713 - val_loss: 103.0438\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.3171 - val_loss: 109.3675\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.8862 - val_loss: 103.8931\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2944 - val_loss: 104.3218\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6669 - val_loss: 108.7173\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.0318 - val_loss: 106.9776\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6177 - val_loss: 107.1784\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.3468 - val_loss: 106.6734\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.2564 - val_loss: 103.8132\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.8548 - val_loss: 105.8872\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.7988 - val_loss: 105.1839\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.7154 - val_loss: 104.4701\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.5651 - val_loss: 106.0642\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.3436 - val_loss: 108.2170\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.9075 - val_loss: 105.4880\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.5661 - val_loss: 102.5181\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.8798 - val_loss: 111.2237\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.0842 - val_loss: 102.3930\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.5955 - val_loss: 104.9066\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7792 - val_loss: 102.8223\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.4454 - val_loss: 102.1921\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7318 - val_loss: 131.8086\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 12910.5117 - val_loss: 4664.8521\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2477.0344 - val_loss: 856.7576\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 638.4143 - val_loss: 472.5629\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.5533 - val_loss: 382.2839\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 355.1032 - val_loss: 322.9136\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 313.9663 - val_loss: 287.8846\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.0269 - val_loss: 248.9557\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 264.1466 - val_loss: 233.4802\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.1382 - val_loss: 227.4139\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 241.0895 - val_loss: 217.8561\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.2292 - val_loss: 216.5037\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.1017 - val_loss: 206.4621\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.0603 - val_loss: 202.6542\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 212.6814 - val_loss: 196.1796\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.9616 - val_loss: 192.3496\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 202.1303 - val_loss: 189.4585\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.2799 - val_loss: 183.6506\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.4460 - val_loss: 181.7596\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.4214 - val_loss: 177.9985\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.3184 - val_loss: 173.8572\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5738 - val_loss: 171.6976\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.2634 - val_loss: 168.8907\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.3998 - val_loss: 163.3301\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.6706 - val_loss: 161.6766\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.6784 - val_loss: 158.5942\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.6384 - val_loss: 154.4139\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.8961 - val_loss: 154.4444\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157.6014 - val_loss: 151.4227\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.1099 - val_loss: 148.9118\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.7225 - val_loss: 148.2217\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4773 - val_loss: 145.8353\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.5600 - val_loss: 145.4362\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.6588 - val_loss: 141.5810\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.2473 - val_loss: 142.2492\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.9508 - val_loss: 138.8985\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.3751 - val_loss: 138.4727\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3736 - val_loss: 136.8338\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.2827 - val_loss: 135.5582\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.2330 - val_loss: 134.5620\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3107 - val_loss: 131.3385\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.4462 - val_loss: 133.7458\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.7877 - val_loss: 130.2502\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.8060 - val_loss: 132.2122\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.6431 - val_loss: 127.6337\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.6351 - val_loss: 126.5024\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8583 - val_loss: 127.4274\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.4632 - val_loss: 125.8231\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.2510 - val_loss: 124.8582\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.4912 - val_loss: 124.4401\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.7093 - val_loss: 125.7257\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.4374 - val_loss: 120.9845\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.4761 - val_loss: 123.8441\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0423 - val_loss: 117.6257\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.0995 - val_loss: 119.5891\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.5102 - val_loss: 121.3244\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.9671 - val_loss: 116.5839\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.5181 - val_loss: 116.1160\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3403 - val_loss: 113.8682\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.3892 - val_loss: 114.6413\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.5807 - val_loss: 114.6690\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.0089 - val_loss: 115.8240\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6101 - val_loss: 110.2256\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8015 - val_loss: 110.5027\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.5073 - val_loss: 108.9120\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.5865 - val_loss: 108.2802\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.5464 - val_loss: 112.2468\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6917 - val_loss: 106.3286\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.2249 - val_loss: 105.9166\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4602 - val_loss: 107.9893\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.8470 - val_loss: 103.1973\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.0100 - val_loss: 105.9532\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.7261 - val_loss: 103.5888\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.3227 - val_loss: 100.8272\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5524 - val_loss: 103.5257\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.4061 - val_loss: 101.2715\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.3958 - val_loss: 98.4633\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.8084 - val_loss: 99.9181\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.1577 - val_loss: 98.7230\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.1755 - val_loss: 98.7926\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9302 - val_loss: 96.4113\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.7732 - val_loss: 97.5748\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.7365 - val_loss: 98.2560\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.2935 - val_loss: 94.1187\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.0462 - val_loss: 96.4477\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7296 - val_loss: 93.1221\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.6543 - val_loss: 96.1347\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.1643 - val_loss: 91.5709\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.8254 - val_loss: 89.9455\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.7301 - val_loss: 91.4329\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7865 - val_loss: 91.4439\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.7774 - val_loss: 91.7268\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.0173 - val_loss: 87.8721\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.0135 - val_loss: 87.9522\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.5292 - val_loss: 87.3347\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.0478 - val_loss: 86.7971\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.3314 - val_loss: 87.9418\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.1566 - val_loss: 87.0682\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.8458 - val_loss: 82.1488\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.0676 - val_loss: 91.3076\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.1744 - val_loss: 79.7274\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1046.7869 - val_loss: 990.0183\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 849.6213 - val_loss: 789.3566\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 706.9967 - val_loss: 654.2484\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 590.0231 - val_loss: 541.8451\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 505.1676 - val_loss: 470.3537\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 440.3099 - val_loss: 400.1934\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 387.0556 - val_loss: 342.5358\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 342.5541 - val_loss: 304.1656\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.9276 - val_loss: 272.4156\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.8969 - val_loss: 248.1354\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 257.3722 - val_loss: 225.8478\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.6794 - val_loss: 203.5832\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.0296 - val_loss: 193.1293\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.9730 - val_loss: 172.6220\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.2539 - val_loss: 161.1806\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.4315 - val_loss: 151.8251\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.7122 - val_loss: 142.7406\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.0227 - val_loss: 135.4240\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.8646 - val_loss: 128.7751\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.4253 - val_loss: 122.4783\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.9621 - val_loss: 120.8385\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.7668 - val_loss: 114.0229\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.6048 - val_loss: 110.8479\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.2394 - val_loss: 106.9539\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.1516 - val_loss: 105.7782\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2034 - val_loss: 101.5977\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.1500 - val_loss: 98.6564\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3497 - val_loss: 104.2835\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.8614 - val_loss: 100.1992\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.6340 - val_loss: 97.2671\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0856 - val_loss: 94.6916\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.8683 - val_loss: 91.5379\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1546 - val_loss: 90.5886\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2342 - val_loss: 89.3430\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0013 - val_loss: 87.9671\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.8739 - val_loss: 89.9238\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.9288 - val_loss: 86.9085\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.3978 - val_loss: 87.7380\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2745 - val_loss: 88.2417\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 100.7338 - val_loss: 85.6901\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.9161 - val_loss: 85.5162\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.5303 - val_loss: 83.8373\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.5609 - val_loss: 84.7465\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.4269 - val_loss: 83.3828\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.9487 - val_loss: 85.1343\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.9498 - val_loss: 83.6792\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.2990 - val_loss: 81.9595\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.1883 - val_loss: 81.4669\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.7801 - val_loss: 80.7716\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.5503 - val_loss: 82.0043\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.1289 - val_loss: 81.2787\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.9148 - val_loss: 80.3945\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5400 - val_loss: 79.9424\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.9562 - val_loss: 79.6611\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.6333 - val_loss: 84.6577\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.7102 - val_loss: 79.6751\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.6379 - val_loss: 80.5637\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.7334 - val_loss: 109.8611\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0896 - val_loss: 81.7663\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.6324 - val_loss: 104.9833\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7821 - val_loss: 80.4015\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.8894 - val_loss: 79.5541\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.2224 - val_loss: 77.3892\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.6076 - val_loss: 80.1494\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.3565 - val_loss: 79.9267\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.4117 - val_loss: 84.3931\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.9260 - val_loss: 75.8071\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.5664 - val_loss: 78.9507\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 95.7559 - val_loss: 87.9239\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1977 - val_loss: 78.3107\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5022 - val_loss: 80.2064\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.6458 - val_loss: 75.3360\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.1360 - val_loss: 94.2903\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.5702 - val_loss: 76.3328\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.1425 - val_loss: 74.5751\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.5825 - val_loss: 75.5220\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.8627 - val_loss: 76.3875\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.3772 - val_loss: 75.3143\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.1441 - val_loss: 74.9918\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.5340 - val_loss: 73.7532\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.0494 - val_loss: 73.6090\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.1363 - val_loss: 73.5313\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.7584 - val_loss: 73.2499\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.2218 - val_loss: 73.1572\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.9044 - val_loss: 78.5882\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.4419 - val_loss: 75.7568\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.7601 - val_loss: 78.8003\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.0641 - val_loss: 72.7523\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.8700 - val_loss: 71.8170\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.8669 - val_loss: 72.1279\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.7436 - val_loss: 72.7473\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.1367 - val_loss: 71.3935\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.8806 - val_loss: 75.8261\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.0900 - val_loss: 70.9166\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.1926 - val_loss: 71.8165\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.4544 - val_loss: 70.8662\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.7982 - val_loss: 72.3145\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.8253 - val_loss: 72.9636\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.4331 - val_loss: 70.3352\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 83.2679 - val_loss: 73.4824\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total Execution Time :  0:08:15.858021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob23hKqNOfoM",
        "outputId": "23e0ba06-4dd9-4d18-f1d8-b56e190bc047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' , str(std_of_mse))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  110.94569612436645\n",
            "Standard Deviation of MSE of 50 Models :  44.89824809504772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAVXnC2rOfoM"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTcbSwI7OfoM"
      },
      "source": [
        "#### <font color = green> Comparision of Mean of MSE with Mean of MSE with PART C </font>\n",
        "<table style=\"width:30%\">\n",
        "  <tr>\n",
        "    <th>Mean of MSE of PART A</th>\n",
        "    <th>Mean of MSE of PART B</th>\n",
        "    <th>Mean of MSE of PART C</th>\n",
        "    <th>Mean of MSE of PART D</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>244.77</td>\n",
        "    <td>126.13</td>\n",
        "    <td>149.31</td>\n",
        "    <td>121.49</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "The table above compares the Mean of **MSE for PART A**, **Mean of MSE for PART B**, **Mean of MSE for PART C** and **Mean of MSE for PART D**. As can be seen, the value of Mean of MSE of PART D is marginally smaller than that of PART C and is the smallest value obtained. This shows that the effect of **normalizing the features** as well as **increasing the number of epochs by 2** yield the best results in terms of the performance of the regression model and helps it in finding the line of best fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IMCNnzzOfoM"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK8FCTQIOfoM"
      },
      "source": [
        "# <font color = blue> END OF PART D</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRjzHAlMOfoM"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7QECaDlOfoM"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NctGmuVAOfoM"
      },
      "source": [
        "# <font color = ac36e3> END NOTE </font>\n",
        "\n",
        "Although the results above table show that the best performance is achieved by normalizing the features, increasing the number of epochs **and** increasing the number of hidden layers, this might not be decisive. Repeating ***TASK 2*** for **PART A**, **PART B**, **PART C** and **PART D** several times shows different results. However, for the purposes of this project, those results are not included. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVqyH1RROfoM"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uVrWZdUOfoN"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ooq1-FXdOfoN"
      },
      "source": [
        "# <font color = red> END OF NOTEBOOK </font>"
      ]
    }
  ]
}